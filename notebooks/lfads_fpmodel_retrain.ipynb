{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8ccaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU ID:0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    " %run /Desktop/Share/CUDA_DEVICE_setup.py -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccaf1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e700f7f-706d-4347-ae12-d9a010d589d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:07:50.592225: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-12 15:07:50.643267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 15:07:51.424924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#%config Completer.use_jedi = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "from pprint import pprint    \n",
    "import tensorflow as tf    \n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from tndm.data import DataManager\n",
    "from tndm import LFADS\n",
    "from tndm.runtime import Runtime\n",
    "from typing import Dict, Any\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93ea1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data/disk/scratch/cole/Chewie_CO_FF_2016-10-07_pos_M1_spikes/test_data/\n",
    "spike_data_dir = \"Chewie_CO_FF_2016-10-07_pos_M1_spikes/\"\n",
    "\n",
    "data_dir = os.path.join( spike_data_dir )\n",
    "\n",
    "dataset, settings = DataManager.load_dataset(\n",
    "    directory=data_dir,\n",
    "    filename='dataset.h5')\n",
    "\n",
    "#train\n",
    "neural_data = dataset['train_data'].astype('float')\n",
    "behavioural_data = dataset['train_behaviours'].astype('float')\n",
    "\n",
    "# valid\n",
    "valid_neural_data = dataset['valid_data'].astype('float')\n",
    "valid_behavioural_data = dataset['valid_behaviours'].astype('float')\n",
    "\n",
    "# test\n",
    "test_neural_data = dataset['test_data'].astype('float')\n",
    "test_behavioural_data = dataset['test_behaviours'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1ab64",
   "metadata": {},
   "source": [
    "# get dataset, to train by myself\n",
    "# with_behaviour = False for lfads\n",
    "# target = input for reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d679349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = Runtime.clean_datasets(\n",
    "            train_dataset=(neural_data, behavioural_data), \n",
    "            val_dataset=(valid_neural_data, valid_behavioural_data), \n",
    "            with_behaviour=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f96c7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_neural_data\n",
    "y_test = test_behavioural_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_shape(data):\n",
    "    if data is not None:\n",
    "        print(data.shape)\n",
    "    else:\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf5af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 73, 70)\n",
      "None\n",
      "(17, 73, 70)\n",
      "None\n",
      "(17, 73, 70)\n",
      "(17, 73, 2)\n"
     ]
    }
   ],
   "source": [
    "print_data_shape(x_train)\n",
    "print_data_shape(y_train)\n",
    "print_data_shape(x_val)\n",
    "print_data_shape(y_val)\n",
    "print_data_shape(x_test)\n",
    "print_data_shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba749a",
   "metadata": {},
   "source": [
    "# Quantize data first\n",
    "## the input and last layer will remain ap<16,6> precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb1de754",
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_BITS = 16\n",
    "AP_INTS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac366c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ususal quantize\n",
    "from qkeras import QActivation\n",
    "ACTIVATION_BITS = \"quantized_bits(16,5,alpha=1)\".format(AP_BITS, AP_INTS-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f40062",
   "metadata": {},
   "source": [
    "## change to quantize inputs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01473a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see mae after quanitze\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01259fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0\n",
      "before quantization min/max: 0.0 / 3.0\n",
      "after quantization min/max: 0.0 / 3.0\n",
      "MAE of quantization:  0.0\n",
      "index:  1\n",
      "before quantization min/max: 0.0 / 3.0\n",
      "after quantization min/max: 0.0 / 3.0\n",
      "MAE of quantization:  0.0\n",
      "index:  2\n",
      "before quantization min/max: 0.0 / 3.0\n",
      "after quantization min/max: 0.0 / 3.0\n",
      "MAE of quantization:  0.0\n"
     ]
    }
   ],
   "source": [
    "#total_data = [x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "total_data = [x_train, x_val, x_test]\n",
    "\n",
    "for index, d in enumerate(total_data):\n",
    "    print(\"index: \", index)\n",
    "    if d is None:\n",
    "        print(\"None\")\n",
    "    else:                \n",
    "        print(\"before quantization min/max: {} / {}\".format(d.min(), d.max()))\n",
    "        q_d = QActivation(ACTIVATION_BITS)(d)\n",
    "        q_d_numpy = q_d.numpy()\n",
    "        print(\"after quantization min/max: {} / {}\".format(q_d_numpy.min(), q_d_numpy.max()))\n",
    "        print(\"MAE of quantization: \", mean_absolute_error(d.flatten(), q_d_numpy.flatten()))\n",
    "        total_data[index] = q_d_numpy\n",
    "    \n",
    "#[x_train, y_train, x_val, y_val, x_test, y_test] = total_data    \n",
    "[x_train, x_val, x_test] = total_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ef869",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4900bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "\n",
    "# l2 regulariser for the recurrent decoder weights\n",
    "l2_reg = .1\n",
    "#initial_neural_weight = 1.0 # weight of neural nll\n",
    "#initial_behaviour_weight = .2 # weight of behaviour loss\n",
    "#lambda_q = 100.0\n",
    "#update_rate = .0005\n",
    "dropout = .15\n",
    "#seed = 0\n",
    "#GRU_pre_activation = False\n",
    "#var_min = 0.0001\n",
    "#prior_variance = 1\n",
    "threshold_poisson_log_firing_rate = 100.\n",
    "\n",
    "\n",
    "layers_settings=defaultdict(lambda: dict(\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "        scale=1.0, mode='fan_in', distribution='normal'),\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(l=0.0)\n",
    "))\n",
    "\n",
    "layers_settings['decoder'].update(dict(kernel_regularizer=tf.keras.regularizers.l2(l=0),\n",
    "                                      recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                      original_cell=False))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9a6bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f12ac0be310>,\n",
      "            {'decoder': {'kernel_initializer': <keras.initializers.initializers.VarianceScaling object at 0x7f12ad6bb4f0>,\n",
      "                         'kernel_regularizer': <keras.regularizers.L2 object at 0x7f12ad6bb340>,\n",
      "                         'original_cell': False,\n",
      "                         'recurrent_regularizer': <keras.regularizers.L2 object at 0x7f12ad6bbc40>}})\n"
     ]
    }
   ],
   "source": [
    "pprint(layers_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3086f5c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_initializer': <keras.initializers.initializers.VarianceScaling at 0x7f12ad6a8b80>,\n",
       " 'kernel_regularizer': <keras.regularizers.L2 at 0x7f12ad6a8d90>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_settings['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b13aef4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_initializer': <keras.initializers.initializers.VarianceScaling at 0x7f12ad6bb4f0>,\n",
       " 'kernel_regularizer': <keras.regularizers.L2 at 0x7f12ad6bb340>,\n",
       " 'recurrent_regularizer': <keras.regularizers.L2 at 0x7f12ad6bbc40>,\n",
       " 'original_cell': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_settings['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94262ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel_initializer': <keras.initializers.initializers.VarianceScaling at 0x7f12ad6a8bb0>,\n",
       " 'kernel_regularizer': <keras.regularizers.L2 at 0x7f12ad6a8910>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_settings['dense_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efe6e0",
   "metadata": {},
   "source": [
    "## function to build the model"
   ]
  },
  {
   "attachments": {
    "%E5%9C%96%E7%89%87.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "246c7882",
   "metadata": {},
   "source": [
    "![%E5%9C%96%E7%89%87.png](attachment:%E5%9C%96%E7%89%87.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829adb3c",
   "metadata": {},
   "source": [
    "## the ACCUM bits in QGRU is based on the state quantizer, so the previous act_quan precision should be less than it\n",
    "## here set the state quantizer same as the act_quan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308c77e",
   "metadata": {},
   "source": [
    "# input for decoder GRU\n",
    "# Assuming inputs are zero and everything comes from the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ee6246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef1aa3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_input(decoder_dim=64):\n",
    "    inputs2decoder_train = tf.stack([tf.zeros_like(x_train)[:, :, -1]\n",
    "                for i in range(decoder_dim)], axis=-1)\n",
    "    inputs2decoder_val = tf.stack([tf.zeros_like(x_val)[:, :, -1]\n",
    "                for i in range(decoder_dim)], axis=-1)\n",
    "    inputs2decoder_train = np.array(inputs2decoder_train)\n",
    "    inputs2decoder_val = np.array(inputs2decoder_val)\n",
    "    print(\"inputs2decoder_train shape: \", inputs2decoder_train.shape)\n",
    "    print(\"inputs2decoder_val shape: \", inputs2decoder_val.shape)\n",
    "    return inputs2decoder_train, inputs2decoder_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97518421",
   "metadata": {},
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baef405",
   "metadata": {},
   "source": [
    "## BenchMark fp-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63a55565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f196c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 15:16:29.215908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-12 15:16:29.217130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-12 15:16:29.218600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-12 15:16:29.330000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-12 15:16:29.362507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-12 15:16:29.363710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-12 15:16:29.365097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "/home/docker/anaconda3/envs/NNGEN/lib/python3.8/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2023-07-12 15:16:29.532002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-12 15:16:29.533222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-12 15:16:29.534696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "#fmodel = load_model(\"fpmodel_xianhan.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ef773fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 73, 70)]     0           []                               \n",
      "                                                                                                  \n",
      " initial_dropout (Dropout)      (None, 73, 70)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder_BidirectionalGRU (Bidi  [(None, 128),       52224       ['initial_dropout[0][0]']        \n",
      " rectional)                      (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " postencoder_dropout (Dropout)  (None, 128)          0           ['Encoder_BidirectionalGRU[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 73, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_mean (Dense)             (None, 64)           8256        ['postencoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " decoder_GRU (GRU)              (None, 73, 64)       24960       ['input_2[0][0]',                \n",
      "                                                                  'dense_mean[0][0]']             \n",
      "                                                                                                  \n",
      " postdecoder_dropout (Dropout)  (None, 73, 64)       0           ['decoder_GRU[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 73, 4)        256         ['postdecoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " nerual_dense (Dense)           (None, 73, 70)       350         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 86,046\n",
      "Trainable params: 86,046\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2286bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs2decoder_train shape:  (136, 73, 64)\n",
      "inputs2decoder_val shape:  (17, 73, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs2decoder_train, inputs2decoder_val = get_decoder_input(decoder_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b49d0ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/anaconda3/envs/NNGEN/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-07-12 15:16:33.858998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/nvidia/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 918ms/step\n"
     ]
    }
   ],
   "source": [
    "#pred_val_z, pred_val_logf = fmodel.predict([x_val, inputs2decoder_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be8fd49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NPLL(targets, pred_logrates):\n",
    "    targets = tf.cast(targets, dtype=tf.float32)\n",
    "    logrates = tf.cast(tf.math.log(0.01) + pred_logrates, tf.float32)  # Timestep\n",
    "    npll = tf.nn.log_poisson_loss(targets=targets,log_input=logrates, compute_full_loss=True)\n",
    "    results = tf.reduce_sum(npll, axis=[1, 2]) # sum up each batch seperately\n",
    "    results = tf.reduce_mean(results) # batch mean\n",
    "\n",
    "    print(results) # negative possion loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "252ed0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1768.8014, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#evaluate_NPLL(targets=x_val, pred_logrates=pred_val_logf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "171ff317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del fmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7b3e9",
   "metadata": {},
   "source": [
    "# loss: poisson_loglike_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4624250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f871cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2eab81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.01\n",
    "\n",
    "def poisson_loglike_loss(y_true, y_pred):    \n",
    "    # POISSON LOG-LIKELIHOOD\n",
    "    # clip the y_pred first\n",
    "    y_pred = tf.clip_by_value(y_pred, \n",
    "                                     clip_value_min=-threshold_poisson_log_firing_rate,\n",
    "                                     clip_value_max=threshold_poisson_log_firing_rate\n",
    "                             )\n",
    "    targets = tf.cast(y_true, dtype=tf.float32)\n",
    "    logrates = tf.cast(tf.math.log(timestep) + y_pred, tf.float32)  # Timestep\n",
    "    npll = tf.nn.log_poisson_loss(\n",
    "        targets=targets,\n",
    "        log_input=logrates, compute_full_loss=True\n",
    "    )\n",
    "    #print(npll.shape)\n",
    "    loss = tf.reduce_sum(npll, axis=[1, 2]) # sum up each batch seperately\n",
    "    loss = tf.reduce_mean(loss) # batch mean\n",
    "    #loss = tf.reduce_sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163ace5",
   "metadata": {},
   "source": [
    "## Build a fp model and train\n",
    "## compare with the benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0590b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26bdfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fpmodel(input_shape = (73,70),\n",
    "                    encoder_dim=64,  \n",
    "                   decoder_dim = decoder_dim,\n",
    "                   factors = 4,\n",
    "                   drop=dropout\n",
    "                  ):\n",
    "    \n",
    "    # input layer\n",
    "    inputLayer =  tfl.Input(shape=input_shape)        \n",
    "    x = tfl.Dropout(drop, name = 'initial_dropout')(inputLayer)\n",
    "    \n",
    "    # encoder\n",
    "    forward_layer = tfl.GRU(\n",
    "            encoder_dim, \n",
    "            time_major=False,\n",
    "            name=\"EncoderGRUForward\",\n",
    "            return_state=True,\n",
    "            kernel_regularizer=layers_settings['encoder']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['encoder']['kernel_initializer'],\n",
    "            )\n",
    "    \n",
    "    backward_layer = tfl.GRU(\n",
    "            encoder_dim, \n",
    "            time_major=False,\n",
    "            name=\"EncoderGRUBackward\",\n",
    "            return_state=True, \n",
    "            go_backwards=True,\n",
    "            kernel_regularizer=layers_settings['encoder']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['encoder']['kernel_initializer'],\n",
    "             )\n",
    "                \n",
    "    x = tfl.Bidirectional(\n",
    "        forward_layer, \n",
    "        backward_layer=backward_layer,\n",
    "        merge_mode='concat', \n",
    "        name = 'Encoder_BidirectionalGRU'\n",
    "        )(x)[0]  \n",
    "    \n",
    "    x = tfl.Dropout(drop, name = 'postencoder_dropout')(x)\n",
    "    \n",
    "    # latent space, no mean and var \n",
    "    # since the latent vector will become the initial state of the decoder GRU, \n",
    "    # decoder_dim = latent dimension\n",
    "    x = tfl.Dense(decoder_dim, \n",
    "               kernel_regularizer=layers_settings['dense_mean']['kernel_regularizer'],\n",
    "               kernel_initializer=layers_settings['dense_mean']['kernel_initializer'],\n",
    "               name='dense_latent'\n",
    "              )(x)\n",
    "    \n",
    "    # decoder\n",
    "    input_decoder_shape = (input_shape[0], decoder_dim) #( 73 timesteps, 64 decoder_dim)\n",
    "    input_decoder = tfl.Input(shape=input_decoder_shape)\n",
    "        \n",
    "    x = tfl.GRU(\n",
    "                decoder_dim,                \n",
    "                return_sequences=True,\n",
    "                time_major=False,\n",
    "                name='DecoderGRU'\n",
    "                )(input_decoder, initial_state = x)\n",
    "    x = tfl.Dropout(drop, name = 'postdecoder_dropout')(x)\n",
    "    \n",
    "    # DIMENSIONALITY REDUCTION\n",
    "    z = tfl.Dense(\n",
    "            factors, \n",
    "            use_bias=False, \n",
    "            kernel_regularizer=layers_settings['dense']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['dense']['kernel_initializer'],\n",
    "            name=\"dense\"\n",
    "            )(x)\n",
    "    \n",
    "    # NEURAL\n",
    "    neural_dim = input_shape[-1] #70\n",
    "    \n",
    "    z = tfl.Dense(\n",
    "            neural_dim, \n",
    "            use_bias=True, \n",
    "            kernel_regularizer=layers_settings['nerual_dense']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['nerual_dense']['kernel_initializer'],\n",
    "            name='nerual_dense')(z)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = [inputLayer,input_decoder], outputs =z)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65cb4f",
   "metadata": {},
   "source": [
    "# train the fp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5b185fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpmodel = create_fpmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5e3314fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 73, 70)]     0           []                               \n",
      "                                                                                                  \n",
      " initial_dropout (Dropout)      (None, 73, 70)       0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder_BidirectionalGRU (Bidi  [(None, 128),       52224       ['initial_dropout[0][0]']        \n",
      " rectional)                      (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " postencoder_dropout (Dropout)  (None, 128)          0           ['Encoder_BidirectionalGRU[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 73, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_latent (Dense)           (None, 64)           8256        ['postencoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " DecoderGRU (GRU)               (None, 73, 64)       24960       ['input_25[0][0]',               \n",
      "                                                                  'dense_latent[0][0]']           \n",
      "                                                                                                  \n",
      " postdecoder_dropout (Dropout)  (None, 73, 64)       0           ['DecoderGRU[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 73, 4)        256         ['postdecoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " nerual_dense (Dense)           (None, 73, 70)       350         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 86,046\n",
      "Trainable params: 86,046\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fpmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec1cc4",
   "metadata": {},
   "source": [
    "# train\n",
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97638ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(\"fp_log.csv\", separator=\",\", append=False)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"lfadfp.h5\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    save_weights_only= False\n",
    ")\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lfadfp_callbacks=[csv_logger, model_check, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fe35d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-2,\n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ebfc413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpmodel.compile(\n",
    "    loss = poisson_loglike_loss,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eaee619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 3000.9448 - val_loss: 2744.1719\n",
      "Epoch 2/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2621.7803 - val_loss: 2399.7068\n",
      "Epoch 3/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2312.3101 - val_loss: 2143.6670\n",
      "Epoch 4/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2092.8936 - val_loss: 1976.2964\n",
      "Epoch 5/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1955.1898 - val_loss: 1880.2726\n",
      "Epoch 6/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1882.1598 - val_loss: 1838.7418\n",
      "Epoch 7/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1850.4299 - val_loss: 1820.4463\n",
      "Epoch 8/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1834.3115 - val_loss: 1816.4210\n",
      "Epoch 9/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1828.5623 - val_loss: 1815.9033\n",
      "Epoch 10/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.4106 - val_loss: 1810.9805\n",
      "Epoch 11/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1823.3535 - val_loss: 1809.7709\n",
      "Epoch 12/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1822.6080 - val_loss: 1809.9073\n",
      "Epoch 13/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1822.3226 - val_loss: 1808.9703\n",
      "Epoch 14/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1820.6262 - val_loss: 1809.9031\n",
      "Epoch 15/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1819.8983 - val_loss: 1809.8110\n",
      "Epoch 16/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1819.6707 - val_loss: 1810.3009\n",
      "Epoch 17/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1819.6746 - val_loss: 1809.5828\n",
      "Epoch 18/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1820.2566 - val_loss: 1812.7666\n",
      "Epoch 19/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1818.9850 - val_loss: 1808.7390\n",
      "Epoch 20/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1817.8414 - val_loss: 1808.7302\n",
      "Epoch 21/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1817.3506 - val_loss: 1810.4045\n",
      "Epoch 22/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1817.9924 - val_loss: 1813.2563\n",
      "Epoch 23/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1818.8138 - val_loss: 1810.7343\n",
      "Epoch 24/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1817.9950 - val_loss: 1807.9667\n",
      "Epoch 25/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1818.2108 - val_loss: 1809.1748\n",
      "Epoch 26/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1817.3890 - val_loss: 1806.1869\n",
      "Epoch 27/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1815.2113 - val_loss: 1806.6271\n",
      "Epoch 28/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1814.6604 - val_loss: 1806.5865\n",
      "Epoch 29/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1814.4446 - val_loss: 1804.8833\n",
      "Epoch 30/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1813.6411 - val_loss: 1804.6160\n",
      "Epoch 31/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1813.4393 - val_loss: 1804.3038\n",
      "Epoch 32/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1812.1100 - val_loss: 1803.6200\n",
      "Epoch 33/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1810.9288 - val_loss: 1802.7825\n",
      "Epoch 34/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1809.4377 - val_loss: 1802.0062\n",
      "Epoch 35/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1810.0951 - val_loss: 1801.6592\n",
      "Epoch 36/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1808.6721 - val_loss: 1802.4003\n",
      "Epoch 37/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1808.3505 - val_loss: 1800.8564\n",
      "Epoch 38/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1809.1276 - val_loss: 1800.5753\n",
      "Epoch 39/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1807.3204 - val_loss: 1798.9910\n",
      "Epoch 40/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1805.6753 - val_loss: 1799.6084\n",
      "Epoch 41/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1805.5381 - val_loss: 1796.3217\n",
      "Epoch 42/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1803.7460 - val_loss: 1796.5162\n",
      "Epoch 43/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1804.1879 - val_loss: 1803.8375\n",
      "Epoch 44/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1806.5120 - val_loss: 1797.9309\n",
      "Epoch 45/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1805.9329 - val_loss: 1799.1371\n",
      "Epoch 46/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1803.1348 - val_loss: 1793.3373\n",
      "Epoch 47/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1800.9919 - val_loss: 1792.7087\n",
      "Epoch 48/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1799.7362 - val_loss: 1793.3656\n",
      "Epoch 49/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1798.3639 - val_loss: 1790.2009\n",
      "Epoch 50/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1796.8104 - val_loss: 1788.3090\n",
      "Epoch 51/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1795.3966 - val_loss: 1787.7233\n",
      "Epoch 52/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1795.0914 - val_loss: 1788.1484\n",
      "Epoch 53/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1793.7684 - val_loss: 1787.4225\n",
      "Epoch 54/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1794.5049 - val_loss: 1790.7600\n",
      "Epoch 55/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1794.1014 - val_loss: 1786.8748\n",
      "Epoch 56/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1791.8949 - val_loss: 1785.7812\n",
      "Epoch 57/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1790.6821 - val_loss: 1784.0297\n",
      "Epoch 58/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1789.7954 - val_loss: 1784.4805\n",
      "Epoch 59/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1789.0365 - val_loss: 1782.6993\n",
      "Epoch 60/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1788.5248 - val_loss: 1783.0699\n",
      "Epoch 61/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1787.1255 - val_loss: 1783.4913\n",
      "Epoch 62/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.2817 - val_loss: 1786.1466\n",
      "Epoch 63/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1790.6969 - val_loss: 1782.6477\n",
      "Epoch 64/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1788.1233 - val_loss: 1784.0953\n",
      "Epoch 65/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1787.1033 - val_loss: 1780.8076\n",
      "Epoch 66/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1785.9392 - val_loss: 1778.9788\n",
      "Epoch 67/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1784.8289 - val_loss: 1779.1714\n",
      "Epoch 68/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1783.5526 - val_loss: 1779.2563\n",
      "Epoch 69/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1782.9430 - val_loss: 1778.5188\n",
      "Epoch 70/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1782.2589 - val_loss: 1778.2015\n",
      "Epoch 71/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1781.9141 - val_loss: 1777.4193\n",
      "Epoch 72/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1781.2557 - val_loss: 1777.6764\n",
      "Epoch 73/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1781.9468 - val_loss: 1777.1562\n",
      "Epoch 74/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1781.3673 - val_loss: 1776.3842\n",
      "Epoch 75/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1780.5596 - val_loss: 1777.3220\n",
      "Epoch 76/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1780.2000 - val_loss: 1778.7893\n",
      "Epoch 77/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1779.7656 - val_loss: 1777.5845\n",
      "Epoch 78/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.3115 - val_loss: 1778.2635\n",
      "Epoch 79/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.1726 - val_loss: 1777.2336\n",
      "Epoch 80/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1780.3640 - val_loss: 1774.3322\n",
      "Epoch 81/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1777.9080 - val_loss: 1776.0757\n",
      "Epoch 82/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1777.1951 - val_loss: 1776.2584\n",
      "Epoch 83/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1776.6077 - val_loss: 1774.7324\n",
      "Epoch 84/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1777.0986 - val_loss: 1773.5143\n",
      "Epoch 85/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1777.5566 - val_loss: 1775.4626\n",
      "Epoch 86/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1776.5117 - val_loss: 1773.5425\n",
      "Epoch 87/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.2523 - val_loss: 1773.7202\n",
      "Epoch 88/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1774.0803 - val_loss: 1771.6630\n",
      "Epoch 89/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1773.9904 - val_loss: 1772.3279\n",
      "Epoch 90/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1773.6693 - val_loss: 1773.3142\n",
      "Epoch 91/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1773.3662 - val_loss: 1772.8440\n",
      "Epoch 92/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1773.1284 - val_loss: 1770.2294\n",
      "Epoch 93/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1772.1332 - val_loss: 1771.6361\n",
      "Epoch 94/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1772.2628 - val_loss: 1771.3218\n",
      "Epoch 95/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1771.2679 - val_loss: 1772.0232\n",
      "Epoch 96/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.2712 - val_loss: 1772.4971\n",
      "Epoch 97/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1773.4473 - val_loss: 1770.9834\n",
      "Epoch 98/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1771.7979 - val_loss: 1769.0986\n",
      "Epoch 99/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1771.3784 - val_loss: 1769.0396\n",
      "Epoch 100/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1771.3282 - val_loss: 1770.9437\n",
      "Epoch 101/10000\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 1771.1927 - val_loss: 1771.4347\n",
      "Epoch 102/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.7286 - val_loss: 1772.2028\n",
      "Epoch 103/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.6521 - val_loss: 1770.6852\n",
      "Epoch 104/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1770.1326 - val_loss: 1770.3287\n",
      "Epoch 105/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1769.1748 - val_loss: 1769.6158\n",
      "Epoch 106/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1768.6344 - val_loss: 1768.7217\n",
      "Epoch 107/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1768.3665 - val_loss: 1768.4984\n",
      "Epoch 108/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1767.6077 - val_loss: 1769.3889\n",
      "Epoch 109/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1768.2350 - val_loss: 1768.8870\n",
      "Epoch 110/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1767.1956 - val_loss: 1769.6796\n",
      "Epoch 111/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1767.3990 - val_loss: 1767.9211\n",
      "Epoch 112/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1766.9357 - val_loss: 1769.6166\n",
      "Epoch 113/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1767.0758 - val_loss: 1767.4834\n",
      "Epoch 114/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1767.0363 - val_loss: 1768.8721\n",
      "Epoch 115/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.1200 - val_loss: 1768.2878\n",
      "Epoch 116/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.4448 - val_loss: 1770.1226\n",
      "Epoch 117/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.9016 - val_loss: 1767.1228\n",
      "Epoch 118/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1766.7297 - val_loss: 1770.0404\n",
      "Epoch 119/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1766.5713 - val_loss: 1767.5356\n",
      "Epoch 120/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1767.7773 - val_loss: 1767.3146\n",
      "Epoch 121/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1767.2819 - val_loss: 1766.5339\n",
      "Epoch 122/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1766.3591 - val_loss: 1770.3278\n",
      "Epoch 123/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1766.8746 - val_loss: 1766.0638\n",
      "Epoch 124/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.1294 - val_loss: 1767.7822\n",
      "Epoch 125/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1765.0808 - val_loss: 1768.0037\n",
      "Epoch 126/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1765.4028 - val_loss: 1768.3110\n",
      "Epoch 127/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.7811 - val_loss: 1767.7545\n",
      "Epoch 128/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.5397 - val_loss: 1771.8307\n",
      "Epoch 129/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1766.2775 - val_loss: 1768.5162\n",
      "Epoch 130/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.2948 - val_loss: 1768.7937\n",
      "Epoch 131/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1764.9380 - val_loss: 1767.3712\n",
      "Epoch 132/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.4640 - val_loss: 1766.4050\n",
      "Epoch 133/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1765.5322 - val_loss: 1769.1998\n",
      "Epoch 134/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.4919 - val_loss: 1768.2982\n",
      "Epoch 135/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1765.5226 - val_loss: 1766.8162\n",
      "Epoch 136/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.9205 - val_loss: 1766.8225\n",
      "Epoch 137/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1765.2529 - val_loss: 1769.5504\n",
      "Epoch 138/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1764.9592 - val_loss: 1768.1423\n",
      "Epoch 139/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.7616 - val_loss: 1766.2402\n",
      "Epoch 140/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1765.4337 - val_loss: 1771.1279\n",
      "Epoch 141/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1765.3749 - val_loss: 1767.5741\n",
      "Epoch 142/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1764.5244 - val_loss: 1770.1349\n",
      "Epoch 143/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1765.0830 - val_loss: 1767.3521\n",
      "Epoch 144/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1764.3986 - val_loss: 1766.6198\n",
      "Epoch 145/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1763.5483 - val_loss: 1767.1147\n",
      "Epoch 146/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1763.6575 - val_loss: 1766.6310\n",
      "Epoch 147/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.4994 - val_loss: 1766.8589\n",
      "Epoch 148/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1761.9662 - val_loss: 1767.1466\n",
      "Epoch 149/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1762.7552 - val_loss: 1769.6051\n",
      "Epoch 150/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.4873 - val_loss: 1769.8828\n",
      "Epoch 151/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1765.1227 - val_loss: 1768.2725\n",
      "Epoch 152/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.8049 - val_loss: 1766.6006\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.9365 - val_loss: 1768.8004\n",
      "Epoch 154/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.3267 - val_loss: 1767.0087\n",
      "Epoch 155/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.8214 - val_loss: 1770.6802\n",
      "Epoch 156/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1763.2057 - val_loss: 1767.9644\n",
      "Epoch 157/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.4255 - val_loss: 1768.3384\n",
      "Epoch 158/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.9902 - val_loss: 1769.6744\n",
      "Epoch 159/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1763.2842 - val_loss: 1766.9756\n",
      "Epoch 160/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1763.3506 - val_loss: 1767.2852\n",
      "Epoch 161/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1762.1671 - val_loss: 1765.5439\n",
      "Epoch 162/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.8452 - val_loss: 1767.6700\n",
      "Epoch 163/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.6948 - val_loss: 1768.4849\n",
      "Epoch 164/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1761.3756 - val_loss: 1768.0364\n",
      "Epoch 165/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1762.7119 - val_loss: 1767.3649\n",
      "Epoch 166/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.2844 - val_loss: 1769.5887\n",
      "Epoch 167/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.4098 - val_loss: 1770.1136\n",
      "Epoch 168/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1762.7019 - val_loss: 1766.6626\n",
      "Epoch 169/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1761.5945 - val_loss: 1767.2059\n",
      "Epoch 170/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1761.3834 - val_loss: 1766.8806\n",
      "Epoch 171/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.6870 - val_loss: 1766.7661\n",
      "Epoch 172/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.0360 - val_loss: 1767.7739\n",
      "Epoch 173/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1762.8933 - val_loss: 1767.9607\n",
      "Epoch 174/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1762.6593 - val_loss: 1768.8970\n",
      "Epoch 175/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1762.9727 - val_loss: 1770.2184\n",
      "Epoch 176/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1763.0630 - val_loss: 1767.7394\n",
      "Epoch 177/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.0159 - val_loss: 1767.0214\n",
      "Epoch 178/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1762.6357 - val_loss: 1767.0629\n",
      "Epoch 179/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.5833 - val_loss: 1765.5287\n",
      "Epoch 180/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.0576 - val_loss: 1768.0421\n",
      "Epoch 181/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.8146 - val_loss: 1768.0140\n",
      "Epoch 182/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1760.7214 - val_loss: 1766.2502\n",
      "Epoch 183/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1761.1702 - val_loss: 1766.3833\n",
      "Epoch 184/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1760.8610 - val_loss: 1770.7993\n",
      "Epoch 185/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1762.0146 - val_loss: 1766.5640\n",
      "Epoch 186/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1760.5400 - val_loss: 1768.1597\n",
      "Epoch 187/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1761.7502 - val_loss: 1767.7065\n",
      "Epoch 188/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.1110 - val_loss: 1768.0378\n",
      "Epoch 189/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.5543 - val_loss: 1766.9960\n",
      "Epoch 190/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1760.9868 - val_loss: 1767.9600\n",
      "Epoch 191/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.3989 - val_loss: 1766.6766\n",
      "Epoch 192/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1761.7523 - val_loss: 1765.8654\n",
      "Epoch 193/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1760.9679 - val_loss: 1768.5923\n",
      "Epoch 194/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1760.6144 - val_loss: 1767.3704\n",
      "Epoch 195/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1760.5164 - val_loss: 1766.0565\n",
      "Epoch 196/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1759.9484 - val_loss: 1765.6422\n",
      "Epoch 197/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1759.9583 - val_loss: 1766.6050\n",
      "Epoch 198/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1760.7135 - val_loss: 1767.4730\n",
      "Epoch 199/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1759.7784 - val_loss: 1766.1541\n",
      "Epoch 200/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1759.7482 - val_loss: 1766.0260\n",
      "Epoch 201/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1759.9185 - val_loss: 1768.0466\n",
      "Epoch 202/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1759.1582 - val_loss: 1766.6396\n",
      "Epoch 203/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1760.0015 - val_loss: 1766.7565\n",
      "Epoch 204/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1759.4902 - val_loss: 1767.2650\n",
      "Epoch 205/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1759.0756 - val_loss: 1767.0303\n",
      "Epoch 206/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1758.7181 - val_loss: 1766.6700\n",
      "Epoch 207/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1758.7523 - val_loss: 1765.4930\n",
      "Epoch 208/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1759.0342 - val_loss: 1769.5258\n",
      "Epoch 209/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1758.9517 - val_loss: 1767.6365\n",
      "Epoch 210/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1759.3976 - val_loss: 1768.0059\n",
      "Epoch 211/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1760.4579 - val_loss: 1767.5466\n",
      "Epoch 212/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1759.4679 - val_loss: 1767.9066\n",
      "Epoch 213/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1760.1489 - val_loss: 1767.6261\n",
      "Epoch 214/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1759.4529 - val_loss: 1767.4791\n",
      "Epoch 215/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1759.7507 - val_loss: 1766.1185\n",
      "Epoch 216/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1759.2969 - val_loss: 1766.5217\n",
      "Epoch 217/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1758.6991 - val_loss: 1766.8998\n",
      "Epoch 218/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1758.8993 - val_loss: 1766.3300\n",
      "Epoch 219/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.1952 - val_loss: 1766.0441\n",
      "Epoch 220/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.9224 - val_loss: 1767.4854\n",
      "Epoch 221/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1757.9694 - val_loss: 1767.2971\n",
      "Epoch 222/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.3577 - val_loss: 1766.8755\n",
      "Epoch 223/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.8287 - val_loss: 1766.6027\n",
      "Epoch 224/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.9412 - val_loss: 1766.8597\n",
      "Epoch 225/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1758.0863 - val_loss: 1767.0782\n",
      "Epoch 226/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.9962 - val_loss: 1765.8779\n",
      "Epoch 227/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1757.5226 - val_loss: 1766.0912\n",
      "Epoch 228/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1757.9714 - val_loss: 1767.5333\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 34ms/step - loss: 1758.2404 - val_loss: 1765.7655\n",
      "Epoch 230/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.1150 - val_loss: 1766.5367\n",
      "Epoch 231/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1758.6605 - val_loss: 1764.9188\n",
      "Epoch 232/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1757.9072 - val_loss: 1766.4636\n",
      "Epoch 233/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1759.4482 - val_loss: 1768.0342\n",
      "Epoch 234/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1759.3726 - val_loss: 1765.2112\n",
      "Epoch 235/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1759.3547 - val_loss: 1768.9258\n",
      "Epoch 236/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1758.5453 - val_loss: 1766.1871\n",
      "Epoch 237/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1758.8826 - val_loss: 1765.5459\n",
      "Epoch 238/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1758.7502 - val_loss: 1766.4562\n",
      "Epoch 239/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1758.2921 - val_loss: 1765.4005\n",
      "Epoch 240/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1757.6050 - val_loss: 1765.8076\n",
      "Epoch 241/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1757.4006 - val_loss: 1766.5256\n",
      "Epoch 242/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1757.5013 - val_loss: 1764.9772\n",
      "Epoch 243/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1757.6233 - val_loss: 1769.9072\n",
      "Epoch 244/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1758.5022 - val_loss: 1767.6586\n",
      "Epoch 245/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.1720 - val_loss: 1770.5066\n",
      "Epoch 246/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1758.0283 - val_loss: 1765.5938\n",
      "Epoch 247/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1758.6705 - val_loss: 1766.1249\n",
      "Epoch 248/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1757.5509 - val_loss: 1765.8807\n",
      "Epoch 249/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1758.1222 - val_loss: 1768.1266\n",
      "Epoch 250/10000\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1757.7804 - val_loss: 1766.8372\n",
      "Epoch 251/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1757.8085 - val_loss: 1769.7389\n",
      "Epoch 252/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1759.0303 - val_loss: 1766.3124\n",
      "Epoch 253/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1758.3616 - val_loss: 1767.0243\n",
      "Epoch 254/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.9519 - val_loss: 1765.7542\n",
      "Epoch 255/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.6815 - val_loss: 1766.0970\n",
      "Epoch 256/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1756.9412 - val_loss: 1765.1576\n",
      "Epoch 257/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.9764 - val_loss: 1767.8854\n",
      "Epoch 258/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.9893 - val_loss: 1765.4053\n",
      "Epoch 259/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.9659 - val_loss: 1765.7783\n",
      "Epoch 260/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.3838 - val_loss: 1765.5776\n",
      "Epoch 261/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1756.1758 - val_loss: 1765.7343\n",
      "Epoch 262/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1756.4990 - val_loss: 1767.1948\n",
      "Epoch 263/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1756.6027 - val_loss: 1766.7319\n",
      "Epoch 264/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1755.8523 - val_loss: 1766.3055\n",
      "Epoch 265/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.9889 - val_loss: 1767.2015\n",
      "Epoch 266/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.3112 - val_loss: 1766.6353\n",
      "Epoch 267/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1756.7747 - val_loss: 1767.5402\n",
      "Epoch 268/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1757.1705 - val_loss: 1768.6984\n",
      "Epoch 269/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.7406 - val_loss: 1770.1177\n",
      "Epoch 270/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.3772 - val_loss: 1767.2844\n",
      "Epoch 271/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1756.5194 - val_loss: 1768.3159\n",
      "Epoch 272/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.3862 - val_loss: 1766.6527\n",
      "Epoch 273/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.3389 - val_loss: 1767.3525\n",
      "Epoch 274/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1756.7546 - val_loss: 1767.4001\n",
      "Epoch 275/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.8699 - val_loss: 1769.5588\n",
      "Epoch 276/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.4613 - val_loss: 1767.5792\n",
      "Epoch 277/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.3608 - val_loss: 1765.3865\n",
      "Epoch 278/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.8586 - val_loss: 1768.7661\n",
      "Epoch 279/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1756.4280 - val_loss: 1766.3409\n",
      "Epoch 280/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1756.0714 - val_loss: 1768.8477\n",
      "Epoch 281/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1756.3527 - val_loss: 1766.0461\n",
      "Epoch 282/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1756.1302 - val_loss: 1765.7521\n",
      "Epoch 283/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.6925 - val_loss: 1766.0219\n",
      "Epoch 284/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1755.3142 - val_loss: 1767.6431\n",
      "Epoch 285/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.8368 - val_loss: 1765.6937\n",
      "Epoch 286/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1754.9127 - val_loss: 1765.3273\n",
      "Epoch 287/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1754.7471 - val_loss: 1766.1594\n",
      "Epoch 288/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1754.3389 - val_loss: 1765.5610\n",
      "Epoch 289/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.3181 - val_loss: 1766.1173\n",
      "Epoch 290/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.7013 - val_loss: 1766.7887\n",
      "Epoch 291/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1755.4736 - val_loss: 1767.7424\n",
      "Epoch 292/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1756.3457 - val_loss: 1769.8394\n",
      "Epoch 293/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1757.0986 - val_loss: 1768.9706\n",
      "Epoch 294/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1757.4291 - val_loss: 1768.5778\n",
      "Epoch 295/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1755.6774 - val_loss: 1765.5640\n",
      "Epoch 296/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1755.6862 - val_loss: 1770.2354\n",
      "Epoch 297/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1756.1045 - val_loss: 1765.4921\n",
      "Epoch 298/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1755.7747 - val_loss: 1765.8345\n",
      "Epoch 299/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1754.9066 - val_loss: 1764.6028\n",
      "Epoch 300/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.2123 - val_loss: 1766.9098\n",
      "Epoch 301/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.5773 - val_loss: 1765.5328\n",
      "Epoch 302/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.9072 - val_loss: 1765.0615\n",
      "Epoch 303/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1754.3715 - val_loss: 1766.9614\n",
      "Epoch 304/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.6700 - val_loss: 1765.2694\n",
      "Epoch 305/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 37ms/step - loss: 1754.5538 - val_loss: 1767.5731\n",
      "Epoch 306/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1755.9388 - val_loss: 1765.6006\n",
      "Epoch 307/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1754.8297 - val_loss: 1766.4521\n",
      "Epoch 308/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1754.1509 - val_loss: 1764.5872\n",
      "Epoch 309/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1754.1182 - val_loss: 1766.2275\n",
      "Epoch 310/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.1326 - val_loss: 1766.8776\n",
      "Epoch 311/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1754.0078 - val_loss: 1765.6829\n",
      "Epoch 312/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.3209 - val_loss: 1766.5813\n",
      "Epoch 313/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.5175 - val_loss: 1767.0725\n",
      "Epoch 314/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.8333 - val_loss: 1765.8816\n",
      "Epoch 315/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1754.0850 - val_loss: 1764.8271\n",
      "Epoch 316/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1753.1855 - val_loss: 1766.5573\n",
      "Epoch 317/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1753.1104 - val_loss: 1765.5454\n",
      "Epoch 318/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1753.0914 - val_loss: 1765.1431\n",
      "Epoch 319/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1753.4180 - val_loss: 1765.7898\n",
      "Epoch 320/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.2615 - val_loss: 1765.6675\n",
      "Epoch 321/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1754.0928 - val_loss: 1765.8523\n",
      "Epoch 322/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1753.5499 - val_loss: 1766.5127\n",
      "Epoch 323/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1754.3274 - val_loss: 1764.2755\n",
      "Epoch 324/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1754.4733 - val_loss: 1766.5358\n",
      "Epoch 325/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.9673 - val_loss: 1765.2134\n",
      "Epoch 326/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1753.8076 - val_loss: 1765.2380\n",
      "Epoch 327/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1753.8580 - val_loss: 1765.3887\n",
      "Epoch 328/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.8792 - val_loss: 1766.0139\n",
      "Epoch 329/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1753.6689 - val_loss: 1765.6768\n",
      "Epoch 330/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1753.5272 - val_loss: 1764.9976\n",
      "Epoch 331/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1752.8966 - val_loss: 1764.6293\n",
      "Epoch 332/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.0312 - val_loss: 1765.0479\n",
      "Epoch 333/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1751.9117 - val_loss: 1766.0615\n",
      "Epoch 334/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1751.7300 - val_loss: 1763.7679\n",
      "Epoch 335/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1752.6588 - val_loss: 1766.3108\n",
      "Epoch 336/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1753.0021 - val_loss: 1763.3907\n",
      "Epoch 337/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1752.1182 - val_loss: 1764.9668\n",
      "Epoch 338/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.0321 - val_loss: 1764.5687\n",
      "Epoch 339/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1753.0006 - val_loss: 1767.0103\n",
      "Epoch 340/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1753.3285 - val_loss: 1765.7159\n",
      "Epoch 341/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1753.1517 - val_loss: 1763.1740\n",
      "Epoch 342/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1753.6216 - val_loss: 1764.0634\n",
      "Epoch 343/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1753.0341 - val_loss: 1766.0172\n",
      "Epoch 344/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1753.8104 - val_loss: 1766.4927\n",
      "Epoch 345/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1753.7306 - val_loss: 1766.1094\n",
      "Epoch 346/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1754.4932 - val_loss: 1764.7841\n",
      "Epoch 347/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1753.1780 - val_loss: 1764.2378\n",
      "Epoch 348/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1752.4957 - val_loss: 1766.6729\n",
      "Epoch 349/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1752.5135 - val_loss: 1764.0618\n",
      "Epoch 350/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1751.1006 - val_loss: 1764.0879\n",
      "Epoch 351/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1751.3982 - val_loss: 1763.6566\n",
      "Epoch 352/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1751.9952 - val_loss: 1764.2578\n",
      "Epoch 353/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1751.1680 - val_loss: 1764.2583\n",
      "Epoch 354/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1752.2954 - val_loss: 1764.4955\n",
      "Epoch 355/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1751.9779 - val_loss: 1765.0958\n",
      "Epoch 356/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1752.2196 - val_loss: 1765.1986\n",
      "Epoch 357/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1752.7422 - val_loss: 1765.6886\n",
      "Epoch 358/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1751.3895 - val_loss: 1765.4006\n",
      "Epoch 359/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1750.9618 - val_loss: 1764.2882\n",
      "Epoch 360/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1751.7356 - val_loss: 1763.7000\n",
      "Epoch 361/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1751.5479 - val_loss: 1763.7782\n",
      "Epoch 362/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1751.3926 - val_loss: 1766.1913\n",
      "Epoch 363/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1751.9790 - val_loss: 1763.7167\n",
      "Epoch 364/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1751.5573 - val_loss: 1764.8483\n",
      "Epoch 365/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1750.8569 - val_loss: 1765.5078\n",
      "Epoch 366/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1752.7136 - val_loss: 1767.7314\n",
      "Epoch 367/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1753.3669 - val_loss: 1764.8060\n",
      "Epoch 368/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1753.0245 - val_loss: 1764.8188\n",
      "Epoch 369/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1752.7891 - val_loss: 1767.2377\n",
      "Epoch 370/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1752.6597 - val_loss: 1765.0322\n",
      "Epoch 371/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1752.4735 - val_loss: 1764.6207\n",
      "Epoch 372/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1752.2717 - val_loss: 1764.6699\n",
      "Epoch 373/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1751.0342 - val_loss: 1765.0521\n",
      "Epoch 374/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1750.0596 - val_loss: 1764.5601\n",
      "Epoch 375/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1749.9760 - val_loss: 1763.2072\n",
      "Epoch 376/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1749.7881 - val_loss: 1765.6403\n",
      "Epoch 377/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1750.6727 - val_loss: 1765.3691\n",
      "Epoch 378/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1750.3478 - val_loss: 1764.0752\n",
      "Epoch 379/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1750.5785 - val_loss: 1765.1143\n",
      "Epoch 380/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1750.6021 - val_loss: 1764.6543\n",
      "Epoch 381/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 38ms/step - loss: 1750.9148 - val_loss: 1763.8661\n",
      "Epoch 382/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1750.7087 - val_loss: 1763.8689\n",
      "Epoch 383/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1750.2369 - val_loss: 1764.0972\n",
      "Epoch 384/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1749.7045 - val_loss: 1766.1509\n",
      "Epoch 385/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1750.6299 - val_loss: 1763.4497\n",
      "Epoch 386/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1749.3813 - val_loss: 1764.4247\n",
      "Epoch 387/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1749.5566 - val_loss: 1764.7150\n",
      "Epoch 388/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1749.5013 - val_loss: 1763.8805\n",
      "Epoch 389/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1749.6731 - val_loss: 1764.4420\n",
      "Epoch 390/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1749.9689 - val_loss: 1763.7952\n",
      "Epoch 391/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1750.5619 - val_loss: 1765.4320\n",
      "Epoch 392/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1751.2607 - val_loss: 1763.0887\n",
      "Epoch 393/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1750.8260 - val_loss: 1763.1106\n",
      "Epoch 394/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1750.6125 - val_loss: 1762.9452\n",
      "Epoch 395/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1749.7084 - val_loss: 1765.0315\n",
      "Epoch 396/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1749.8123 - val_loss: 1762.5632\n",
      "Epoch 397/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1749.2645 - val_loss: 1765.6520\n",
      "Epoch 398/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1750.9863 - val_loss: 1762.7562\n",
      "Epoch 399/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1750.0958 - val_loss: 1764.4742\n",
      "Epoch 400/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1749.4414 - val_loss: 1762.7566\n",
      "Epoch 401/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1749.3628 - val_loss: 1762.6937\n",
      "Epoch 402/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1749.1958 - val_loss: 1764.7416\n",
      "Epoch 403/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1750.4232 - val_loss: 1762.6396\n",
      "Epoch 404/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1749.1320 - val_loss: 1764.2388\n",
      "Epoch 405/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1748.8726 - val_loss: 1764.6106\n",
      "Epoch 406/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1750.4780 - val_loss: 1765.4200\n",
      "Epoch 407/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1753.7888 - val_loss: 1766.9512\n",
      "Epoch 408/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1755.0551 - val_loss: 1765.0289\n",
      "Epoch 409/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1753.9489 - val_loss: 1763.4755\n",
      "Epoch 410/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1752.4172 - val_loss: 1764.5503\n",
      "Epoch 411/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1751.8971 - val_loss: 1765.9232\n",
      "Epoch 412/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1752.2057 - val_loss: 1763.7235\n",
      "Epoch 413/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1752.0403 - val_loss: 1764.1176\n",
      "Epoch 414/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1752.0150 - val_loss: 1766.2795\n",
      "Epoch 415/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1751.8751 - val_loss: 1763.7936\n",
      "Epoch 416/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1751.8209 - val_loss: 1764.1641\n",
      "Epoch 417/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1750.8350 - val_loss: 1764.8514\n",
      "Epoch 418/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1749.6992 - val_loss: 1764.0610\n",
      "Epoch 419/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1749.9303 - val_loss: 1765.6028\n",
      "Epoch 420/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1749.5950 - val_loss: 1764.0978\n",
      "Epoch 421/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1749.7019 - val_loss: 1763.2388\n",
      "Epoch 422/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1749.8645 - val_loss: 1765.8885\n",
      "Epoch 423/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1749.7773 - val_loss: 1764.9146\n",
      "Epoch 424/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1750.3853 - val_loss: 1763.4333\n",
      "Epoch 425/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1750.9246 - val_loss: 1761.8971\n",
      "Epoch 426/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1750.1992 - val_loss: 1762.8242\n",
      "Epoch 427/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1750.0997 - val_loss: 1765.4718\n",
      "Epoch 428/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1751.3156 - val_loss: 1764.6882\n",
      "Epoch 429/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1750.8772 - val_loss: 1762.3436\n",
      "Epoch 430/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1750.6388 - val_loss: 1764.6005\n",
      "Epoch 431/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1750.2911 - val_loss: 1765.0366\n",
      "Epoch 432/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1749.4279 - val_loss: 1762.2362\n",
      "Epoch 433/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1748.7080 - val_loss: 1762.3792\n",
      "Epoch 434/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1748.0394 - val_loss: 1761.0038\n",
      "Epoch 435/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1748.5654 - val_loss: 1762.5848\n",
      "Epoch 436/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1749.3712 - val_loss: 1762.9963\n",
      "Epoch 437/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1748.8641 - val_loss: 1761.8123\n",
      "Epoch 438/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1748.1104 - val_loss: 1762.0977\n",
      "Epoch 439/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1748.1687 - val_loss: 1762.1208\n",
      "Epoch 440/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1748.3940 - val_loss: 1764.0739\n",
      "Epoch 441/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1748.1750 - val_loss: 1762.1805\n",
      "Epoch 442/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1747.8298 - val_loss: 1760.6500\n",
      "Epoch 443/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1747.7898 - val_loss: 1761.3777\n",
      "Epoch 444/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1747.2087 - val_loss: 1760.7246\n",
      "Epoch 445/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1747.5508 - val_loss: 1762.5912\n",
      "Epoch 446/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1747.8558 - val_loss: 1763.3158\n",
      "Epoch 447/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1747.7467 - val_loss: 1763.7729\n",
      "Epoch 448/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1746.4167 - val_loss: 1761.0406\n",
      "Epoch 449/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1747.4407 - val_loss: 1765.2253\n",
      "Epoch 450/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1748.1278 - val_loss: 1766.5310\n",
      "Epoch 451/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1750.4606 - val_loss: 1768.4888\n",
      "Epoch 452/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1750.1953 - val_loss: 1764.6617\n",
      "Epoch 453/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1750.6063 - val_loss: 1765.9780\n",
      "Epoch 454/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1749.2949 - val_loss: 1764.2073\n",
      "Epoch 455/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1748.1090 - val_loss: 1763.7107\n",
      "Epoch 456/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1748.4583 - val_loss: 1761.6719\n",
      "Epoch 457/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 34ms/step - loss: 1748.5031 - val_loss: 1761.8490\n",
      "Epoch 458/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1748.4325 - val_loss: 1765.1379\n",
      "Epoch 459/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1748.1025 - val_loss: 1761.4463\n",
      "Epoch 460/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1747.9000 - val_loss: 1761.7778\n",
      "Epoch 461/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1747.1572 - val_loss: 1763.1738\n",
      "Epoch 462/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1747.0627 - val_loss: 1763.0612\n",
      "Epoch 463/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1747.1991 - val_loss: 1759.7728\n",
      "Epoch 464/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1746.8662 - val_loss: 1761.3718\n",
      "Epoch 465/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1746.9904 - val_loss: 1761.9332\n",
      "Epoch 466/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1747.6462 - val_loss: 1763.0480\n",
      "Epoch 467/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1747.5635 - val_loss: 1763.8606\n",
      "Epoch 468/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1747.3738 - val_loss: 1762.1183\n",
      "Epoch 469/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1748.5249 - val_loss: 1761.5675\n",
      "Epoch 470/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1747.4761 - val_loss: 1762.3010\n",
      "Epoch 471/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1748.1093 - val_loss: 1760.9417\n",
      "Epoch 472/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1747.2843 - val_loss: 1761.2106\n",
      "Epoch 473/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1746.9873 - val_loss: 1763.8965\n",
      "Epoch 474/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1747.5997 - val_loss: 1764.9117\n",
      "Epoch 475/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1747.2054 - val_loss: 1765.0460\n",
      "Epoch 476/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1746.9862 - val_loss: 1761.3125\n",
      "Epoch 477/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1746.4772 - val_loss: 1761.8052\n",
      "Epoch 478/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1745.9667 - val_loss: 1761.6010\n",
      "Epoch 479/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1744.9028 - val_loss: 1761.1084\n",
      "Epoch 480/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1745.6294 - val_loss: 1763.2856\n",
      "Epoch 481/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.9363 - val_loss: 1765.0222\n",
      "Epoch 482/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1746.0585 - val_loss: 1764.8525\n",
      "Epoch 483/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1745.2744 - val_loss: 1763.2993\n",
      "Epoch 484/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1745.0461 - val_loss: 1763.8835\n",
      "Epoch 485/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.8545 - val_loss: 1763.6802\n",
      "Epoch 486/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1745.7881 - val_loss: 1762.7808\n",
      "Epoch 487/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.3046 - val_loss: 1763.0448\n",
      "Epoch 488/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.8958 - val_loss: 1764.4075\n",
      "Epoch 489/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1745.1650 - val_loss: 1762.4677\n",
      "Epoch 490/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1745.5642 - val_loss: 1762.9708\n",
      "Epoch 491/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1746.0901 - val_loss: 1766.4625\n",
      "Epoch 492/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1745.4209 - val_loss: 1763.3953\n",
      "Epoch 493/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1745.0685 - val_loss: 1765.1820\n",
      "Epoch 494/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1744.8458 - val_loss: 1762.1875\n",
      "Epoch 495/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1745.3048 - val_loss: 1763.4681\n",
      "Epoch 496/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.9261 - val_loss: 1765.9122\n",
      "Epoch 497/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1746.6525 - val_loss: 1766.1310\n",
      "Epoch 498/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1746.2372 - val_loss: 1764.3770\n",
      "Epoch 499/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1746.2169 - val_loss: 1765.2761\n",
      "Epoch 500/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.8988 - val_loss: 1762.8909\n",
      "Epoch 501/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1746.1367 - val_loss: 1761.7921\n",
      "Epoch 502/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1745.5596 - val_loss: 1763.5956\n",
      "Epoch 503/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.8627 - val_loss: 1764.0040\n",
      "Epoch 504/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.2830 - val_loss: 1761.5992\n",
      "Epoch 505/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.5375 - val_loss: 1762.7249\n",
      "Epoch 506/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1745.0056 - val_loss: 1762.8872\n",
      "Epoch 507/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1746.0439 - val_loss: 1762.6841\n",
      "Epoch 508/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1745.8053 - val_loss: 1761.7214\n",
      "Epoch 509/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1745.0449 - val_loss: 1761.7576\n",
      "Epoch 510/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1744.5830 - val_loss: 1763.4072\n",
      "Epoch 511/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1745.8617 - val_loss: 1763.0399\n",
      "Epoch 512/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1745.9038 - val_loss: 1762.8308\n",
      "Epoch 513/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1744.5115 - val_loss: 1764.8245\n",
      "Epoch 514/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1744.3293 - val_loss: 1763.8420\n",
      "Epoch 515/10000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1744.8894 - val_loss: 1763.3185\n",
      "Epoch 516/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.9962 - val_loss: 1765.5020\n",
      "Epoch 517/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1746.4363 - val_loss: 1768.3724\n",
      "Epoch 518/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1748.8160 - val_loss: 1763.8685\n",
      "Epoch 519/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1748.0988 - val_loss: 1762.7954\n",
      "Epoch 520/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1747.9238 - val_loss: 1762.3270\n",
      "Epoch 521/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1747.3917 - val_loss: 1762.3031\n",
      "Epoch 522/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1747.0979 - val_loss: 1764.3988\n",
      "Epoch 523/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1747.2217 - val_loss: 1760.8982\n",
      "Epoch 524/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1746.5846 - val_loss: 1762.6571\n",
      "Epoch 525/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1745.6154 - val_loss: 1764.7694\n",
      "Epoch 526/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1745.8516 - val_loss: 1765.0812\n",
      "Epoch 527/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1744.7994 - val_loss: 1764.3339\n",
      "Epoch 528/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1744.8254 - val_loss: 1765.1807\n",
      "Epoch 529/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1745.7469 - val_loss: 1764.5205\n",
      "Epoch 530/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1746.5295 - val_loss: 1764.0804\n",
      "Epoch 531/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1746.3192 - val_loss: 1765.4071\n",
      "Epoch 532/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1746.3881 - val_loss: 1765.0557\n",
      "Epoch 533/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 35ms/step - loss: 1745.2522 - val_loss: 1764.9774\n",
      "Epoch 534/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1745.8623 - val_loss: 1764.8984\n",
      "Epoch 535/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1744.6475 - val_loss: 1764.1250\n",
      "Epoch 536/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.4287 - val_loss: 1764.6903\n",
      "Epoch 537/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1743.5334 - val_loss: 1764.3693\n",
      "Epoch 538/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1743.4086 - val_loss: 1763.5886\n",
      "Epoch 539/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1743.8644 - val_loss: 1764.1444\n",
      "Epoch 540/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1744.3698 - val_loss: 1762.9016\n",
      "Epoch 541/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1743.9797 - val_loss: 1762.9458\n",
      "Epoch 542/10000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1744.2830 - val_loss: 1762.8429\n",
      "Epoch 543/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.2732 - val_loss: 1764.5825\n",
      "Epoch 544/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1743.8761 - val_loss: 1767.4568\n",
      "Epoch 545/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.4420 - val_loss: 1764.2821\n",
      "Epoch 546/10000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1744.6356 - val_loss: 1763.8049\n",
      "Epoch 547/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.4072 - val_loss: 1764.3160\n",
      "Epoch 548/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1743.8236 - val_loss: 1764.1334\n",
      "Epoch 549/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1743.6949 - val_loss: 1763.5209\n",
      "Epoch 550/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.1816 - val_loss: 1763.4604\n",
      "Epoch 551/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.5522 - val_loss: 1764.0769\n",
      "Epoch 552/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.1429 - val_loss: 1765.7079\n",
      "Epoch 553/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1743.6099 - val_loss: 1764.4847\n",
      "Epoch 554/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1744.0602 - val_loss: 1765.8230\n",
      "Epoch 555/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1743.9316 - val_loss: 1762.4971\n",
      "Epoch 556/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1743.6049 - val_loss: 1764.3247\n",
      "Epoch 557/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1743.1602 - val_loss: 1767.7800\n",
      "Epoch 558/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1743.8571 - val_loss: 1762.6013\n",
      "Epoch 559/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1742.7185 - val_loss: 1767.3422\n",
      "Epoch 560/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1744.0583 - val_loss: 1765.2800\n",
      "Epoch 561/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1742.6783 - val_loss: 1766.1722\n",
      "Epoch 562/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1741.8862 - val_loss: 1765.3197\n",
      "Epoch 563/10000\n",
      "9/9 [==============================] - ETA: 0s - loss: 1742.4070Restoring model weights from the end of the best epoch: 463.\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1742.4070 - val_loss: 1767.6686\n",
      "Epoch 563: early stopping\n"
     ]
    }
   ],
   "source": [
    "fpmodel_history=fpmodel.fit([x_train, inputs2decoder_train], x_train, batch_size = BATCH_SIZE, epochs=10000, \n",
    "          callbacks = lfadfp_callbacks,\n",
    "          validation_data=([x_val, inputs2decoder_val], x_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cba05b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgdUlEQVR4nO3deXwU5eE/8M/svTl2QwhJCDkIhCtcCiIGFEGQIJFKpfVChQLikaiAJ7YqYmusrTeKtvYr9mcpKopS7kggKoYblDPchGuTQJLdnHs+vz8mGbIcEiDJLO7n/Xrty+zMs7PPTFb2k+caSQghQERERBTENGpXgIiIiEhtDEREREQU9BiIiIiIKOgxEBEREVHQYyAiIiKioMdAREREREGPgYiIiIiCHgMRERERBT0GIiIiIgp6DEREdFE2bNiAAQMGIDQ0FJIkYevWrWpX6bLNmDEDkiRd0mvHjx+P9u3bX7Dc4MGDMXjw4Et6DyJqfjq1K0BEVw63243f//73MJlMePPNNxESEoKkpCS1q0VEdNkYiIio0fbv34/Dhw/jn//8JyZNmqR2dYiImgy7zIio0YqLiwEAERER6laEiKiJMRARUaOMHz8eN954IwDg97//PSRJUsbEjB8/HmFhYThw4ADS09MRGhqKuLg4zJw5E0KICx67ffv2uPXWW7F69Wpcc801MJvN6NmzJ1avXg0A+Oqrr9CzZ0+YTCb07dsXW7ZsOesYubm5uOGGGxAaGoqIiAjcdttt2LVr11nlfvjhB/Tr1w8mkwkdO3bEhx9+eN56ffrpp+jbty/MZjMiIyNx11134ciRI424Wo1TXFyMiRMnIiYmBiaTCb1798Ynn3xyVrl58+ahb9++CA8Ph8ViQc+ePfH2228r+91uN1566SV06tQJJpMJrVu3xvXXX4+cnJwmqyvRrx27zIioUR588EG0a9cOr7zyCh577DH069cPMTExyn6v14sRI0bguuuuw2uvvYZly5bhxRdfhMfjwcyZMy94/H379uGee+7Bgw8+iHvvvRd///vfMWrUKHzwwQd47rnn8MgjjwAAsrOzcccdd6CgoAAajfw33bfffotbbrkFHTp0wIwZM1BTU4N3330XAwcOxObNm5VBz9u2bcPw4cPRpk0bzJgxAx6PBy+++KLfedT7y1/+gueffx533HEHJk2ahJKSErz77rsYNGgQtmzZctmtZDU1NRg8eDD27duHrKwsJCcn44svvsD48eNRXl6Oxx9/HACQk5ODu+++G0OHDsVf//pXAMCuXbuwZs0apcyMGTOQnZ2NSZMm4dprr4XD4cDGjRuxefNm3HzzzZdVT6KgIYiIGmnVqlUCgPjiiy/8to8bN04AEI8++qiyzefziYyMDGEwGERJSckvHjcpKUkAED/++KOybfny5QKAMJvN4vDhw8r2Dz/8UAAQq1atUrZdddVVIjo6Wpw6dUrZ9tNPPwmNRiPuv/9+Zdvo0aOFyWTyO97OnTuFVqsVDf85PHTokNBqteIvf/mLXz23bdsmdDqd3/Zx48aJpKSkXzw/IYS48cYbxY033qg8f+uttwQA8emnnyrbXC6XSEtLE2FhYcLhcAghhHj88ceFxWIRHo/nvMfu3bu3yMjIuGAdiOj82GVGRE0mKytL+VmSJGRlZcHlcuHbb7+94GtTU1ORlpamPO/fvz8A4KabbkJiYuJZ2w8cOAAAOHHiBLZu3Yrx48cjMjJSKderVy/cfPPNWLJkCQC5BWv58uUYPXq03/G6deuG9PR0v7p89dVX8Pl8uOOOO3Dy5EnlERsbi06dOmHVqlWNvibns2TJEsTGxuLuu+9Wtun1ejz22GOorKxEXl4eAHm8VlVV1S92f0VERGDHjh3Yu3fvZdeLKFgxEBFRk9BoNOjQoYPfts6dOwMADh06dMHXNwwpAGC1WgEACQkJ59xeVlYGADh8+DAAoEuXLmcds1u3bjh58iSqqqpQUlKCmpoadOrU6axyZ7527969EEKgU6dOaNOmjd9j165dyuDyy3H48GF06tRJ6fZrWOeG5/XII4+gc+fOuOWWWxAfH48JEyZg2bJlfq+ZOXMmysvL0blzZ/Ts2RNPPfUUfv7558uuI1Ew4RgiIgoIWq32oraLRgzWvlQ+nw+SJGHp0qXnfP+wsLBme+8zRUdHY+vWrVi+fDmWLl2KpUuX4uOPP8b999+vDMAeNGgQ9u/fj2+++QYrVqzARx99hDfffBMffPABl0cgaiQGIiJqEj6fDwcOHFBahQBgz549ANColZwvVf3CkAUFBWft2717N6KiohAaGgqTyQSz2XzObqUzX9uxY0cIIZCcnOx3Pk1d759//hk+n8+vlWj37t3K/noGgwGjRo3CqFGj4PP58Mgjj+DDDz/E888/j5SUFABAZGQk/vCHP+APf/gDKisrMWjQIMyYMYOBiKiR2GVGRE1m1qxZys9CCMyaNQt6vR5Dhw5ttvds27YtrrrqKnzyyScoLy9Xtm/fvh0rVqzAyJEjAcgtTenp6fj6669RWFiolNu1axeWL1/ud8zbb78dWq0WL7300lktUUIInDp16rLrPXLkSNhsNnz22WfKNo/Hg3fffRdhYWHKEgdnvpdGo0GvXr0AAE6n85xlwsLCkJKSouwnogtjCxERNQmTyYRly5Zh3Lhx6N+/P5YuXYrFixfjueeeQ5s2bZr1vf/2t7/hlltuQVpaGiZOnKhMu7darZgxY4ZS7qWXXsKyZctwww034JFHHlECSPfu3f3G3HTs2BF//vOfMX36dBw6dAijR49GeHg4Dh48iAULFmDy5Ml48sknL6vOkydPxocffojx48dj06ZNaN++PebPn481a9bgrbfeQnh4OABg0qRJKC0txU033YT4+HgcPnwY7777Lq666iplvFFqaioGDx6Mvn37IjIyEhs3bsT8+fP9BrkT0QWoOcWNiK4svzTtPjQ0VOzfv18MHz5chISEiJiYGPHiiy8Kr9d7weMmJSWdc9o4AJGZmem37eDBgwKA+Nvf/ua3/dtvvxUDBw4UZrNZWCwWMWrUKLFz586zjpmXlyf69u0rDAaD6NChg/jggw/Eiy++KM71z+GXX34prr/+ehEaGipCQ0NF165dRWZmpigoKPA790uZdi+EEEVFReIPf/iDiIqKEgaDQfTs2VN8/PHHfmXmz58vhg8fLqKjo4XBYBCJiYniwQcfFCdOnFDK/PnPfxbXXnutiIiIEGazWXTt2lX85S9/ES6X64L1IiKZJEQzjkwkoqAwfvx4zJ8/H5WVlWpXhYjoknAMEREREQU9BiIiIiIKegxEREREFPQ4hoiIiIiCHluIiIiIKOgxEBEREVHQ48KMjeTz+XD8+HGEh4dDkiS1q0NERESNIIRARUUF4uLizrqZckMMRI10/Pjxs+66TURERFeGI0eOID4+/rz7GYgaqX4Z/SNHjsBisahcGyIiImoMh8OBhIQE5Xv8fBiIGqm+m8xisTAQERERXWEuNNyFg6qJiIgo6DEQERERUdBjICIiIqKgxzFETcjr9cLtdqtdjSuSXq+HVqtVuxpERBSkGIiagBACNpsN5eXlalflihYREYHY2Fiu80RERC2OgagJ1Ieh6OhohISE8Av9IgkhUF1djeLiYgBA27ZtVa4REREFGwaiy+T1epUw1Lp1a7Wrc8Uym80AgOLiYkRHR7P7jIiIWhQHVV+m+jFDISEhKtfkyld/DTkOi4iIWhoDURNhN9nl4zUkIiK1MBARERFR0FM1EM2ePRu9evVSboeRlpaGpUuXKvtra2uRmZmJ1q1bIywsDGPGjEFRUZHfMQoLC5GRkYGQkBBER0fjqaeegsfj8SuzevVq9OnTB0ajESkpKZgzZ05LnF5Qad++Pd566y21q0FERHRJVA1E8fHxePXVV7Fp0yZs3LgRN910E2677Tbs2LEDADB16lT873//wxdffIG8vDwcP34ct99+u/J6r9eLjIwMuFwu/Pjjj/jkk08wZ84cvPDCC0qZgwcPIiMjA0OGDMHWrVsxZcoUTJo0CcuXL2/x8w00gwcPxpQpU5rkWBs2bMDkyZOb5FhEREQtTgSYVq1aiY8++kiUl5cLvV4vvvjiC2Xfrl27BACRn58vhBBiyZIlQqPRCJvNppSZPXu2sFgswul0CiGEePrpp0X37t393uPOO+8U6enpF1Uvu90uAAi73e63vaamRuzcuVPU1NRc1PHqOd1e4XR7hM/nu6TXX44bb7xRPP744+fd7/P5hNvtbrH6XO61JCIiOtP5vr/PFDBjiLxeL+bNm4eqqiqkpaVh06ZNcLvdGDZsmFKma9euSExMRH5+PgAgPz8fPXv2RExMjFImPT0dDodDaWXKz8/3O0Z9mfpjnI/T6YTD4fB7NIeCogrstlXA7RXNcvzzGT9+PPLy8vD2229DkiRIkoQ5c+ZAkiQsXboUffv2hdFoxA8//ID9+/fjtttuQ0xMDMLCwtCvXz98++23fsc7s8tMkiR89NFH+O1vf4uQkBB06tQJCxcubNFzJCIiaizVA9G2bdsQFhYGo9GIhx56CAsWLEBqaipsNhsMBgMiIiL8ysfExMBmswGQF0RsGIbq99fv+6UyDocDNTU1561XdnY2rFar8khISGj0OQkhUO3yNOrhdHtR6/Y2uvyFHkI0Lli9/fbbSEtLwwMPPIATJ07gxIkTyjk+++yzePXVV7Fr1y706tULlZWVGDlyJFauXIktW7ZgxIgRGDVqFAoLC3/xPV566SXccccd+PnnnzFy5EiMHTsWpaWljb6ORERELUX1hRm7dOmCrVu3wm63Y/78+Rg3bhzy8vLUrhamT5+OadOmKc8dDkejQ1GN24vUF9QZo7RzZjpCDBf+tVqtVhgMBoSEhCA2NhYAsHv3bgDAzJkzcfPNNytlIyMj0bt3b+X5yy+/jAULFmDhwoXIyso673uMHz8ed999NwDglVdewTvvvIP169djxIgRl3RuREREzUX1QGQwGJCSkgIA6Nu3LzZs2IC3334bd955J1wuF8rLy/1aiYqKipQv8NjYWKxfv97vePWz0BqWOXNmWlFRESwWi7I68rkYjUYYjcbLPr8r0TXXXOP3vLKyEjNmzMDixYtx4sQJeDwe1NTUXLCFqFevXsrPoaGhsFgsyu05iIiIAonqgehMPp8PTqcTffv2hV6vx8qVKzFmzBgAQEFBAQoLC5GWlgYASEtLw1/+8hfldg8AkJOTA4vFgtTUVKXMkiVL/N4jJydHOUZzMOu12DkzvVFldx13wCsEOkWHwai//NtVmJvgGKGhoX7Pn3zySeTk5ODvf/87UlJSYDab8bvf/Q4ul+sXj6PX6/2eS5IEn8932fUjIiJqaqoGounTp+OWW25BYmIiKioqMHfuXKxevRrLly+H1WrFxIkTMW3aNERGRsJiseDRRx9FWloarrvuOgDA8OHDkZqaivvuuw+vvfYabDYb/vSnPyEzM1Np3XnooYcwa9YsPP3005gwYQJyc3Px+eefY/Hixc12XpIkNarbCgBMBi28PoEQg65JAtHFMBgM8Hq9Fyy3Zs0ajB8/Hr/97W8ByC1Ghw4daubaERERtRxVA1FxcTHuv/9+nDhxAlarFb169cLy5cuV8StvvvkmNBoNxowZA6fTifT0dLz//vvK67VaLRYtWoSHH34YaWlpCA0Nxbhx4zBz5kylTHJyMhYvXoypU6fi7bffRnx8PD766COkpzeuBaeltOwcM1n79u2xbt06HDp0CGFhYedtvenUqRO++uorjBo1CpIk4fnnn2dLDxER/aqoGoj+9a9//eJ+k8mE9957D++99955yyQlJZ3VJXamwYMHY8uWLZdUx+YmQYI6cUjuChs3bhxSU1NRU1ODjz/++Jzl3njjDUyYMAEDBgxAVFQUnnnmmWZbhoCIiEgNkmjsPO0g53A4YLVaYbfbYbFYlO21tbU4ePAgkpOTYTKZLvq4O4874PH50DkmHKYW7jILNJd7LYmIiM50vu/vM6m+DlHQq7vBO2MpERGRehiIVCYpPzERERERqYWBiIiIiIIeA5HK6luI2D5ERESkHgYiIiIiCnoMRGrjoGoiIiLVMRCpTLpwESIiImpmDESqYyQiIiJSGwNRgGCPGRERkXoYiFSmtA9dgYmoffv2eOutt9SuBhER0WVjIFLblZyIiIiIfiUYiAIE4xAREZF6GIhUptaQ6n/84x+Ii4uDz+fz237bbbdhwoQJ2L9/P2677TbExMQgLCwM/fr1w7fffqtSbYmIiJoXA1FzEAJwVTXqIbmrIbmrIRpZ/oKPRi5o9Pvf/x6nTp3CqlWrlG2lpaVYtmwZxo4di8rKSowcORIrV67Eli1bMGLECIwaNQqFhYXNddWIiIhUo1O7Ar9K7mrglbhGFU1p6vd+7jhgCL1gsVatWuGWW27B3LlzMXToUADA/PnzERUVhSFDhkCj0aB3795K+ZdffhkLFizAwoULkZWV1dS1JiIiUhVbiILY2LFj8eWXX8LpdAIA/vOf/+Cuu+6CRqNBZWUlnnzySXTr1g0REREICwvDrl272EJERES/Smwhag76ELmlphH2l1Sh2uVBYmQIrGZ907x3I40aNQpCCCxevBj9+vXD999/jzfffBMA8OSTTyInJwd///vfkZKSArPZjN/97ndwuVyXX0ciIqIAw0DUHCSpUd1WACD0AkJ45PKGJghEF8FkMuH222/Hf/7zH+zbtw9dunRBnz59AABr1qzB+PHj8dvf/hYAUFlZiUOHDrVo/YiIiFoKA5HKTi9DpM7E+7Fjx+LWW2/Fjh07cO+99yrbO3XqhK+++gqjRo2CJEl4/vnnz5qRRkRE9GvBMURqq7/bvUpvf9NNNyEyMhIFBQW45557lO1vvPEGWrVqhQEDBmDUqFFIT09XWo+IiIh+bdhCFOQ0Gg2OHz97vFP79u2Rm5vrty0zM9PvObvQiIjo14ItRCrjve6JiIjUx0AUIHjrDiIiIvUwEKlMklQeREREREQMRIGCeYiIiEg9DERNRFzitHmOITrtUq8hERHR5WIgukx6vbyYYnV19WUeiWGg/hrWX1MiIqKWwmn3l0mr1SIiIgLFxcUAgJCQkNPjghrB63ZCeDxwOjWo1QZnKBJCoLq6GsXFxYiIiIBWq1W7SkREFGQYiJpAbGwsACih6GKcqnSixu2Du1yPcmNw/zoiIiKUa0lERNSSgvsbuIlIkoS2bdsiOjoabrf7ol77ycId+H5vCR4b2gm3dW3XTDUMfHq9ni1DRESkGgaiJqTVai/6S73CLeFYhRdOoYXJZGqmmhEREdEv4aBqldUPN/L5gnP8EBERUSBgIFKZpi4RMQ8RERGph4FIZZr6FiKuwUNERKQaBiKV1bcQMQ8RERGph4FIZZLSZcZEREREpBYGIpWd7jJTtx5ERETBjIFIZRq2EBEREamOgUhlmrrfAG9sSkREpB4GIpVJnHZPRESkOgYilXHaPRERkfpUDUTZ2dno168fwsPDER0djdGjR6OgoMCvjM1mw3333YfY2FiEhoaiT58++PLLL/3KlJaWYuzYsbBYLIiIiMDEiRNRWVnpV+bnn3/GDTfcAJPJhISEBLz22mvNfn6NoYwhYhMRERGRalQNRHl5ecjMzMTatWuRk5MDt9uN4cOHo6qqSilz//33o6CgAAsXLsS2bdtw++2344477sCWLVuUMmPHjsWOHTuQk5ODRYsW4bvvvsPkyZOV/Q6HA8OHD0dSUhI2bdqEv/3tb5gxYwb+8Y9/tOj5ngtXqiYiIgoAIoAUFxcLACIvL0/ZFhoaKv7973/7lYuMjBT//Oc/hRBC7Ny5UwAQGzZsUPYvXbpUSJIkjh07JoQQ4v333xetWrUSTqdTKfPMM8+ILl26NLpudrtdABB2u/2Szu18ZizcLpKeWST+unRXkx6XiIiIGv/9HVBjiOx2OwAgMjJS2TZgwAB89tlnKC0thc/nw7x581BbW4vBgwcDAPLz8xEREYFrrrlGec2wYcOg0Wiwbt06pcygQYNgMBiUMunp6SgoKEBZWVkLnNn5sYWIiIhIfTq1K1DP5/NhypQpGDhwIHr06KFs//zzz3HnnXeidevW0Ol0CAkJwYIFC5CSkgJAHmMUHR3tdyydTofIyEjYbDalTHJysl+ZmJgYZV+rVq3Oqo/T6YTT6VSeOxyOpjnRM9QPqhYcVE1ERKSagGkhyszMxPbt2zFv3jy/7c8//zzKy8vx7bffYuPGjZg2bRruuOMObNu2rVnrk52dDavVqjwSEhKa5X24MCMREZH6AqKFKCsrSxkMHR8fr2zfv38/Zs2ahe3bt6N79+4AgN69e+P777/He++9hw8++ACxsbEoLi72O57H40FpaSliY2MBALGxsSgqKvIrU/+8vsyZpk+fjmnTpinPHQ5Hs4QirkNERESkPlVbiIQQyMrKwoIFC5Cbm3tWt1Z1dTUAQKPxr6ZWq4XP5wMApKWloby8HJs2bVL25+bmwufzoX///kqZ7777Dm63WymTk5ODLl26nLO7DACMRiMsFovfozlwHSIiIiL1qRqIMjMz8emnn2Lu3LkIDw+HzWaDzWZDTU0NAKBr165ISUnBgw8+iPXr12P//v14/fXXkZOTg9GjRwMAunXrhhEjRuCBBx7A+vXrsWbNGmRlZeGuu+5CXFwcAOCee+6BwWDAxIkTsWPHDnz22Wd4++23/VqA1FLfZcY8REREpB5VA9Hs2bNht9sxePBgtG3bVnl89tlnAAC9Xo8lS5agTZs2GDVqFHr16oV///vf+OSTTzBy5EjlOP/5z3/QtWtXDB06FCNHjsT111/vt8aQ1WrFihUrcPDgQfTt2xdPPPEEXnjhBb+1itTCFiIiIiL1qTqGqDEzqzp16nTWytRnioyMxNy5c3+xTK9evfD9999fVP1agsRB1URERKoLmFlmwYrrEBEREamPgUhlXIeIiIhIfQxEKtNo6m/uqnJFiIiIghgDkcokDqomIiJSHQORyjiGiIiISH0MRCrjGCIiIiL1MRCpjPcyIyIiUh8DkcoGFLyKV3T/hNFToXZViIiIghYDkco6H1+Ae3SroPdWq10VIiKioMVApDr5VyAJzrsnIiJSCwORykT9vHvhVbciREREQYyBSHXyr0CwhYiIiEg1DEQqE1Ldr4BLVRMREamGgUhlSiBiCxEREZFqGIhUxkBERESkPgYi1TEQERERqY2BSGX1LUQcVE1ERKQeBiK1cVA1ERGR6hiIVHZ6HSIGIiIiIrUwEKlNGVTNhRmJiIjUwkCkMiFp635gCxEREZFaGIhUx1lmREREamMgUhvHEBEREamOgUhl9dPuebd7IiIi9TAQqY0rVRMREamOgUhtHFRNRESkOgYilXEdIiIiIvUxEKmNY4iIiIhUx0CkNo4hIiIiUh0DkdrqxhCxhYiIiEg9DERqYwsRERGR6hiI1MZ7mREREamOgUhtdbPMJAiVK0JERBS8GIjUxi4zIiIi1TEQqUwog6rZQkRERKQWBiKVSWwhIiIiUh0DkdrqF2YEB1UTERGphYFIbRquVE1ERKQ2BiK18eauREREqmMgUlv9GCJOuyciIlINA5HaNPI6RBouzEhERKQaBiKVnZ5lxhYiIiIitTAQqY1jiIiIiFSnaiDKzs5Gv379EB4ejujoaIwePRoFBQVnlcvPz8dNN92E0NBQWCwWDBo0CDU1Ncr+0tJSjB07FhaLBREREZg4cSIqKyv9jvHzzz/jhhtugMlkQkJCAl577bVmP79GkTjLjIiISG2qBqK8vDxkZmZi7dq1yMnJgdvtxvDhw1FVVaWUyc/Px4gRIzB8+HCsX78eGzZsQFZWFjSa01UfO3YsduzYgZycHCxatAjfffcdJk+erOx3OBwYPnw4kpKSsGnTJvztb3/DjBkz8I9//KNFz/dcJE67JyIiUp0kROAMXikpKUF0dDTy8vIwaNAgAMB1112Hm2++GS+//PI5X7Nr1y6kpqZiw4YNuOaaawAAy5Ytw8iRI3H06FHExcVh9uzZ+OMf/wibzQaDwQAAePbZZ/H1119j9+7djaqbw+GA1WqF3W6HxWJpgrOVVc0dj9A9C/CK7348N/PdJjsuERERNf77O6DGENntdgBAZGQkAKC4uBjr1q1DdHQ0BgwYgJiYGNx444344YcflNfk5+cjIiJCCUMAMGzYMGg0Gqxbt04pM2jQICUMAUB6ejoKCgpQVlZ2zro4nU44HA6/R3M43UIUMLmUiIgo6ARMIPL5fJgyZQoGDhyIHj16AAAOHDgAAJgxYwYeeOABLFu2DH369MHQoUOxd+9eAIDNZkN0dLTfsXQ6HSIjI2Gz2ZQyMTExfmXqn9eXOVN2djasVqvySEhIaLqTbYj3MiMiIlJdwASizMxMbN++HfPmzVO2+XxySHjwwQfxhz/8AVdffTXefPNNdOnSBf/3f//XrPWZPn067Ha78jhy5EizvI+kkWeZaXgvMyIiItXo1K4AAGRlZSmDoePj45Xtbdu2BQCkpqb6le/WrRsKCwsBALGxsSguLvbb7/F4UFpaitjYWKVMUVGRX5n65/VlzmQ0GmE0Gi/jrBpJOt1lJoSAJEnN/55ERETkR9UWIiEEsrKysGDBAuTm5iI5Odlvf/v27REXF3fWVPw9e/YgKSkJAJCWloby8nJs2rRJ2Z+bmwufz4f+/fsrZb777ju43W6lTE5ODrp06YJWrVo11+k1ijKGCIJrMxIREalE1UCUmZmJTz/9FHPnzkV4eDhsNhtsNpuyxpAkSXjqqafwzjvvYP78+di3bx+ef/557N69GxMnTgQgtxaNGDECDzzwANavX481a9YgKysLd911F+Li4gAA99xzDwwGAyZOnIgdO3bgs88+w9tvv41p06apdu71JKm+y8wHLxMRERGRKlTtMps9ezYAYPDgwX7bP/74Y4wfPx4AMGXKFNTW1mLq1KkoLS1F7969kZOTg44dOyrl//Of/yArKwtDhw6FRqPBmDFj8M477yj7rVYrVqxYgczMTPTt2xdRUVF44YUX/NYqUkt9C5FW8sHHQERERKSKgFqHKJA11zpEroXTYNj8L7zt+S0mv/AvmA3aJjs2ERFRsLsi1yEKRhpllplgCxEREZFKGIjUVjerTAN2mREREamFgUhlklYexqWBgI9rMxIREamCgUhlUt06RGwhIiIiUg8DkcpOByLBafdEREQqYSBSWf20ew6qJiIiUg8DkdoaLMzIMURERETqYCBSG8cQERERqY6BSG0NxxD5GIiIiIjUwECktgaBiA1ERERE6mAgUptUf7d73tyViIhILQxEaqu/uStnmREREamGgUhtDQdVcwwRERGRKhiI1FYfiCQB5iEiIiJ1MBCpTRlDxFlmREREamEgUlvdwoxarkNERESkGgYitXFhRiIiItUxEKmtQZcZe8yIiIjUwUCkNkkCwJWqiYiI1MRApDbN6TFEgl1mREREqmAgUhvvZUZERKQ6BiK1Nbh1B/MQERGROhiI1NaghYizzIiIiNTBQKQ2BiIiIiLVMRCprW5hRg18HENERESkEgYitTVYmJENREREROpgIFIb1yEiIiJSHQOR2vzuds9AREREpAYGIrVpTo8hYiAiIiJSBwOR2vxmmalcFyIioiDFQKQ23u2eiIhIdQxEauOtO4iIiFTHQKQ2TrsnIiJSHQOR2pSFGdlCREREpBYGIrU1WIeIY4iIiIjUwUCkNr+73TMQERERqYGBSG11gUgLH6fdExERqYSBSG0ajiEiIiJSGwOR2pQuMwHBLjMiIiJVMBCprcG0e7YQERERqYOBSG0cQ0RERKQ6BiK11a9DxLvdExERqUbVQJSdnY1+/fohPDwc0dHRGD16NAoKCs5ZVgiBW265BZIk4euvv/bbV1hYiIyMDISEhCA6OhpPPfUUPB6PX5nVq1ejT58+MBqNSElJwZw5c5rprC5S3TpEEtchIiIiUo2qgSgvLw+ZmZlYu3YtcnJy4Ha7MXz4cFRVVZ1V9q233oJUFx4a8nq9yMjIgMvlwo8//ohPPvkEc+bMwQsvvKCUOXjwIDIyMjBkyBBs3boVU6ZMwaRJk7B8+fJmPb9G8buXmcp1ISIiClbiEsyZM0csWrRIef7UU08Jq9Uq0tLSxKFDhy7lkEIIIYqLiwUAkZeX57d9y5Ytol27duLEiRMCgFiwYIGyb8mSJUKj0QibzaZsmz17trBYLMLpdAohhHj66adF9+7d/Y555513ivT09EbXzW63CwDCbrdfwpn9guM/CfGiRdheSBSzcvc27bGJiIiCXGO/vy+pheiVV16B2WwGAOTn5+O9997Da6+9hqioKEydOvWSw5ndbgcAREZGKtuqq6txzz334L333kNsbOxZr8nPz0fPnj0RExOjbEtPT4fD4cCOHTuUMsOGDfN7XXp6OvLz889bF6fTCYfD4fdoFg1mmfk4qpqIiEgVlxSIjhw5gpSUFADA119/jTFjxmDy5MnIzs7G999/f0kV8fl8mDJlCgYOHIgePXoo26dOnYoBAwbgtttuO+frbDabXxgCoDy32Wy/WMbhcKCmpuacx83OzobValUeCQkJl3ReF1S3MCNnmREREannkgJRWFgYTp06BQBYsWIFbr75ZgCAyWQ6b8C4kMzMTGzfvh3z5s1Tti1cuBC5ubl46623LumYl2P69Omw2+3K48iRI83zRg3HEHFQNRERkSp0l/Kim2++GZMmTcLVV1+NPXv2YOTIkQCAHTt2oH379hd9vKysLCxatAjfffcd4uPjle25ubnYv38/IiIi/MqPGTMGN9xwA1avXo3Y2FisX7/eb39RUREAKF1ssbGxyraGZSwWi9L1dyaj0Qij0XjR53LR6qfdw8eVqomIiFRySS1E7733HtLS0lBSUoIvv/wSrVu3BgBs2rQJd999d6OPI4RAVlYWFixYgNzcXCQnJ/vtf/bZZ/Hzzz9j69atygMA3nzzTXz88ccAgLS0NGzbtg3FxcXK63JycmCxWJCamqqUWblypd+xc3JykJaWdtHn3uQ0pxdm5ErVRERE6rikFqKIiAjMmjXrrO0vvfTSRR0nMzMTc+fOxTfffIPw8HBlzI/VaoXZbEZsbOw5B1InJiYq4Wn48OFITU3Ffffdh9deew02mw1/+tOfkJmZqbTwPPTQQ5g1axaefvppTJgwAbm5ufj888+xePHiiz31pidxDBEREZHaLqmFaNmyZfjhhx+U5++99x6uuuoq3HPPPSgrK2v0cWbPng273Y7Bgwejbdu2yuOzzz5r9DG0Wi0WLVoErVaLtLQ03Hvvvbj//vsxc+ZMpUxycjIWL16MnJwc9O7dG6+//jo++ugjpKenN/p9mo3mdJcZF2YkIiJShyQuYeBKz5498de//hUjR47Etm3b0K9fP0ybNg2rVq1C165dle6sXxOHwwGr1Qq73Q6LxdKEBz4BvNEVXiEhu9+P+NOtqU13bCIioiDX2O/vS+oyO3jwoDI+58svv8Stt96KV155BZs3b1YGWFMj1U+7lwS8Pi5VTUREpIZL6jIzGAyorq4GAHz77bcYPnw4AHlBxWZbwPDXqm4MEQBAMBARERGp4ZJaiK6//npMmzYNAwcOxPr165UxP3v27PGbNk+NoDmdSYXXq2JFiIiIgtcltRDNmjULOp0O8+fPx+zZs9GuXTsAwNKlSzFixIgmreCvnuZ0JhWCgYiIiEgNl9RClJiYiEWLFp21/c0337zsCgWdhl1mPgYiIiIiNVxSIAIAr9eLr7/+Grt27QIAdO/eHb/5zW+g1Wov8Eryo2EgIiIiUtslBaJ9+/Zh5MiROHbsGLp06QJAvhlqQkICFi9ejI4dOzZpJX/VGrQQCQYiIiIiVVzSGKLHHnsMHTt2xJEjR7B582Zs3rwZhYWFSE5OxmOPPdbUdfx1a9BCxDFERERE6rikFqK8vDysXbsWkZGRyrbWrVvj1VdfxcCBA5usckFBkiAgQYKAxEBERESkiktqITIajaioqDhre2VlJQwGw2VXKtiIum4zTrsnIiJSxyUFoltvvRWTJ0/GunXrIISAEAJr167FQw89hN/85jdNXcdfPSHV/RrYQkRERKSKSwpE77zzDjp27Ii0tDSYTCaYTCYMGDAAKSkpeOutt5q4ir9+PgYiIiIiVV3SGKKIiAh888032LdvnzLtvlu3bkhJSWnSygULgbqB1byXGRERkSoaHYimTZv2i/tXrVql/PzGG29ceo2CUV0LEafdExERqaPRgWjLli2NKidJ0iVXJljVD6rmLDMiIiJ1NDoQNWwBoqalDKpmCxEREZEqLmlQNTUtZdo9W4iIiIhUwUAUAOoDEVuIiIiI1MFAFAg07DIjIiJSEwNRAFC6zBiIiIiIVMFAFAjqu8w4hoiIiEgVDESBQFmHiAszEhERqYGBKAAIDdchIiIiUhMDUSDgGCIiIiJVMRAFgvqVqhmIiIiIVMFAFAjqpt1zYUYiIiJ1MBAFAt7LjIiISFUMRIFAwzFEREREamIgCgTKLDNOuyciIlIDA1Eg4L3MiIiIVMVAFAAkTf1K1WwhIiIiUgMDUSBQusw8KleEiIgoODEQBQBJYgsRERGRmhiIAkHdOkRcmJGIiEgdDEQBoH4MkQQGIiIiIjUwEAUCjQ4Ap90TERGphYEoACizzNhlRkREpAoGogBQH4g08MHnEyrXhoiIKPgwEAWAhoHIKxiIiIiIWhoDUQCoD0Ra+OBlCxEREVGLYyAKAKcDkWAgIiIiUgEDUQBglxkREZG6VA1E2dnZ6NevH8LDwxEdHY3Ro0ejoKBA2V9aWopHH30UXbp0gdlsRmJiIh577DHY7Xa/4xQWFiIjIwMhISGIjo7GU089BY/H/zYYq1evRp8+fWA0GpGSkoI5c+a0xCk2iqSVp91r4YPXy0BERETU0lQNRHl5ecjMzMTatWuRk5MDt9uN4cOHo6qqCgBw/PhxHD9+HH//+9+xfft2zJkzB8uWLcPEiROVY3i9XmRkZMDlcuHHH3/EJ598gjlz5uCFF15Qyhw8eBAZGRkYMmQItm7diilTpmDSpElYvnx5i5/zudTfukMrsYWIiIhIDZIQgfMNXFJSgujoaOTl5WHQoEHnLPPFF1/g3nvvRVVVFXQ6HZYuXYpbb70Vx48fR0xMDADggw8+wDPPPIOSkhIYDAY888wzWLx4MbZv364c56677kJ5eTmWLVvWqLo5HA5YrVbY7XZYLJbLP9mGljwNrP8Q73pG446nP0SMxdS0xyciIgpSjf3+DqgxRPVdYZGRkb9YxmKxQKeTu5ny8/PRs2dPJQwBQHp6OhwOB3bs2KGUGTZsmN9x0tPTkZ+f39SncGk4y4yIiEhVOrUrUM/n82HKlCkYOHAgevTocc4yJ0+exMsvv4zJkycr22w2m18YAqA8t9lsv1jG4XCgpqYGZrP5rPdyOp1wOp3Kc4fDcWkn1hiSnEs1DERERESqCJgWoszMTGzfvh3z5s07536Hw4GMjAykpqZixowZzV6f7OxsWK1W5ZGQkNB8b8YWIiIiIlUFRCDKysrCokWLsGrVKsTHx5+1v6KiAiNGjEB4eDgWLFgAvV6v7IuNjUVRUZFf+frnsbGxv1jGYrGcs3UIAKZPnw673a48jhw5clnn+Iuk04HIw0BERETU4lQNREIIZGVlYcGCBcjNzUVycvJZZRwOB4YPHw6DwYCFCxfCZPIfcJyWloZt27ahuLhY2ZaTkwOLxYLU1FSlzMqVK/1el5OTg7S0tPPWzWg0wmKx+D2aTcN7mQXOGHciIqKgoWogyszMxKeffoq5c+ciPDwcNpsNNpsNNTU1AE6HoaqqKvzrX/+Cw+FQyni98p3hhw8fjtTUVNx333346aefsHz5cvzpT39CZmYmjEYjAOChhx7CgQMH8PTTT2P37t14//338fnnn2Pq1Kmqnbufhi1EXIeIiIioxak6qHr27NkAgMGDB/tt//jjjzF+/Hhs3rwZ69atAwCkpKT4lTl48CDat28PrVaLRYsW4eGHH0ZaWhpCQ0Mxbtw4zJw5UymbnJyMxYsXY+rUqXj77bcRHx+Pjz76COnp6c17go3VYAwRW4iIiIhanqqB6EJLIA0ePPiCZQAgKSkJS5YsueCxtmzZclH1azENZplxDBEREVHLC4hB1UGPs8yIiIhUxUAUCOrGEGkkBiIiIiI1MBAFArYQERERqYqBKBBIDERERERqYiAKBA3WIeLd7omIiFoeA1EgqJtlpoWA1+dTuTJERETBh4EoEPiNIVK5LkREREGIgSgQSA26zNhCRERE1OIYiAKBRl4fUwcvW4iIiIhUwEAUCOoCkRZeeNhCRERE1OIYiAJB3RgincR7mREREamBgSgQaPUA5C4z3u2eiIio5TEQBQLN6UDEhRmJiIhaHgNRIGg4qJpdZkRERC2OgSgQaBvOMmMgIiIiamkMRIFAw0BERESkJgaiQMAxRERERKpiIAoE9V1mEgMRERGRGhiIAkGDLjMPAxEREVGLYyAKBA26zHwMRERERC2OgSgQsIWIiIhIVQxEgaDBtHveuoOIiKjlMRAFgroWIj28cPPWHURERC2OgSgQ1I0h0sILj5d3uyciImppDESBoP7mrpKPgYiIiEgFDESBQKNVfvR43SpWhIiIKDgxEAWCui4zAPC5XSpWhIiIKDgxEAWCukHVACDYQkRERNTiGIgCgfZ0C5GXgYiIiKjFMRAFAo0WAhIAQHgYiIiIiFoaA1GA8EnywGqf16NyTYiIiIIPA1GAEHUDq4WXg6qJiIhaGgNRgBB1LUQcVE1ERNTyGIgChKibacYuMyIiopbHQBQg6rvMwBYiIiKiFsdAFCCEpr7LjC1ERERELY2BKFCwhYiIiEg1DESBor6FyMdARERE1NIYiALE6TFEXnUrQkREFIQYiAKEVH8/M7YQERERtTgGokBRfz8zBiIiIqIWx0AUKOq6zCQfu8yIiIhaGgNRgJC08qBqthARERG1PFUDUXZ2Nvr164fw8HBER0dj9OjRKCgo8CtTW1uLzMxMtG7dGmFhYRgzZgyKior8yhQWFiIjIwMhISGIjo7GU089BY/Hfz2f1atXo0+fPjAajUhJScGcOXOa+/QuilTXZSYJthARERG1NFUDUV5eHjIzM7F27Vrk5OTA7XZj+PDhqKqqUspMnToV//vf//DFF18gLy8Px48fx+23367s93q9yMjIgMvlwo8//ohPPvkEc+bMwQsvvKCUOXjwIDIyMjBkyBBs3boVU6ZMwaRJk7B8+fIWPd9fItV1mWl8Hnh9QuXaEBERBRdJCBEw374lJSWIjo5GXl4eBg0aBLvdjjZt2mDu3Ln43e9+BwDYvXs3unXrhvz8fFx33XVYunQpbr31Vhw/fhwxMTEAgA8++ADPPPMMSkpKYDAY8Mwzz2Dx4sXYvn278l533XUXysvLsWzZskbVzeFwwGq1wm63w2KxNPm5u//fGOj3f4un3JPx8oxXYdJrm/w9iIiIgk1jv78DagyR3W4HAERGRgIANm3aBLfbjWHDhillunbtisTEROTn5wMA8vPz0bNnTyUMAUB6ejocDgd27NihlGl4jPoy9cc4F6fTCYfD4fdoThqtAQCggxcethARERG1qIAJRD6fD1OmTMHAgQPRo0cPAIDNZoPBYEBERIRf2ZiYGNhsNqVMwzBUv79+3y+VcTgcqKmpOWd9srOzYbValUdCQsJln+Mv0WjldYh08MLt8TXrexEREZG/gAlEmZmZ2L59O+bNm6d2VQAA06dPh91uVx5Hjhxp1verH1StgxduHwMRERFRS9KpXQEAyMrKwqJFi/Ddd98hPj5e2R4bGwuXy4Xy8nK/VqKioiLExsYqZdavX+93vPpZaA3LnDkzraioCBaLBWaz+Zx1MhqNMBqNl31ujaZp0ELkZZcZERFRS1K1hUgIgaysLCxYsAC5ublITk7229+3b1/o9XqsXLlS2VZQUIDCwkKkpaUBANLS0rBt2zYUFxcrZXJycmCxWJCamqqUaXiM+jL1xwgIdbPM9PDC42ULERERUUtStYUoMzMTc+fOxTfffIPw8HBlzI/VaoXZbIbVasXEiRMxbdo0REZGwmKx4NFHH0VaWhquu+46AMDw4cORmpqK++67D6+99hpsNhv+9Kc/ITMzU2nheeihhzBr1iw8/fTTmDBhAnJzc/H5559j8eLFqp37WerGEGnhhZuBiIiIqEWp2kI0e/Zs2O12DB48GG3btlUen332mVLmzTffxK233ooxY8Zg0KBBiI2NxVdffaXs12q1WLRoEbRaLdLS0nDvvffi/vvvx8yZM5UyycnJWLx4MXJyctC7d2+8/vrr+Oijj5Cent6i5/uL6rvMJC9cHnaZERERtaSAWocokDX3OkRY+iywbjZme0Zh4EOz0Cs+ounfg4iIKMhckesQBTWd3L1ngIddZkRERC2MgShQ6EwAACNcnGVGRETUwhiIAkVdC5ERbrYQERERtTAGokBR30IkMRARERG1NAaiQKGv7zJzc5YZERFRC2MgChS6BoGILUREREQtioEoUDQYQ1Tj8qhcGSIiouDCQBQolDFELtS4vCpXhoiIKLgwEAWKBi1E1W4GIiIiopbEQBQoGowhYgsRERFRy2IgChQMRERERKphIAoU9V1mErvMiIiIWhoDUaBocOuOWrYQERERtSgGokDRcFA1AxEREVGLYiAKFHUtRCaJ6xARERG1NAaiQFHXQgQAbletihUhIiIKPgxEgaKuhQgAvAxERERELYqBKFBoDcqPXleNihUhIiIKPgxEgUKS4NPK3WY+D1uIiIiIWhIDUQARWrnbzMcWIiIiohbFQBRI6gZWC49T5YoQEREFFwaiQFI3sFryOOHzCZUrQ0REFDwYiAKIpD+9OGMNb99BRETUYhiIAoikr7t9h+RiICIiImpBDEQBRKpfrRouVNZytWoiIqKWwkAUSAxhAIBQ1OJUFQdWExERtRQGokBibgUAaCVVoqSCgYiIiKilMBAFkpBIAICVgYiIiKhFMRAFkvoWIjAQERERtSQGokBilluIIqRKlFQyEBEREbUUBqJAUtdCFIFKFDsYiIiIiFoKA1EgCWELERERkRoYiAJJXZdZK7YQERERtSgGokBS12VmlSphc9Si0snFGYmIiFoCA1Egqesys0g10MGD3SccKleIiIgoODAQBRKTFYAEAIhAFXYyEBEREbUIBqJAotECYdEAgHZSCXYcYyAiIiJqCQxEgaZNFwBAJ80xLNthg73GrXKFiIiIfv0YiAJNm64AgGtDi2GvceNPX2+H2+tTuVJERES/bjq1K0BnqGshGtamHLpKCf/76Th2HLejX1IkRvSIxY2d20CjkSCEgCRJKleWiIjo14GBKNDUtRBF2nfhw7u6Y+pXu3GgpAoHSqrw2cYjCDVoEWLUoazKhW5tLfj9NfHQazXYdsyOqFADLGY9bujUBl1iw1U+ESIioiuHJIQQalfiSuBwOGC1WmG322GxWJrvjVxVwFu9gOqTgLkVHKP/jVU1HbHhUCm+3HQMNW5vXUGB+hlpoaiBC3q46/KtJAG39orD1QkRSIkOQ3JUKBIiQ5qvzkRERAGqsd/fqo4h+u677zBq1CjExcVBkiR8/fXXfvsrKyuRlZWF+Ph4mM1mpKam4oMPPvArU1tbi8zMTLRu3RphYWEYM2YMioqK/MoUFhYiIyMDISEhiI6OxlNPPQWPJ0AXPTSEAmM+AiQtUFMGy/8ewG3mbfjzdRJ+Hh+Ktbc7sbHfKuxrNQWLOi3C5HaHsd78GDaGP4lHu9dicEoEhAD+99NxzFy0E/f/33rc8NoqjPu/9Vj403GsPXAKbq8PPh9zMBERUT1Vu8yqqqrQu3dvTJgwAbfffvtZ+6dNm4bc3Fx8+umnaN++PVasWIFHHnkEcXFx+M1vfgMAmDp1KhYvXowvvvgCVqsVWVlZuP3227FmzRoAgNfrRUZGBmJjY/Hjjz/ixIkTuP/++6HX6/HKK6+06Pk2WschwLRdwIc3AJU24L93AgD0AGIbFOtxZC561D9xV+GJ/RMASQtbrzvxk7cDVru6YoPdgv0llcjbU4K8PSUAgDCjDrVuL7q3s+LJ4Z3RN6kVtBoJ6w6Uok24Ed3aNmMLGBERUQAKmC4zSZKwYMECjB49WtnWo0cP3HnnnXj++eeVbX379sUtt9yCP//5z7Db7WjTpg3mzp2L3/3udwCA3bt3o1u3bsjPz8d1112HpUuX4tZbb8Xx48cRExMDAPjggw/wzDPPoKSkBAaDoVH1a7Eus4aKdwO5LwMlBUDpASAsBghtDfi8QPHOukISkHob4DgGHN3g/3pJA0R2QE1oO6x3dcDCU+2wtyYcDq8Oh0RbpViozocnDF8jt7YTfvD1xKTrkzF9ZDdoNRy0TUREV7bGfn8H9KDqAQMGYOHChZgwYQLi4uKwevVq7NmzB2+++SYAYNOmTXC73Rg2bJjymq5duyIxMVEJRPn5+ejZs6cShgAgPT0dDz/8MHbs2IGrr776nO/tdDrhdJ6+warDocIiidFdgbv+I//s88oBp+HMsqpT8vOQSMDjAg7/AOzPBY5vBZwVwImtwKl9MJ/ahxuRhxsB+TeuA2ojOuEnTTfknbRAeD2Y4JuPCQZgquth/OsHHzYeLsOjN6VgSJdoaBiMiIjoVy6gA9G7776LyZMnIz4+HjqdDhqNBv/85z8xaNAgAIDNZoPBYEBERITf62JiYmCz2ZQyDcNQ/f76feeTnZ2Nl156qQnP5jJptGdvC219+medAeh4k/wAACGAskOA/ShwsgA4ulFuQSo9CAgvTOV70R970V8Dv5FkbxpmI9FXjrePjMLETzaic0wYxvZPQr/2kQg36RAZakCoMaA/NkRERBctoL/Z3n33XaxduxYLFy5EUlISvvvuO2RmZiIuLs6vVag5TJ8+HdOmTVOeOxwOJCQkNOt7NilJAiKT5UfyDUC/Saf32Y8Bh9cAP80D9q8866VTNf/F3ZGb8HVVD7xaNAYvLtwBAAhHNWq1oZg8qAPGD0hGm3Dj6UPWuBFq0EKn5VqfRER05QnYQFRTU4PnnnsOCxYsQEZGBgCgV69e2Lp1K/7+979j2LBhiI2NhcvlQnl5uV8rUVFREWJj5eHHsbGxWL9+vd+x62eh1Zc5F6PRCKPReN79VzRrO6DXHfKj9ACwfxWQcC0QnQr862bg2CbEVu/BQ9IeDEuowPeuzuhSthr9pZ2Y570Jf1w1AbNX78e1yZFI6xCFgiIHlu8oQsc2oXh1TC9cnRDBRSOJiOiKErCByO12w+12Q6Pxb3HQarXw+eRbWfTt2xd6vR4rV67EmDFjAAAFBQUoLCxEWloaACAtLQ1/+ctfUFxcjOho+capOTk5sFgsSE1NbcEzClCRHeRHvXGL5FajHQuA7V8hpSQHKchRutXG6laiv+kwvqm5CusPdsOKg2Y8ofsc9+ucmFcyBOPfL0JUm2j8rm88bu0Zh4RIM8MREREFPFVnmVVWVmLfvn0AgKuvvhpvvPEGhgwZgsjISCQmJmLw4ME4efIkZs2ahaSkJOTl5eHhhx/GG2+8gYcffhgA8PDDD2PJkiWYM2cOLBYLHn30UQDAjz/+CECedn/VVVchLi4Or732Gmw2G+677z5MmjTpoqbdqzLLTG1HNwKbPpYHb7sq5dakyiLAd/41nPaIBExwPYEqYYIDoQgxydP4JQBmgxZdYsLRJVZ+mPRa7LFVYEjXaJj05xgjRUREdJka+/2taiBavXo1hgwZctb2cePGYc6cObDZbJg+fTpWrFiB0tJSJCUlYfLkyZg6darS6lBbW4snnngC//3vf+F0OpGeno7333/frzvs8OHDePjhh7F69WqEhoZi3LhxePXVV6HTNb6BLCgD0blUFgP5s4AjG4Cj6wGNHhA+wOs8q2it0GOnSMIREY1KYcYBEYvrNdvRUTqOUlhwVLTB/3lGIDlCi6u6dsbJkA4odVRiYJe2uKlrDAw6jkciIqLLc0UEoisJA9E5eFyAVi8P4Pa65Rakrx8Gjm26pMM5hQ46eLHG1wM7dKlATA8k4yhqrR3hS0lHhygz4kQRth44gTJLVwxLjUVkiB5SpQ3Q6ICw6KY7N69bXi1cw1BGRHQlYyBqYgxEF8FVBWiN8rT/41uAiuNA9SmgeBfQpgvQuhMgaSC2fArpyFrU6q3QuyuhhfeCh6633tcFm32dMFr7I2KlUnihwS7TVaht3R3mlIFoa3BC761BiFQLrUYLGMOB1ilAyW7g1D5AZwQiO0BcfT+k7fPlhS4HPQXUOoCyg8CCBwFIwJDngC63yItk1pYDyTcCRTsA209ARBKw9GnAGg/EXQ3c8IT8PgDg9QCbPwFO7Qc6pwOtkoCincCW/ycfwxguh8mev5cDpeM44KqWl1fY/AngcQKDpwOmus+aswI4kAcULAW6jQK6jDh9rb0u+Xp/84hcl4FT5WNr9YDWIB+zulSuf8PxYg1/X4ZQ/23HtwAle4CUYXIdPE65zKWOBxNCPsapvUB4WyA0yn//kQ3A7v/J1yF5ENDnfrl8rR3Y9gXQaTgQ1el0eZ/33EtR1Ks6KV9rjxPoOx4IiZLX8do+X163K+l64OQeQGeSz8va7vzHKjsk18ESD7TtBWz+f0CHG+XPxa9R/VcCx/7JnJWAuwYIa6N2TZqOxwV4agCTVZ33F+Lsz1etHagpA1q1b/K3YyBqYgxEzcDjkr94464GqoqB7V8BxjD4Tu1H7bb/QXicKDJ3QlLZj0pYqhZGaCUBI1yqVNmtDYHeW33ufeY20IVFQTJHyF+iFScufEBDuPwP0/nGZUV1kQNP2UH/7ZEd5JBZa5efSxq56/JcLPGA46j8c+IA+Xof/kG+/mHRwME8oE03wBgm/8PvqpTrfyZJC0R3k0NXTRkQ2gawbZPLG8IAowWAAFp3lANY2SGgbW85dBzfApTul49jigB6/k4ONeZW8gKi+3P93yvhOrl8VYn/tra9gWMb5XDd6WZ5ZmTVSXkZiZDWcl1c1XLoFQ0Ctr7u5sbuc/zu9CFyADu6UX6/PvcB1WXy2l5FO+Qgeo4uYfS+Ry4fEilfx/2rgfJCIDwGaHeN/PuoLa9rRdXIy1206wt4auXXRCTJnxGvSz5OrUMOn/HXAj63fCxjuBzmtAa5BVaS5OuceB2w42vA9jPQZ5wc1Db8S74pdEx3OXTuz5XDYMJ18nWptctd3o6jclAUQl6SQx8CrPsQiLtK/vJfnS3XL6Y7cOInoP9D8nWWNHL9Tu2Tg36bLvJnyBInf4md2AocWA30vlt+v7BY+XNduh/QmYH4vvJ4xIoT8raoLnIwDo2S10szt5KD/9ENwKZP5D9g0h6Rj6k1yJ/5nd8AV42Vr4+7Rl7Fv3M6sGeZ/EdBt1Hy53jvt/LvKGkAULRdrqM1/tz/f/h8524J9riADR8BeX+Vf49dRgL9H5T/oJEk4MTPcp2MYec+7lnHc8qt58IHJA08HQiqTsl/YEV19q9jrUP+3exdARxZK79vTA+g/LB8Hcyt5PfvMFj+fZ0rZDRUWQJAyP+/fDpG/kxP+lY+hs9b94eVQf5/1Vkhv0arl+tQslv+LBrC5Dp6nPJ/DWGAtm7oydGNwMLH5FtP3fQn+bMUEin/4XL4R/l35aoCktKA1X+Vz8saL/+eLe2AfTnyvw0P5Db+mjYSA1ETYyBSkW07UGmDiO2FCo0F4e6TkH54C96yQlQkDcOJpNtQU7QfroM/QhzbhOiKnajwaGEXoYiWytFNUwhAHtNUDSMipcrzvpVPSHBBB5PkxiFfDIySG22l0kuqtlMyYa3ojgFiK/TShVu/vBoDtD4XSqVWiBRlZ+0v17ZGrWRErOf4JdUn6BgtgLOJVpi3Jsitiqf2Nc3xWpQEIAD+mY/tCZzcKwfChqK6yK11TVFHc6QcLI6sPWNH3S2OwtsC9iOA3iy/78E84NhmoN9EOWSWH5Fn2RbtPP1HxJnCYuRW7sM/yC0sKcPk8N/+eiCujxzO966Qg2zXDDlohLSWg1V9wI+/Vg7hTgew+tXTn1ONXj5mZAfg+GY55LmrfvmcQ9vIdTq5FwiPlYOsRiufq84I7MuVQ1jJrnOfS8owOTxXnJD/QHNVXMwVlwNNeFvgyPqz/3DQh8iP6pONO5YlHrhvAdCm88XV4QIYiJoYA9GVpdbthRDA4dIquNxeOCoc8AgNdpW4ECI50VrnhKQ3obPWhtpyG8qralFW7cIXFT0QbjIg1KiFXq/HibJqhBRvhtlbgS36qzBAWwCPRo8Dxq4Y5N2AY6YUbHGEweOsQVfXNlS6BEJRi3KEYZcvEadgRbxUjESpGEdFG5SKcFRCbq1ohxJcoylAH81ezPUOxV4Rj9awowQR6CCdQKJUDCf0MMKFrb4UlCMMgIQ2KEMXzVEM1GzHYRGDzb5OuF6zHVt9HWGSXDjsi0EZwhErlcIAD3pqDiAGZVjquxY3azahnXQS20UytPAhyeDAHikZYXqBSrcES7gF3U3FiHYdxZKIe7DfIeHgsWJojKGIkhwYqt+GUKMORksUYnzFMLWKQ7mlCzy1lXBXO6Dz1aKLdx+ERie3DtSUIaLqAHYbe6G2yiF/NYe1QaznGAw6HSxGCUZzOEKqCvFd0qM47g7FDbZ/o9qnhT48GkXh3VGptUIUrkWSuRbdw6thqDwKj8YIodFDawqDWa+DiLsKPkkLnVYHYQhFsakD9nii4akoQecoE9rW7ocnpA181iQYS3cDP/0XUtIA+S9c+xG59cUUIbcglRfKX2DCC0R3B5LSUNu6O/YUORC351NE6V3yF2B5odzFF5ksn6vPI4ewsBj53oKlB4Huo+UvREOYvH334rpy4XKrQ0SS/Fd52UH5izksRm5t0pvlv57d1XILQk2Z3CrmrGsR1OjkL01DmPwXPQTQcajc3bhneV3L3RlfbDpz3Zdtsnz8mvLTr60X2VH+gqsqkf+ad1XKZZ0V8pdq1Um5fHR3uZUnvC1QU3q6pbKeyXr2tsZqnQK06Sq3KJzaK5+j64w/YkxWuYXI26ClWB9y7hbAyzXkj0DhWjm0VZz4xVm2F3S+ltyLDe+JA+TPj3JPy4vUqr3cKneuc9GZ5M+h1y0HK8dxuVVZkuTf6al98vWvOfuPNtk5AriklT/X52o1b3eN3B2uMwI3veB/B4YmwkDUxBiI6EJ8PoGDp6pQWFqN9QdLoddI6N+hNa5p3wr2ajdOVsr/eJfXuOD1CdS4vPAJgY2HylBS6URplQsd24ShV7wVNkctDpRU4VhZDQBAQGBQ5zaICjUixKhFZa0HGw+XYdcJ+R/Rk5VOGHXymBqnx4uoMCN0Ggm1bh9CjVpoJAmHTlWjrFp+718Tg1YDt88HrSShdZgB5dVuOD3n7j7UaiRoJMDjE9BrNdBrJOh1Gui1Ghi0Gui1EpJah6JTdBgsZj1q3F5sP2bHhkOlqHXLx+wQFQqDTgODToM+ia0QFWbAyUoXosIMcHp8yN9/ChazHgM6toZRr4XX64PHJ+DxCcRaTIgKMyKpdQh8QqDS6cHx8lp4vD4ct9fC6/MhxmJCuEkHrUauT4zFhMgQAyLMOkieGlQ7TsEYYkG5zwyX1weUFKC0FhCtklFcUYsT9lrEWkwY1LkN9D6n/MVlCPUbLyKEkGfqOivkkGNNkL/sQiLhE0BhaTW0GgmtQg0INWhPryVWYZNf03A8FyCHK61e7rapPiWPmXNWyGEPkL+4y4/IoaW+C9FZIdfp5B75C7rqJJDYH4hIxIZDpVix7Ri6W10Y0rcnrHqP3E1mssqvM4afHutUekAOiJZ2wI6v5C6yziPksLl7sdwytD9XnhVbvFtuyXFXy3UOiZTD7/Yv5YAhaYDU0XLY3PEV0P12oO+40+fpqgY2zZGPZY2XW2VCouSuxHUfyq01XW4BEvrLweFkgVxf+1E5rKa/Indt7vtWDhs15UCPMXJXXNmh09ev7BAQkShfm9A28vFqy4Fd/5O7Nuu77Wod8pjDmjIgvp/clRbZQe5OK94p728/UD5HS7x8zOpTciuaqwLYs0IOtsIHHPxO7lq8+WX/MXVndsXVP68sls/Ntk1u9bPEAe1vkENWrQMwR8h/FLir5KBtDJO70XZ+I18LxzG5RSy+b6P/X79UDERNjIGIfg18PgF7jRtur/zlXlrtgsvjQ7HDiahwI46V1eBYeTUkSDDoNGgVakDX2HBUOj3QShKcHh+KHLU4Vl6D8mo3iitq4fT4YNRpIARg0mtQ5fTC6xPyF2qIHka9FuXVLgzoGAWzQYt9xZXQaiSUVrmwp6gC5dVuCCEQGWpAQmQIKms9EJBDnsWsh9PtQ/vWIdhcWIafj9rhEwIhBh0kCahyenCufKfTSEhqHQKzQYtdJyqaJASGG3WocF5G68BlSog0w+sVOG6vhSSdzgPno9NIiAozonucBaeqXNBqJBRX1MLnA4oratE7PgLtWplxqtIFk16Lk5VORIUZse1YOYocp7s+9FoJVrMefZNaYWTPtogKM+LgySoIAE63F45aD4w6DeIiTDBotfD4fEiJDkNFrQdlVS6cqnJhX3EljDoNEiJDkBgp/142HipDXIQJveMjoNVI2HnCgW6xFvyw7ySeW7DN7/3jIszQSBKMOg2MOg3iI0Mwonss2oQbEWLQwlHjgb3GjZOVTlTUuhEXYcbPR+0IN+nkdc9iwtE+KhR6rQa1bi9q3V5YzfpGLRq7r7gCW4/YUev2okc7K3rHW8/9uspiObDpfqV3OLiCMRA1MQYiIvXV/3NV/4Xk9vpgs9fCqNeg1uVDWbULrUIMaBthgr7uvnq1bi+qnB5IkgRHjRsAEGLUwu0V8Hh9cHt9cHkE3F4fat1ebD/uQLGjFvYaN7QaCd3aWtCvfSQ6x4Th8KlqHC6thlaSUF7jwvqDpah2edE61IBTVS7otRq0izABALYds0OCBK1Wgk4jweMTKHE4cbSsGmXVcj1CjVpYzXoYdFokRpph1GlR5KhFrdsLt1fA5fXhaFm10jp1JoNWA40GsJj0qHJ6kNQ6FCa9BgdPVinvcSkMWg0kCedtaWsJ/dq3QkWtB7ttFzmm5TwMWg3aRphwrKwGHp9AuFGHthEmeHwCYUYdwow6hJt0MOm1cHnklrpqlwdfbT4GT4NA3b51CATkjiFriAFtwgxIiQ6HXitBq5FQ5fSguEIOlAW2CkSGGmDUadA5NhxlVS5EhsothImRIegVb0WNy4tj5TVoHWpEjNWIw6eqYdZrERdhhtvrw9GyGtS4vOjQJhShRh1OVjrx89Fy2GvciDAbYA3RQytJ6BIbDqNOA0mSUOSoRUmFEwmRITDq5M9Dm3AjosKMqHJ68N2eEszO24+KWg9SosPQ1iq3XLYJNyK1rQWtwwyIbxWCY+U12FJYBiGAWKsJsRYToi1GpTX6SsFA1MQYiIhIDT6fQJXLg02HyyBJEq6Kj4DNUYt2rcwIM557cVmfT+C4vQY/H7XjeHkNoi0mnKp0omObMIQatTDrdVh38BQcNR60a2VGTV2LydGyaoQadLjjmgSY9BrUuL0oq3aj2FGLpdttWHewFFVOD6LCDAg36RFi0CLcpEOtWw5uJytdqHV7Uen0IDLUgMgQA1qFGtAuwgwAOFpWjcLSahwvr0V8KzO0GgkHSqpQ6/Ei1KBDpdMDg06DyTd0wLSbO0OjkbCvuAIlFS7otXILZY3Liw2HSpG7uxhen0C1ywuLWQerWY+IEAMMOg1KHE7ER5qh12hQUFSBPUUVqHY1flmPMyVHhSLGYsTmwnK4Wigk6rUS3F7/r+dQgxZV5zkPTV2jVWSoQemer9/uE3KLYaeYcBw8WXnegN2Q1ayHvebsUG2pa3Xr2S4C5dUuHC2vQbhRhxq3Fya93J1fVu1CVJgR0RYjSqtcKKt2ITEyRP4DQSMhMlTuSnV7ffB4Ba5OjECX2HCUVDgxvPv57zF6qRiImhgDERFR86gf01Tj8kKS0OS38vH5BI6UVePgySqkRIchKsyIo2XVsNmd0GnlVp1KpwcVtR5lQsbWI+WICjNgaLcY3NApCpIkd/NuO2ZHqEELnwDsNW4cKa3GkbJq+OrGiem1cvehy+NDZKgR7rpWyCOl1UrIOFxajX3FlThaVgONBMRaTCipdMLtFQg1aJXWQUAOQSa9Fqeq5JAjSXJAa2s1obzajfJqN2rcXpRW+S9FEhlqULaZ9Bq/ENQuwoz+HSJxU9dolFW7UWSvxclKJ46V12DrkXJUOj0QQg5TPdtZYdRrsfO4A5XN3GVs0GqwY2a60rrbVBr7/R2wN3clIqLgUN8FajY0T1eMRiMPlk9qfXoB0pTocKREh1/UcSJDDbixc9Ms0CiEgM1Ri1YhBpj0WtS6vXDUuBEVZoQAYHPUwqzXolWIPNaprMqF0moX2lpNCDHoznksj1egpNKJxMgQRIUZUVblwnF7DbrEhOPgySocKatGfKsQdIoO+8XxU/YaN46V1aBdhBnWED0AKIFv5wkHCmwO7C+pgsWkQ3yrENS6vTAbtKh0ehBu0qNViB6nKl0orqiF1axHqxADCktPzwAsqXCiyuWBo8YDl8eHQ6eqcLKuBdNedw3UwBaiRmILERER0ZWnsd/fvFETERERBT0GIiIiIgp6DEREREQU9BiIiIiIKOgxEBEREVHQYyAiIiKioMdAREREREGPgYiIiIiCHgMRERERBT0GIiIiIgp6DEREREQU9BiIiIiIKOgxEBEREVHQYyAiIiKioKdTuwJXCiEEAMDhcKhcEyIiImqs+u/t+u/x82EgaqSKigoAQEJCgso1ISIiootVUVEBq9V63v2SuFBkIgCAz+fD8ePHER4eDkmSmuy4DocDCQkJOHLkCCwWS5MdN1jw+l0+XsPLw+t3eXj9Lg+v34UJIVBRUYG4uDhoNOcfKcQWokbSaDSIj49vtuNbLBZ+mC8Dr9/l4zW8PLx+l4fX7/Lw+v2yX2oZqsdB1URERBT0GIiIiIgo6DEQqcxoNOLFF1+E0WhUuypXJF6/y8dreHl4/S4Pr9/l4fVrOhxUTUREREGPLUREREQU9BiIiIiIKOgxEBEREVHQYyAiIiKioMdApLL33nsP7du3h8lkQv/+/bF+/Xq1qxQQvvvuO4waNQpxcXGQJAlff/21334hBF544QW0bdsWZrMZw4YNw969e/3KlJaWYuzYsbBYLIiIiMDEiRNRWVnZgmehjuzsbPTr1w/h4eGIjo7G6NGjUVBQ4FemtrYWmZmZaN26NcLCwjBmzBgUFRX5lSksLERGRgZCQkIQHR2Np556Ch6PpyVPRTWzZ89Gr169lMXu0tLSsHTpUmU/r9/FefXVVyFJEqZMmaJs4zU8vxkzZkCSJL9H165dlf28ds1EkGrmzZsnDAaD+L//+z+xY8cO8cADD4iIiAhRVFSkdtVUt2TJEvHHP/5RfPXVVwKAWLBggd/+V199VVitVvH111+Ln376SfzmN78RycnJoqamRikzYsQI0bt3b7F27Vrx/fffi5SUFHH33Xe38Jm0vPT0dPHxxx+L7du3i61bt4qRI0eKxMREUVlZqZR56KGHREJCgli5cqXYuHGjuO6668SAAQOU/R6PR/To0UMMGzZMbNmyRSxZskRERUWJ6dOnq3FKLW7hwoVi8eLFYs+ePaKgoEA899xzQq/Xi+3btwsheP0uxvr160X79u1Fr169xOOPP65s5zU8vxdffFF0795dnDhxQnmUlJQo+3ntmgcDkYquvfZakZmZqTz3er0iLi5OZGdnq1irwHNmIPL5fCI2Nlb87W9/U7aVl5cLo9Eo/vvf/wohhNi5c6cAIDZs2KCUWbp0qZAkSRw7dqzF6h4IiouLBQCRl5cnhJCvlV6vF1988YVSZteuXQKAyM/PF0LIgVSj0QibzaaUmT17trBYLMLpdLbsCQSIVq1aiY8++ojX7yJUVFSITp06iZycHHHjjTcqgYjX8Je9+OKLonfv3ufcx2vXfNhlphKXy4VNmzZh2LBhyjaNRoNhw4YhPz9fxZoFvoMHD8Jms/ldO6vViv79+yvXLj8/HxEREbjmmmuUMsOGDYNGo8G6detavM5qstvtAIDIyEgAwKZNm+B2u/2uX9euXZGYmOh3/Xr27ImYmBilTHp6OhwOB3bs2NGCtVef1+vFvHnzUFVVhbS0NF6/i5CZmYmMjAy/awXwM9gYe/fuRVxcHDp06ICxY8eisLAQAK9dc+LNXVVy8uRJeL1evw8sAMTExGD37t0q1erKYLPZAOCc165+n81mQ3R0tN9+nU6HyMhIpUww8Pl8mDJlCgYOHIgePXoAkK+NwWBARESEX9kzr9+5rm/9vmCwbds2pKWloba2FmFhYViwYAFSU1OxdetWXr9GmDdvHjZv3owNGzactY+fwV/Wv39/zJkzB126dMGJEyfw0ksv4YYbbsD27dt57ZoRAxHRr1hmZia2b9+OH374Qe2qXHG6dOmCrVu3wm63Y/78+Rg3bhzy8vLUrtYV4ciRI3j88ceRk5MDk8mkdnWuOLfccovyc69evdC/f38kJSXh888/h9lsVrFmv27sMlNJVFQUtFrtWTMDioqKEBsbq1Ktrgz11+eXrl1sbCyKi4v99ns8HpSWlgbN9c3KysKiRYuwatUqxMfHK9tjY2PhcrlQXl7uV/7M63eu61u/LxgYDAakpKSgb9++yM7ORu/evfH222/z+jXCpk2bUFxcjD59+kCn00Gn0yEvLw/vvPMOdDodYmJieA0vQkREBDp37ox9+/bx89eMGIhUYjAY0LdvX6xcuVLZ5vP5sHLlSqSlpalYs8CXnJyM2NhYv2vncDiwbt065dqlpaWhvLwcmzZtUsrk5ubC5/Ohf//+LV7nliSEQFZWFhYsWIDc3FwkJyf77e/bty/0er3f9SsoKEBhYaHf9du2bZtfqMzJyYHFYkFqamrLnEiA8fl8cDqdvH6NMHToUGzbtg1bt25VHtdccw3Gjh2r/Mxr2HiVlZXYv38/2rZty89fc1J7VHcwmzdvnjAajWLOnDli586dYvLkySIiIsJvZkCwqqioEFu2bBFbtmwRAMQbb7whtmzZIg4fPiyEkKfdR0REiG+++Ub8/PPP4rbbbjvntPurr75arFu3Tvzwww+iU6dOQTHt/uGHHxZWq1WsXr3ab9pudXW1Uuahhx4SiYmJIjc3V2zcuFGkpaWJtLQ0ZX/9tN3hw4eLrVu3imXLlok2bdoEzbTdZ599VuTl5YmDBw+Kn3/+WTz77LNCkiSxYsUKIQSv36VoOMtMCF7DX/LEE0+I1atXi4MHD4o1a9aIYcOGiaioKFFcXCyE4LVrLgxEKnv33XdFYmKiMBgM4tprrxVr165Vu0oBYdWqVQLAWY9x48YJIeSp988//7yIiYkRRqNRDB06VBQUFPgd49SpU+Luu+8WYWFhwmKxiD/84Q+ioqJChbNpWee6bgDExx9/rJSpqakRjzzyiGjVqpUICQkRv/3tb8WJEyf8jnPo0CFxyy23CLPZLKKiosQTTzwh3G53C5+NOiZMmCCSkpKEwWAQbdq0EUOHDlXCkBC8fpfizEDEa3h+d955p2jbtq0wGAyiXbt24s477xT79u1T9vPaNQ9JCCHUaZsiIiIiCgwcQ0RERERBj4GIiIiIgh4DEREREQU9BiIiIiIKegxEREREFPQYiIiIiCjoMRARERFR0GMgIiK6BKtXr4YkSWfdU4qIrkwMRERERBT0GIiIiIgo6DEQEdEVyefzITs7G8nJyTCbzejduzfmz58P4HR31uLFi9GrVy+YTCZcd9112L59u98xvvzyS3Tv3h1GoxHt27fH66+/7rff6XTimWeeQUJCAoxGI1JSUvCvf/3Lr8ymTZtwzTXXICQkBAMGDEBBQUHznjgRNQsGIiK6ImVnZ+Pf//43PvjgA+zYsQNTp07Fvffei7y8PKXMU089hddffx0bNmxAmzZtMGrUKLjdbgBykLnjjjtw1113Ydu2bZgxYwaef/55zJkzR3n9/fffj//+97945513sGvXLnz44YcICwvzq8cf//hHvP7669i4cSN0Oh0mTJjQIudPRE2LN3cloiuO0+lEZGQkvv32W6SlpSnbJ02ahOrqakyePBlDhgzBvHnzcOeddwIASktLER8fjzlz5uCOO+7A2LFjUVJSghUrViivf/rpp7F48WLs2LEDe/bsQZcuXZCTk4Nhw4adVYfVq1djyJAh+PbbbzF06FAAwJIlS5CRkYGamhqYTKZmvgpE1JTYQkREV5x9+/ahuroaN998M8LCwpTHv//9b+zfv18p1zAsRUZGokuXLti1axcAYNeuXRg4cKDfcQcOHIi9e/fC6/Vi69at0Gq1uPHGG3+xLr169VJ+btu2LQCguLj4ss+RiFqWTu0KEBFdrMrKSgDA4sWL0a5dO799RqPRLxRdKrPZ3Khyer1e+VmSJADy+CYiurKwhYiIrjipqakwGo0oLCxESkqK3yMhIUEpt3btWuXnsrIy7NmzB926dQMAdOvWDWvWrPE77po1a9C5c2dotVr07NkTPp/Pb0wSEf16sYWIiK444eHhePLJJzF16lT4fD5cf/31sNvtWLNmDSwWC5KSkgAAM2fOROvWrRETE4M//vGPiIqKwujRowEATzzxBPr164eXX34Zd955J/Lz8zFr1iy8//77AID27dtj3LhxmDBhAt555x307t0bhw8fRnFxMe644w61Tp2ImgkDERFdkV5++WW0adMG2dnZOHDgACIiItCnTx8899xzSpfVq6++iscffxx79+7FVVddhf/9738wGAwAgD59+uDzzz/HCy+8gJdffhlt27bFzJkzMX78eOU9Zs+ejeeeew6PPPIITp06hcTERDz33HNqnC4RNTPOMiOiX536GWBlZWWIiIhQuzpEdAXgGCIiIiIKegxEREREFPTYZUZERERBjy1EREREFPQYiIiIiCjoMRARERFR0GMgIiIioqDHQERERERBj4GIiIiIgh4DEREREQU9BiIiIiIKegxEREREFPT+Pwgeqd4GN6liAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpmodel_history.history['loss'])\n",
    "plt.plot(fpmodel_history.history['val_loss'])\n",
    "plt.title('fp model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(\"fp model loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aac71b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_logf = fpmodel.predict([x_val, inputs2decoder_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "09c15b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1759.7743, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "evaluate_NPLL(targets=x_val, pred_logrates=pred_val_logf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149880d",
   "metadata": {},
   "source": [
    "# test increase latent dimension(same as decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a72f3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "767e1ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs2decoder_train shape:  (136, 73, 1024)\n",
      "inputs2decoder_val shape:  (17, 73, 1024)\n"
     ]
    }
   ],
   "source": [
    "inputs2decoder_latent1024_train, inputs2decoder_latent1024_val = get_decoder_input(decoder_dim=decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f0b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_latent1024_model = create_fpmodel(decoder_dim = decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a6cb546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)          [(None, 73, 70)]     0           []                               \n",
      "                                                                                                  \n",
      " initial_dropout (Dropout)      (None, 73, 70)       0           ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder_BidirectionalGRU (Bidi  [(None, 128),       52224       ['initial_dropout[0][0]']        \n",
      " rectional)                      (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " postencoder_dropout (Dropout)  (None, 128)          0           ['Encoder_BidirectionalGRU[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, 73, 1024)]   0           []                               \n",
      "                                                                                                  \n",
      " dense_latent (Dense)           (None, 1024)         132096      ['postencoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " DecoderGRU (GRU)               (None, 73, 1024)     6297600     ['input_21[0][0]',               \n",
      "                                                                  'dense_latent[0][0]']           \n",
      "                                                                                                  \n",
      " postdecoder_dropout (Dropout)  (None, 73, 1024)     0           ['DecoderGRU[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 73, 4)        4096        ['postdecoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " nerual_dense (Dense)           (None, 73, 70)       350         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,486,366\n",
      "Trainable params: 6,486,366\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fp_latent1024_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c18c6c",
   "metadata": {},
   "source": [
    "# train\n",
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8cb75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(\"fp_log.csv\", separator=\",\", append=False)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"lfadfp.h5\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    save_weights_only= False\n",
    ")\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lfadfp_latent1024_callbacks=[csv_logger, model_check, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d4e61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-2,\n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c8890a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_latent1024_model.compile(\n",
    "    loss = poisson_loglike_loss,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ed983a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 129088.5312 - val_loss: 2420215.7500\n",
      "Epoch 2/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 330723.5938 - val_loss: 31206.8008\n",
      "Epoch 3/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 94528.8359 - val_loss: 10459.7051\n",
      "Epoch 4/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 8259.1641 - val_loss: 4270.5562\n",
      "Epoch 5/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 4032.0286 - val_loss: 3412.8433\n",
      "Epoch 6/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 3379.5310 - val_loss: 3161.7307\n",
      "Epoch 7/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 3154.5249 - val_loss: 3022.8486\n",
      "Epoch 8/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 3024.3691 - val_loss: 2926.9797\n",
      "Epoch 9/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2941.1965 - val_loss: 2852.9690\n",
      "Epoch 10/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2873.6975 - val_loss: 2790.6533\n",
      "Epoch 11/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2809.4551 - val_loss: 2736.7908\n",
      "Epoch 12/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2753.8816 - val_loss: 2690.3296\n",
      "Epoch 13/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2715.9434 - val_loss: 2651.0513\n",
      "Epoch 14/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2681.6118 - val_loss: 2618.5510\n",
      "Epoch 15/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2646.3767 - val_loss: 2589.9124\n",
      "Epoch 16/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2616.5486 - val_loss: 2563.9209\n",
      "Epoch 17/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2586.1409 - val_loss: 2539.8965\n",
      "Epoch 18/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2560.7756 - val_loss: 2516.7881\n",
      "Epoch 19/10000\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 2537.7766 - val_loss: 2495.3367\n",
      "Epoch 20/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2516.7285 - val_loss: 2475.7209\n",
      "Epoch 21/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2495.4939 - val_loss: 2457.1814\n",
      "Epoch 22/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2474.2109 - val_loss: 2439.6133\n",
      "Epoch 23/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2456.1208 - val_loss: 2423.1025\n",
      "Epoch 24/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2439.3958 - val_loss: 2407.9971\n",
      "Epoch 25/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2425.7412 - val_loss: 2393.9265\n",
      "Epoch 26/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2410.2546 - val_loss: 2380.3464\n",
      "Epoch 27/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2395.5063 - val_loss: 2367.4912\n",
      "Epoch 28/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2384.0300 - val_loss: 2355.4663\n",
      "Epoch 29/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2369.6167 - val_loss: 2343.9290\n",
      "Epoch 30/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2358.4902 - val_loss: 2332.8613\n",
      "Epoch 31/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2348.3020 - val_loss: 2322.3391\n",
      "Epoch 32/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2336.1621 - val_loss: 2312.1907\n",
      "Epoch 33/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2324.0886 - val_loss: 2302.4146\n",
      "Epoch 34/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2313.5718 - val_loss: 2293.0464\n",
      "Epoch 35/10000\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 2304.8616 - val_loss: 2284.4343\n",
      "Epoch 36/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2293.7732 - val_loss: 2276.1204\n",
      "Epoch 37/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2284.8726 - val_loss: 2268.1819\n",
      "Epoch 38/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2275.7754 - val_loss: 2260.7490\n",
      "Epoch 39/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2269.3120 - val_loss: 2253.9807\n",
      "Epoch 40/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2263.7715 - val_loss: 2247.2229\n",
      "Epoch 41/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2256.4712 - val_loss: 2241.4385\n",
      "Epoch 42/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2251.2690 - val_loss: 2235.5447\n",
      "Epoch 43/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2240.9258 - val_loss: 2229.9236\n",
      "Epoch 44/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2237.7715 - val_loss: 2224.4138\n",
      "Epoch 45/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2232.0552 - val_loss: 2219.1360\n",
      "Epoch 46/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2225.8301 - val_loss: 2214.2644\n",
      "Epoch 47/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2219.8572 - val_loss: 2209.6233\n",
      "Epoch 48/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2217.8379 - val_loss: 2205.0361\n",
      "Epoch 49/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2210.8855 - val_loss: 2200.6599\n",
      "Epoch 50/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2205.6538 - val_loss: 2196.1887\n",
      "Epoch 51/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2200.3926 - val_loss: 2191.8325\n",
      "Epoch 52/10000\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 2198.0364 - val_loss: 2187.8967\n",
      "Epoch 53/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2193.5864 - val_loss: 2184.0132\n",
      "Epoch 54/10000\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 2188.5737 - val_loss: 2180.1201\n",
      "Epoch 55/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2186.3945 - val_loss: 2176.4668\n",
      "Epoch 56/10000\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 2182.6824 - val_loss: 2172.9111\n",
      "Epoch 57/10000\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 2176.8423 - val_loss: 2169.5278\n",
      "Epoch 58/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2171.9409 - val_loss: 2166.0784\n",
      "Epoch 59/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2170.1221 - val_loss: 2162.8340\n",
      "Epoch 60/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2166.5088 - val_loss: 2159.4143\n",
      "Epoch 61/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2165.3438 - val_loss: 2156.5112\n",
      "Epoch 62/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2161.0911 - val_loss: 2153.5947\n",
      "Epoch 63/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2156.0330 - val_loss: 2150.6074\n",
      "Epoch 64/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2153.2991 - val_loss: 2147.4451\n",
      "Epoch 65/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 2151.4834 - val_loss: 2144.6465\n",
      "Epoch 66/10000\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 2149.6592 - val_loss: 2141.9829\n",
      "Epoch 67/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2145.5930 - val_loss: 2139.2373\n",
      "Epoch 68/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2143.6411 - val_loss: 2136.5603\n",
      "Epoch 69/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2141.6030 - val_loss: 2133.9824\n",
      "Epoch 70/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2136.4985 - val_loss: 2131.2939\n",
      "Epoch 71/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2133.7683 - val_loss: 2128.9143\n",
      "Epoch 72/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2132.8652 - val_loss: 2126.2917\n",
      "Epoch 73/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2130.1426 - val_loss: 2124.1233\n",
      "Epoch 74/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2126.7407 - val_loss: 2121.5103\n",
      "Epoch 75/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2126.1147 - val_loss: 2119.3386\n",
      "Epoch 76/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2121.6140 - val_loss: 2117.0129\n",
      "Epoch 77/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2118.8293 - val_loss: 2114.9668\n",
      "Epoch 78/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2117.5193 - val_loss: 2112.1265\n",
      "Epoch 79/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2116.0386 - val_loss: 2110.2090\n",
      "Epoch 80/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2112.5789 - val_loss: 2108.0974\n",
      "Epoch 81/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 2109.8245 - val_loss: 2105.7671\n",
      "Epoch 82/10000\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 2108.8843 - val_loss: 2103.5261\n",
      "Epoch 83/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2106.1096 - val_loss: 2101.4824\n",
      "Epoch 84/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2104.4780 - val_loss: 2099.2632\n",
      "Epoch 85/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2101.2830 - val_loss: 2097.1118\n",
      "Epoch 86/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2100.6570 - val_loss: 2095.1313\n",
      "Epoch 87/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2097.3245 - val_loss: 2093.3000\n",
      "Epoch 88/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2096.4148 - val_loss: 2091.1292\n",
      "Epoch 89/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2094.6404 - val_loss: 2089.2400\n",
      "Epoch 90/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2092.2461 - val_loss: 2086.5583\n",
      "Epoch 91/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2089.3960 - val_loss: 2084.5671\n",
      "Epoch 92/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2089.7104 - val_loss: 2082.6819\n",
      "Epoch 93/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2086.1604 - val_loss: 2080.8582\n",
      "Epoch 94/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2082.3916 - val_loss: 2078.9502\n",
      "Epoch 95/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2081.5591 - val_loss: 2076.9629\n",
      "Epoch 96/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2079.6208 - val_loss: 2074.9258\n",
      "Epoch 97/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 2078.1609 - val_loss: 2072.9475\n",
      "Epoch 98/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2075.3337 - val_loss: 2071.3149\n",
      "Epoch 99/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2074.3887 - val_loss: 2069.5830\n",
      "Epoch 100/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2072.3542 - val_loss: 2067.7205\n",
      "Epoch 101/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2071.3530 - val_loss: 2065.7825\n",
      "Epoch 102/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2069.5427 - val_loss: 2063.8003\n",
      "Epoch 103/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2067.4045 - val_loss: 2062.0244\n",
      "Epoch 104/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 2064.3691 - val_loss: 2060.1504\n",
      "Epoch 105/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 2064.3826 - val_loss: 2058.6033\n",
      "Epoch 106/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 2060.1833 - val_loss: 2056.6594\n",
      "Epoch 107/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2059.6689 - val_loss: 2054.6897\n",
      "Epoch 108/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2057.3889 - val_loss: 2053.0276\n",
      "Epoch 109/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2055.0242 - val_loss: 2051.6028\n",
      "Epoch 110/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 2052.9387 - val_loss: 2049.8777\n",
      "Epoch 111/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2053.2664 - val_loss: 2048.0156\n",
      "Epoch 112/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 2051.1504 - val_loss: 2045.5687\n",
      "Epoch 113/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 2049.2346 - val_loss: 2043.8536\n",
      "Epoch 114/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2047.3492 - val_loss: 2041.9995\n",
      "Epoch 115/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2045.0184 - val_loss: 2040.9268\n",
      "Epoch 116/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 2043.0138 - val_loss: 2038.9464\n",
      "Epoch 117/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 2041.8875 - val_loss: 2037.0771\n",
      "Epoch 118/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2039.2247 - val_loss: 2035.3201\n",
      "Epoch 119/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2039.0476 - val_loss: 2033.5969\n",
      "Epoch 120/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2035.9683 - val_loss: 2031.7388\n",
      "Epoch 121/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2035.4855 - val_loss: 2029.9513\n",
      "Epoch 122/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2033.8964 - val_loss: 2028.1315\n",
      "Epoch 123/10000\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 2032.0623 - val_loss: 2026.4347\n",
      "Epoch 124/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2029.3920 - val_loss: 2024.4117\n",
      "Epoch 125/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 2028.5106 - val_loss: 2022.9026\n",
      "Epoch 126/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2026.9639 - val_loss: 2021.1071\n",
      "Epoch 127/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2025.7645 - val_loss: 2019.1742\n",
      "Epoch 128/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 2021.8893 - val_loss: 2017.5815\n",
      "Epoch 129/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2019.8469 - val_loss: 2015.6128\n",
      "Epoch 130/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2019.3334 - val_loss: 2013.8474\n",
      "Epoch 131/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2016.9690 - val_loss: 2012.3120\n",
      "Epoch 132/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2015.2941 - val_loss: 2010.5242\n",
      "Epoch 133/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2015.6427 - val_loss: 2008.6971\n",
      "Epoch 134/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 2011.9034 - val_loss: 2006.9789\n",
      "Epoch 135/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2010.3065 - val_loss: 2005.1932\n",
      "Epoch 136/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2010.1356 - val_loss: 2003.0685\n",
      "Epoch 137/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2007.0216 - val_loss: 2001.3394\n",
      "Epoch 138/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 2006.8167 - val_loss: 1999.5498\n",
      "Epoch 139/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 2005.3911 - val_loss: 1998.0992\n",
      "Epoch 140/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 2002.4279 - val_loss: 1996.3331\n",
      "Epoch 141/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 2000.6436 - val_loss: 1994.3802\n",
      "Epoch 142/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1999.4742 - val_loss: 1992.4028\n",
      "Epoch 143/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1997.7451 - val_loss: 1990.8258\n",
      "Epoch 144/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1996.7120 - val_loss: 1988.8325\n",
      "Epoch 145/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1995.3279 - val_loss: 1987.2831\n",
      "Epoch 146/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 1991.4440 - val_loss: 1985.5958\n",
      "Epoch 147/10000\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 1991.7693 - val_loss: 1983.5830\n",
      "Epoch 148/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1988.9818 - val_loss: 1981.8969\n",
      "Epoch 149/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1987.0844 - val_loss: 1980.8070\n",
      "Epoch 150/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1986.5175 - val_loss: 1979.1174\n",
      "Epoch 151/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1983.4329 - val_loss: 1977.0281\n",
      "Epoch 152/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1983.9685 - val_loss: 1975.4524\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 56ms/step - loss: 1979.5750 - val_loss: 1973.6349\n",
      "Epoch 154/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1978.6310 - val_loss: 1971.4888\n",
      "Epoch 155/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1978.0721 - val_loss: 1969.7180\n",
      "Epoch 156/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1976.4807 - val_loss: 1968.2651\n",
      "Epoch 157/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1975.1903 - val_loss: 1966.7880\n",
      "Epoch 158/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1973.9401 - val_loss: 1964.6370\n",
      "Epoch 159/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1972.1104 - val_loss: 1963.0125\n",
      "Epoch 160/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1970.1091 - val_loss: 1961.3654\n",
      "Epoch 161/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1969.0497 - val_loss: 1959.7289\n",
      "Epoch 162/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1967.1716 - val_loss: 1958.1351\n",
      "Epoch 163/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1964.9896 - val_loss: 1956.1995\n",
      "Epoch 164/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1962.7906 - val_loss: 1954.9235\n",
      "Epoch 165/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1962.8479 - val_loss: 1952.8656\n",
      "Epoch 166/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1960.9559 - val_loss: 1951.1107\n",
      "Epoch 167/10000\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 1959.7838 - val_loss: 1949.6307\n",
      "Epoch 168/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1958.8120 - val_loss: 1948.2024\n",
      "Epoch 169/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1956.5128 - val_loss: 1946.4542\n",
      "Epoch 170/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1955.4049 - val_loss: 1944.7654\n",
      "Epoch 171/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1952.5443 - val_loss: 1943.0857\n",
      "Epoch 172/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1951.5073 - val_loss: 1942.0471\n",
      "Epoch 173/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1951.7411 - val_loss: 1940.0034\n",
      "Epoch 174/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1948.8175 - val_loss: 1938.3309\n",
      "Epoch 175/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1947.8021 - val_loss: 1936.8815\n",
      "Epoch 176/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1946.9550 - val_loss: 1935.1221\n",
      "Epoch 177/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1945.0002 - val_loss: 1934.0308\n",
      "Epoch 178/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1943.5170 - val_loss: 1931.9993\n",
      "Epoch 179/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1943.0073 - val_loss: 1930.6318\n",
      "Epoch 180/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1940.5557 - val_loss: 1929.1268\n",
      "Epoch 181/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1940.9460 - val_loss: 1927.6843\n",
      "Epoch 182/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1938.8440 - val_loss: 1926.4182\n",
      "Epoch 183/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1936.9873 - val_loss: 1925.2438\n",
      "Epoch 184/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1936.4550 - val_loss: 1923.5156\n",
      "Epoch 185/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1934.0034 - val_loss: 1922.2881\n",
      "Epoch 186/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1935.1344 - val_loss: 1921.1526\n",
      "Epoch 187/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1932.5381 - val_loss: 1919.7762\n",
      "Epoch 188/10000\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 1930.5869 - val_loss: 1918.6437\n",
      "Epoch 189/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1931.1261 - val_loss: 1917.2180\n",
      "Epoch 190/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1928.2982 - val_loss: 1916.2577\n",
      "Epoch 191/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1926.9062 - val_loss: 1915.3822\n",
      "Epoch 192/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1926.8834 - val_loss: 1913.6960\n",
      "Epoch 193/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1927.6740 - val_loss: 1912.4954\n",
      "Epoch 194/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1926.4712 - val_loss: 1912.1672\n",
      "Epoch 195/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1924.5834 - val_loss: 1910.6338\n",
      "Epoch 196/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1922.9841 - val_loss: 1909.3628\n",
      "Epoch 197/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1922.5044 - val_loss: 1908.7991\n",
      "Epoch 198/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1922.6315 - val_loss: 1907.6371\n",
      "Epoch 199/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1919.9664 - val_loss: 1906.3949\n",
      "Epoch 200/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1920.2505 - val_loss: 1905.7715\n",
      "Epoch 201/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1919.2825 - val_loss: 1904.2726\n",
      "Epoch 202/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1917.0206 - val_loss: 1903.4861\n",
      "Epoch 203/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1917.7791 - val_loss: 1902.4075\n",
      "Epoch 204/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1916.0195 - val_loss: 1901.4639\n",
      "Epoch 205/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1915.4573 - val_loss: 1900.7271\n",
      "Epoch 206/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1915.0659 - val_loss: 1899.7891\n",
      "Epoch 207/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1914.8552 - val_loss: 1898.6290\n",
      "Epoch 208/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1912.8533 - val_loss: 1897.9716\n",
      "Epoch 209/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1913.3859 - val_loss: 1897.1858\n",
      "Epoch 210/10000\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 1910.8359 - val_loss: 1896.3563\n",
      "Epoch 211/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1910.1548 - val_loss: 1895.6840\n",
      "Epoch 212/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1910.2798 - val_loss: 1894.6840\n",
      "Epoch 213/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1909.9348 - val_loss: 1893.9965\n",
      "Epoch 214/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1908.5162 - val_loss: 1892.9425\n",
      "Epoch 215/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1907.8369 - val_loss: 1892.3676\n",
      "Epoch 216/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1907.3524 - val_loss: 1891.4482\n",
      "Epoch 217/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1906.6183 - val_loss: 1891.2750\n",
      "Epoch 218/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1905.5172 - val_loss: 1890.0048\n",
      "Epoch 219/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1905.7904 - val_loss: 1890.0519\n",
      "Epoch 220/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1904.6224 - val_loss: 1889.4442\n",
      "Epoch 221/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1903.9258 - val_loss: 1887.8463\n",
      "Epoch 222/10000\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 1902.8859 - val_loss: 1887.6493\n",
      "Epoch 223/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1902.3357 - val_loss: 1886.7877\n",
      "Epoch 224/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1901.9253 - val_loss: 1886.4990\n",
      "Epoch 225/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1900.7417 - val_loss: 1885.3530\n",
      "Epoch 226/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1901.1334 - val_loss: 1884.9734\n",
      "Epoch 227/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1899.3186 - val_loss: 1884.2015\n",
      "Epoch 228/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1899.9531 - val_loss: 1883.1293\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 45ms/step - loss: 1899.1360 - val_loss: 1883.1335\n",
      "Epoch 230/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1897.4507 - val_loss: 1882.2288\n",
      "Epoch 231/10000\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 1898.0472 - val_loss: 1881.8315\n",
      "Epoch 232/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1897.0448 - val_loss: 1881.2410\n",
      "Epoch 233/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1896.5880 - val_loss: 1880.0323\n",
      "Epoch 234/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1895.4209 - val_loss: 1880.0321\n",
      "Epoch 235/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1896.0581 - val_loss: 1879.2900\n",
      "Epoch 236/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1895.1205 - val_loss: 1878.8378\n",
      "Epoch 237/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1894.8920 - val_loss: 1878.3019\n",
      "Epoch 238/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1894.5996 - val_loss: 1878.2502\n",
      "Epoch 239/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1893.1611 - val_loss: 1876.9515\n",
      "Epoch 240/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1893.5408 - val_loss: 1876.4990\n",
      "Epoch 241/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1892.5435 - val_loss: 1876.0461\n",
      "Epoch 242/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1892.7975 - val_loss: 1875.7587\n",
      "Epoch 243/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1891.7977 - val_loss: 1874.9460\n",
      "Epoch 244/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1891.3054 - val_loss: 1874.7993\n",
      "Epoch 245/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1889.6864 - val_loss: 1874.3311\n",
      "Epoch 246/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1889.5553 - val_loss: 1873.4561\n",
      "Epoch 247/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1888.6962 - val_loss: 1873.3323\n",
      "Epoch 248/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1888.1005 - val_loss: 1872.4888\n",
      "Epoch 249/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1889.9329 - val_loss: 1872.8776\n",
      "Epoch 250/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1886.5319 - val_loss: 1871.6227\n",
      "Epoch 251/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1888.0177 - val_loss: 1871.1327\n",
      "Epoch 252/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1888.2483 - val_loss: 1870.6022\n",
      "Epoch 253/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1886.4489 - val_loss: 1870.3616\n",
      "Epoch 254/10000\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 1886.3147 - val_loss: 1869.8199\n",
      "Epoch 255/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1886.0386 - val_loss: 1869.5925\n",
      "Epoch 256/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1885.7126 - val_loss: 1868.6179\n",
      "Epoch 257/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1884.5801 - val_loss: 1868.8091\n",
      "Epoch 258/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1885.4685 - val_loss: 1867.8196\n",
      "Epoch 259/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1884.3450 - val_loss: 1867.2988\n",
      "Epoch 260/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1884.1113 - val_loss: 1867.2789\n",
      "Epoch 261/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1883.0756 - val_loss: 1866.5623\n",
      "Epoch 262/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1883.0919 - val_loss: 1866.4594\n",
      "Epoch 263/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1882.2725 - val_loss: 1865.4247\n",
      "Epoch 264/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1882.2213 - val_loss: 1865.2096\n",
      "Epoch 265/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1881.3947 - val_loss: 1864.9919\n",
      "Epoch 266/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1880.9578 - val_loss: 1864.1431\n",
      "Epoch 267/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1880.2992 - val_loss: 1864.4446\n",
      "Epoch 268/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1881.4811 - val_loss: 1863.6356\n",
      "Epoch 269/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1879.8914 - val_loss: 1863.3579\n",
      "Epoch 270/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1880.2134 - val_loss: 1862.8322\n",
      "Epoch 271/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1879.3942 - val_loss: 1862.3701\n",
      "Epoch 272/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1880.1584 - val_loss: 1862.6602\n",
      "Epoch 273/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1878.2114 - val_loss: 1861.6904\n",
      "Epoch 274/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1877.4598 - val_loss: 1861.8138\n",
      "Epoch 275/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1877.9103 - val_loss: 1861.0856\n",
      "Epoch 276/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1877.7477 - val_loss: 1860.9795\n",
      "Epoch 277/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1876.1790 - val_loss: 1860.6990\n",
      "Epoch 278/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1876.8555 - val_loss: 1860.3733\n",
      "Epoch 279/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1876.5967 - val_loss: 1860.1304\n",
      "Epoch 280/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1876.1002 - val_loss: 1859.4814\n",
      "Epoch 281/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1875.5636 - val_loss: 1859.8689\n",
      "Epoch 282/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1875.1962 - val_loss: 1859.0503\n",
      "Epoch 283/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1876.1372 - val_loss: 1858.7765\n",
      "Epoch 284/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1874.4327 - val_loss: 1858.8357\n",
      "Epoch 285/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1874.4036 - val_loss: 1857.8796\n",
      "Epoch 286/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1874.3231 - val_loss: 1858.0607\n",
      "Epoch 287/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1874.0957 - val_loss: 1857.8527\n",
      "Epoch 288/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1872.9128 - val_loss: 1857.3767\n",
      "Epoch 289/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1874.8264 - val_loss: 1856.9591\n",
      "Epoch 290/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1872.9374 - val_loss: 1856.4264\n",
      "Epoch 291/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1873.1537 - val_loss: 1856.8948\n",
      "Epoch 292/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1873.3193 - val_loss: 1856.1748\n",
      "Epoch 293/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1874.1433 - val_loss: 1856.1653\n",
      "Epoch 294/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1873.5244 - val_loss: 1855.9218\n",
      "Epoch 295/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1871.5381 - val_loss: 1855.5854\n",
      "Epoch 296/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1870.8241 - val_loss: 1855.5420\n",
      "Epoch 297/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1870.8687 - val_loss: 1855.0898\n",
      "Epoch 298/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1871.0336 - val_loss: 1854.9525\n",
      "Epoch 299/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1870.4911 - val_loss: 1854.4641\n",
      "Epoch 300/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1870.1323 - val_loss: 1854.7267\n",
      "Epoch 301/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1869.9479 - val_loss: 1854.6146\n",
      "Epoch 302/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1870.4084 - val_loss: 1854.1565\n",
      "Epoch 303/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1870.2625 - val_loss: 1853.5841\n",
      "Epoch 304/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1869.7686 - val_loss: 1853.6954\n",
      "Epoch 305/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 56ms/step - loss: 1869.1506 - val_loss: 1852.9138\n",
      "Epoch 306/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1869.4457 - val_loss: 1853.3567\n",
      "Epoch 307/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1868.6643 - val_loss: 1852.9756\n",
      "Epoch 308/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1869.6223 - val_loss: 1852.8765\n",
      "Epoch 309/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1869.2622 - val_loss: 1852.6897\n",
      "Epoch 310/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1867.5677 - val_loss: 1852.4418\n",
      "Epoch 311/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1868.2738 - val_loss: 1852.5479\n",
      "Epoch 312/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1868.6725 - val_loss: 1852.2699\n",
      "Epoch 313/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1867.7408 - val_loss: 1852.1119\n",
      "Epoch 314/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1866.9050 - val_loss: 1851.8049\n",
      "Epoch 315/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1867.4938 - val_loss: 1851.5045\n",
      "Epoch 316/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1867.9717 - val_loss: 1851.5623\n",
      "Epoch 317/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1866.8511 - val_loss: 1851.0258\n",
      "Epoch 318/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1866.3579 - val_loss: 1851.0352\n",
      "Epoch 319/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1865.8036 - val_loss: 1850.6823\n",
      "Epoch 320/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1865.6677 - val_loss: 1850.8047\n",
      "Epoch 321/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1865.1997 - val_loss: 1850.3660\n",
      "Epoch 322/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1865.4550 - val_loss: 1850.2454\n",
      "Epoch 323/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1865.9125 - val_loss: 1849.9949\n",
      "Epoch 324/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1864.7393 - val_loss: 1849.9989\n",
      "Epoch 325/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1865.2888 - val_loss: 1850.0073\n",
      "Epoch 326/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1865.8276 - val_loss: 1849.5389\n",
      "Epoch 327/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1863.9019 - val_loss: 1849.6072\n",
      "Epoch 328/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1864.4509 - val_loss: 1849.7983\n",
      "Epoch 329/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1864.0992 - val_loss: 1849.4374\n",
      "Epoch 330/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1864.6438 - val_loss: 1849.1292\n",
      "Epoch 331/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1864.0413 - val_loss: 1849.8336\n",
      "Epoch 332/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1863.8623 - val_loss: 1848.9111\n",
      "Epoch 333/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1862.6953 - val_loss: 1849.0225\n",
      "Epoch 334/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1863.0483 - val_loss: 1848.7361\n",
      "Epoch 335/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1863.5809 - val_loss: 1848.5173\n",
      "Epoch 336/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1862.1792 - val_loss: 1848.6819\n",
      "Epoch 337/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1862.1182 - val_loss: 1848.1260\n",
      "Epoch 338/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1863.0499 - val_loss: 1848.4490\n",
      "Epoch 339/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1862.3496 - val_loss: 1847.7804\n",
      "Epoch 340/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1862.7631 - val_loss: 1848.0463\n",
      "Epoch 341/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1861.1276 - val_loss: 1847.6782\n",
      "Epoch 342/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1862.1614 - val_loss: 1847.4802\n",
      "Epoch 343/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1861.3658 - val_loss: 1847.8662\n",
      "Epoch 344/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1862.9827 - val_loss: 1847.1978\n",
      "Epoch 345/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1861.9203 - val_loss: 1847.0253\n",
      "Epoch 346/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1861.9897 - val_loss: 1847.2104\n",
      "Epoch 347/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1861.1880 - val_loss: 1846.5364\n",
      "Epoch 348/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1861.0878 - val_loss: 1846.8734\n",
      "Epoch 349/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1860.8708 - val_loss: 1846.7876\n",
      "Epoch 350/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1860.1125 - val_loss: 1846.3694\n",
      "Epoch 351/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1861.1912 - val_loss: 1846.3257\n",
      "Epoch 352/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1859.7850 - val_loss: 1846.6942\n",
      "Epoch 353/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1859.8053 - val_loss: 1846.0619\n",
      "Epoch 354/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1859.9979 - val_loss: 1846.3176\n",
      "Epoch 355/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1860.5746 - val_loss: 1846.2646\n",
      "Epoch 356/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1859.4020 - val_loss: 1846.4215\n",
      "Epoch 357/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1859.1729 - val_loss: 1845.7709\n",
      "Epoch 358/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1858.6052 - val_loss: 1845.7247\n",
      "Epoch 359/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1858.8386 - val_loss: 1845.3652\n",
      "Epoch 360/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1859.0447 - val_loss: 1845.3816\n",
      "Epoch 361/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1858.1720 - val_loss: 1845.4519\n",
      "Epoch 362/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1858.5863 - val_loss: 1844.8568\n",
      "Epoch 363/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1858.4962 - val_loss: 1844.8507\n",
      "Epoch 364/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1858.2617 - val_loss: 1844.6442\n",
      "Epoch 365/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1858.2319 - val_loss: 1844.4131\n",
      "Epoch 366/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1857.4922 - val_loss: 1844.5248\n",
      "Epoch 367/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1858.0946 - val_loss: 1844.7314\n",
      "Epoch 368/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1856.6989 - val_loss: 1843.7990\n",
      "Epoch 369/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1858.4827 - val_loss: 1844.2876\n",
      "Epoch 370/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1856.6731 - val_loss: 1844.0908\n",
      "Epoch 371/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1856.5477 - val_loss: 1843.7557\n",
      "Epoch 372/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1856.5498 - val_loss: 1843.5526\n",
      "Epoch 373/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1855.7817 - val_loss: 1843.3174\n",
      "Epoch 374/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1856.3024 - val_loss: 1843.2158\n",
      "Epoch 375/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1855.3075 - val_loss: 1843.5085\n",
      "Epoch 376/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1855.6150 - val_loss: 1843.3131\n",
      "Epoch 377/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1855.0408 - val_loss: 1842.6652\n",
      "Epoch 378/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1856.1527 - val_loss: 1842.5856\n",
      "Epoch 379/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1855.3975 - val_loss: 1842.2942\n",
      "Epoch 380/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1855.3658 - val_loss: 1842.5742\n",
      "Epoch 381/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 62ms/step - loss: 1854.3467 - val_loss: 1842.1946\n",
      "Epoch 382/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1855.8939 - val_loss: 1841.7401\n",
      "Epoch 383/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1855.8693 - val_loss: 1841.9301\n",
      "Epoch 384/10000\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 1855.7411 - val_loss: 1841.2783\n",
      "Epoch 385/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1855.9280 - val_loss: 1841.3070\n",
      "Epoch 386/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1854.8525 - val_loss: 1841.6376\n",
      "Epoch 387/10000\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 1854.6281 - val_loss: 1841.1315\n",
      "Epoch 388/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1853.4904 - val_loss: 1841.5146\n",
      "Epoch 389/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1854.0464 - val_loss: 1840.8997\n",
      "Epoch 390/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1853.6571 - val_loss: 1840.8833\n",
      "Epoch 391/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1853.5278 - val_loss: 1841.1803\n",
      "Epoch 392/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1853.6757 - val_loss: 1841.4878\n",
      "Epoch 393/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1852.6637 - val_loss: 1841.0499\n",
      "Epoch 394/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1854.6072 - val_loss: 1840.8229\n",
      "Epoch 395/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1853.3035 - val_loss: 1840.5048\n",
      "Epoch 396/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1852.7483 - val_loss: 1840.5137\n",
      "Epoch 397/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1852.7590 - val_loss: 1840.8198\n",
      "Epoch 398/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1853.0364 - val_loss: 1839.5331\n",
      "Epoch 399/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1852.1934 - val_loss: 1839.7719\n",
      "Epoch 400/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1851.7756 - val_loss: 1839.4940\n",
      "Epoch 401/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1852.0096 - val_loss: 1839.9385\n",
      "Epoch 402/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1851.3148 - val_loss: 1839.4747\n",
      "Epoch 403/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1851.7938 - val_loss: 1838.9800\n",
      "Epoch 404/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1851.6791 - val_loss: 1839.8126\n",
      "Epoch 405/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1851.5466 - val_loss: 1839.0166\n",
      "Epoch 406/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1851.2516 - val_loss: 1839.0635\n",
      "Epoch 407/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1851.4989 - val_loss: 1839.0238\n",
      "Epoch 408/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1850.5210 - val_loss: 1838.7280\n",
      "Epoch 409/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1850.9828 - val_loss: 1838.7373\n",
      "Epoch 410/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1852.3693 - val_loss: 1838.6353\n",
      "Epoch 411/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1850.8933 - val_loss: 1838.6418\n",
      "Epoch 412/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1850.8002 - val_loss: 1838.5186\n",
      "Epoch 413/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1850.3748 - val_loss: 1839.1184\n",
      "Epoch 414/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1849.4725 - val_loss: 1838.0400\n",
      "Epoch 415/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1849.2358 - val_loss: 1838.0964\n",
      "Epoch 416/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1848.9828 - val_loss: 1838.1699\n",
      "Epoch 417/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1849.1174 - val_loss: 1837.8002\n",
      "Epoch 418/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1850.0463 - val_loss: 1837.8033\n",
      "Epoch 419/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1849.5276 - val_loss: 1837.8210\n",
      "Epoch 420/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1849.1688 - val_loss: 1837.0088\n",
      "Epoch 421/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1848.8307 - val_loss: 1837.3704\n",
      "Epoch 422/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1848.3262 - val_loss: 1836.7238\n",
      "Epoch 423/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1849.1136 - val_loss: 1836.7544\n",
      "Epoch 424/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1848.9558 - val_loss: 1836.8151\n",
      "Epoch 425/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1848.9836 - val_loss: 1837.0125\n",
      "Epoch 426/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1847.7336 - val_loss: 1836.7268\n",
      "Epoch 427/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1849.0610 - val_loss: 1836.6986\n",
      "Epoch 428/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1847.7815 - val_loss: 1836.1475\n",
      "Epoch 429/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1848.4189 - val_loss: 1836.6000\n",
      "Epoch 430/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1847.5404 - val_loss: 1836.4221\n",
      "Epoch 431/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1847.8339 - val_loss: 1835.9608\n",
      "Epoch 432/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1846.7096 - val_loss: 1836.0865\n",
      "Epoch 433/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1847.5803 - val_loss: 1835.9790\n",
      "Epoch 434/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1846.2040 - val_loss: 1835.3057\n",
      "Epoch 435/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1846.9127 - val_loss: 1835.8083\n",
      "Epoch 436/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1846.5587 - val_loss: 1835.7776\n",
      "Epoch 437/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1846.1289 - val_loss: 1835.8877\n",
      "Epoch 438/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1846.6506 - val_loss: 1835.2240\n",
      "Epoch 439/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1847.0250 - val_loss: 1835.0469\n",
      "Epoch 440/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1846.1531 - val_loss: 1834.9600\n",
      "Epoch 441/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1846.0260 - val_loss: 1835.1232\n",
      "Epoch 442/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1845.0203 - val_loss: 1835.0045\n",
      "Epoch 443/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1845.7025 - val_loss: 1834.8175\n",
      "Epoch 444/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1845.3403 - val_loss: 1834.4575\n",
      "Epoch 445/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1845.9224 - val_loss: 1834.6089\n",
      "Epoch 446/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1844.8136 - val_loss: 1835.0623\n",
      "Epoch 447/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1845.1570 - val_loss: 1834.2496\n",
      "Epoch 448/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1844.8628 - val_loss: 1834.5989\n",
      "Epoch 449/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1844.9208 - val_loss: 1834.3914\n",
      "Epoch 450/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1844.8929 - val_loss: 1833.9875\n",
      "Epoch 451/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1844.8676 - val_loss: 1833.9557\n",
      "Epoch 452/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1844.5381 - val_loss: 1833.6381\n",
      "Epoch 453/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1844.9531 - val_loss: 1833.0641\n",
      "Epoch 454/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1843.7883 - val_loss: 1833.4462\n",
      "Epoch 455/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1844.1030 - val_loss: 1832.8721\n",
      "Epoch 456/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1844.1953 - val_loss: 1833.1820\n",
      "Epoch 457/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 61ms/step - loss: 1844.7607 - val_loss: 1832.4596\n",
      "Epoch 458/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1844.2998 - val_loss: 1833.2883\n",
      "Epoch 459/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1844.7649 - val_loss: 1832.9248\n",
      "Epoch 460/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1843.5238 - val_loss: 1833.3596\n",
      "Epoch 461/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1842.5322 - val_loss: 1833.2395\n",
      "Epoch 462/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1843.4760 - val_loss: 1832.9514\n",
      "Epoch 463/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1842.6443 - val_loss: 1833.4935\n",
      "Epoch 464/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1843.3488 - val_loss: 1832.4354\n",
      "Epoch 465/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1843.0399 - val_loss: 1833.0062\n",
      "Epoch 466/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1841.9641 - val_loss: 1833.0129\n",
      "Epoch 467/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1843.5212 - val_loss: 1832.5193\n",
      "Epoch 468/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1842.7623 - val_loss: 1832.2734\n",
      "Epoch 469/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1842.4948 - val_loss: 1832.4462\n",
      "Epoch 470/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1841.9690 - val_loss: 1832.0001\n",
      "Epoch 471/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1842.0933 - val_loss: 1832.2930\n",
      "Epoch 472/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1842.5850 - val_loss: 1831.9395\n",
      "Epoch 473/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1842.6539 - val_loss: 1832.3802\n",
      "Epoch 474/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1841.2812 - val_loss: 1832.1592\n",
      "Epoch 475/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1841.3573 - val_loss: 1831.3639\n",
      "Epoch 476/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1841.6626 - val_loss: 1831.7365\n",
      "Epoch 477/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1841.9619 - val_loss: 1831.3369\n",
      "Epoch 478/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1841.9880 - val_loss: 1831.1650\n",
      "Epoch 479/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1842.1642 - val_loss: 1831.2290\n",
      "Epoch 480/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1840.8098 - val_loss: 1831.0531\n",
      "Epoch 481/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1840.2423 - val_loss: 1830.8091\n",
      "Epoch 482/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1840.0991 - val_loss: 1830.6111\n",
      "Epoch 483/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1840.4871 - val_loss: 1830.7190\n",
      "Epoch 484/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1839.9609 - val_loss: 1830.9305\n",
      "Epoch 485/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1840.0160 - val_loss: 1830.4050\n",
      "Epoch 486/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1840.9390 - val_loss: 1830.7982\n",
      "Epoch 487/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1840.0087 - val_loss: 1830.0975\n",
      "Epoch 488/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1838.9587 - val_loss: 1829.7286\n",
      "Epoch 489/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1840.2568 - val_loss: 1829.9940\n",
      "Epoch 490/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1839.6646 - val_loss: 1830.2324\n",
      "Epoch 491/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1839.4786 - val_loss: 1829.9690\n",
      "Epoch 492/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1840.1320 - val_loss: 1830.2324\n",
      "Epoch 493/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1839.4175 - val_loss: 1829.9520\n",
      "Epoch 494/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1838.9972 - val_loss: 1829.9733\n",
      "Epoch 495/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1838.5250 - val_loss: 1830.3232\n",
      "Epoch 496/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1839.6029 - val_loss: 1829.2998\n",
      "Epoch 497/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1839.4395 - val_loss: 1830.6240\n",
      "Epoch 498/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1839.3676 - val_loss: 1829.7775\n",
      "Epoch 499/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1839.7249 - val_loss: 1829.1134\n",
      "Epoch 500/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1838.9901 - val_loss: 1829.5544\n",
      "Epoch 501/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1838.6335 - val_loss: 1829.7344\n",
      "Epoch 502/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1838.6674 - val_loss: 1829.0490\n",
      "Epoch 503/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1837.9463 - val_loss: 1829.1377\n",
      "Epoch 504/10000\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 1838.8336 - val_loss: 1828.9495\n",
      "Epoch 505/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1838.4159 - val_loss: 1828.4104\n",
      "Epoch 506/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1838.0477 - val_loss: 1828.9650\n",
      "Epoch 507/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1838.6073 - val_loss: 1828.4902\n",
      "Epoch 508/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1837.0931 - val_loss: 1828.2858\n",
      "Epoch 509/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1838.9268 - val_loss: 1828.6404\n",
      "Epoch 510/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1838.3445 - val_loss: 1828.5435\n",
      "Epoch 511/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1838.2677 - val_loss: 1828.2662\n",
      "Epoch 512/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1837.9773 - val_loss: 1828.7462\n",
      "Epoch 513/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1837.0708 - val_loss: 1828.0725\n",
      "Epoch 514/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1837.2699 - val_loss: 1828.9541\n",
      "Epoch 515/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1838.0261 - val_loss: 1828.5615\n",
      "Epoch 516/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1836.3997 - val_loss: 1827.8041\n",
      "Epoch 517/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1837.9861 - val_loss: 1828.2374\n",
      "Epoch 518/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1837.4901 - val_loss: 1828.1968\n",
      "Epoch 519/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1837.3419 - val_loss: 1827.7762\n",
      "Epoch 520/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1837.0546 - val_loss: 1827.7246\n",
      "Epoch 521/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1837.1793 - val_loss: 1828.0723\n",
      "Epoch 522/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1836.4485 - val_loss: 1827.4298\n",
      "Epoch 523/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1837.4563 - val_loss: 1827.5870\n",
      "Epoch 524/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1837.2579 - val_loss: 1827.9788\n",
      "Epoch 525/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1836.8330 - val_loss: 1828.0824\n",
      "Epoch 526/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1837.4562 - val_loss: 1827.3112\n",
      "Epoch 527/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1836.8046 - val_loss: 1827.4742\n",
      "Epoch 528/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1836.4539 - val_loss: 1827.8324\n",
      "Epoch 529/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1835.6503 - val_loss: 1826.9940\n",
      "Epoch 530/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1836.0709 - val_loss: 1827.1560\n",
      "Epoch 531/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1836.9541 - val_loss: 1827.0168\n",
      "Epoch 532/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1835.9539 - val_loss: 1827.3585\n",
      "Epoch 533/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 41ms/step - loss: 1835.1879 - val_loss: 1827.1018\n",
      "Epoch 534/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1835.8871 - val_loss: 1827.4460\n",
      "Epoch 535/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1835.9769 - val_loss: 1826.6669\n",
      "Epoch 536/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1835.3320 - val_loss: 1826.1852\n",
      "Epoch 537/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1834.9059 - val_loss: 1827.1639\n",
      "Epoch 538/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1834.8744 - val_loss: 1826.3937\n",
      "Epoch 539/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1836.5233 - val_loss: 1826.1683\n",
      "Epoch 540/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1834.9353 - val_loss: 1826.6465\n",
      "Epoch 541/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1835.2333 - val_loss: 1826.3103\n",
      "Epoch 542/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1834.6848 - val_loss: 1826.7134\n",
      "Epoch 543/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1835.3528 - val_loss: 1826.6860\n",
      "Epoch 544/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1835.5458 - val_loss: 1826.2007\n",
      "Epoch 545/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1835.2607 - val_loss: 1826.1167\n",
      "Epoch 546/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1835.3699 - val_loss: 1826.2662\n",
      "Epoch 547/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1835.0234 - val_loss: 1825.3076\n",
      "Epoch 548/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1834.9971 - val_loss: 1825.9396\n",
      "Epoch 549/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1834.8430 - val_loss: 1826.2308\n",
      "Epoch 550/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1834.4258 - val_loss: 1825.8936\n",
      "Epoch 551/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1834.8347 - val_loss: 1825.9463\n",
      "Epoch 552/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1834.4132 - val_loss: 1825.9648\n",
      "Epoch 553/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1834.7678 - val_loss: 1825.8236\n",
      "Epoch 554/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1833.3671 - val_loss: 1825.7228\n",
      "Epoch 555/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1834.5249 - val_loss: 1825.5824\n",
      "Epoch 556/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1832.8975 - val_loss: 1825.7296\n",
      "Epoch 557/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1833.3484 - val_loss: 1825.8110\n",
      "Epoch 558/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1834.5284 - val_loss: 1825.4353\n",
      "Epoch 559/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1832.3759 - val_loss: 1825.6729\n",
      "Epoch 560/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1833.0266 - val_loss: 1826.6500\n",
      "Epoch 561/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1833.9534 - val_loss: 1825.8104\n",
      "Epoch 562/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1833.3463 - val_loss: 1826.0669\n",
      "Epoch 563/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1833.3248 - val_loss: 1826.0742\n",
      "Epoch 564/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1833.5612 - val_loss: 1825.9695\n",
      "Epoch 565/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1833.3728 - val_loss: 1825.8174\n",
      "Epoch 566/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1834.2280 - val_loss: 1825.6525\n",
      "Epoch 567/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1833.2097 - val_loss: 1825.9335\n",
      "Epoch 568/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1833.8713 - val_loss: 1825.8376\n",
      "Epoch 569/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1834.2712 - val_loss: 1825.2406\n",
      "Epoch 570/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1832.5902 - val_loss: 1825.8391\n",
      "Epoch 571/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1832.7441 - val_loss: 1825.1713\n",
      "Epoch 572/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1832.7417 - val_loss: 1824.8000\n",
      "Epoch 573/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1834.3125 - val_loss: 1824.9790\n",
      "Epoch 574/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1833.2139 - val_loss: 1825.1202\n",
      "Epoch 575/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1832.2367 - val_loss: 1825.0242\n",
      "Epoch 576/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1832.4923 - val_loss: 1824.9141\n",
      "Epoch 577/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1832.6353 - val_loss: 1825.0558\n",
      "Epoch 578/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1833.0690 - val_loss: 1825.4924\n",
      "Epoch 579/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1833.0101 - val_loss: 1824.4470\n",
      "Epoch 580/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1832.7639 - val_loss: 1824.3477\n",
      "Epoch 581/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1832.8270 - val_loss: 1824.2909\n",
      "Epoch 582/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1832.4136 - val_loss: 1824.4609\n",
      "Epoch 583/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1832.3531 - val_loss: 1824.9445\n",
      "Epoch 584/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1831.9138 - val_loss: 1824.6307\n",
      "Epoch 585/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1833.7220 - val_loss: 1825.7892\n",
      "Epoch 586/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1830.9779 - val_loss: 1825.0292\n",
      "Epoch 587/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1832.4297 - val_loss: 1824.8550\n",
      "Epoch 588/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1831.6479 - val_loss: 1824.1429\n",
      "Epoch 589/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1832.4922 - val_loss: 1823.8932\n",
      "Epoch 590/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1832.0782 - val_loss: 1825.0212\n",
      "Epoch 591/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1832.1676 - val_loss: 1824.1207\n",
      "Epoch 592/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1831.8030 - val_loss: 1824.2106\n",
      "Epoch 593/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1831.1329 - val_loss: 1823.8232\n",
      "Epoch 594/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1832.0901 - val_loss: 1823.7878\n",
      "Epoch 595/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1831.9592 - val_loss: 1823.9922\n",
      "Epoch 596/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1831.3705 - val_loss: 1824.1442\n",
      "Epoch 597/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1830.6575 - val_loss: 1824.4617\n",
      "Epoch 598/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1831.4307 - val_loss: 1823.3690\n",
      "Epoch 599/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1830.8130 - val_loss: 1823.4608\n",
      "Epoch 600/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1832.5779 - val_loss: 1823.3816\n",
      "Epoch 601/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1831.1414 - val_loss: 1823.8623\n",
      "Epoch 602/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1829.4058 - val_loss: 1823.6437\n",
      "Epoch 603/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1830.3428 - val_loss: 1823.2336\n",
      "Epoch 604/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1831.1603 - val_loss: 1823.7240\n",
      "Epoch 605/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1830.5103 - val_loss: 1824.0925\n",
      "Epoch 606/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1830.4500 - val_loss: 1823.3521\n",
      "Epoch 607/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1830.1099 - val_loss: 1823.0076\n",
      "Epoch 608/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1830.4250 - val_loss: 1823.1559\n",
      "Epoch 609/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 43ms/step - loss: 1831.1801 - val_loss: 1823.6354\n",
      "Epoch 610/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1830.7913 - val_loss: 1823.2573\n",
      "Epoch 611/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1830.3423 - val_loss: 1823.9052\n",
      "Epoch 612/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1829.9783 - val_loss: 1822.8789\n",
      "Epoch 613/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1830.8700 - val_loss: 1823.0560\n",
      "Epoch 614/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1830.6498 - val_loss: 1823.3486\n",
      "Epoch 615/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1829.8531 - val_loss: 1823.0303\n",
      "Epoch 616/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 1830.1062 - val_loss: 1822.3142\n",
      "Epoch 617/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1829.8690 - val_loss: 1823.2466\n",
      "Epoch 618/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1829.9103 - val_loss: 1822.6433\n",
      "Epoch 619/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1829.0817 - val_loss: 1822.4148\n",
      "Epoch 620/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1830.7427 - val_loss: 1823.3571\n",
      "Epoch 621/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1829.1497 - val_loss: 1822.4873\n",
      "Epoch 622/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1829.6487 - val_loss: 1822.4414\n",
      "Epoch 623/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1829.8591 - val_loss: 1823.1168\n",
      "Epoch 624/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1829.0975 - val_loss: 1822.4994\n",
      "Epoch 625/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1828.8422 - val_loss: 1822.8771\n",
      "Epoch 626/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1829.5902 - val_loss: 1822.3948\n",
      "Epoch 627/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1829.6991 - val_loss: 1822.9797\n",
      "Epoch 628/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1828.9054 - val_loss: 1822.7151\n",
      "Epoch 629/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1829.7979 - val_loss: 1822.9698\n",
      "Epoch 630/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1828.7959 - val_loss: 1822.9512\n",
      "Epoch 631/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1828.9460 - val_loss: 1822.6799\n",
      "Epoch 632/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1829.0485 - val_loss: 1822.4017\n",
      "Epoch 633/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1828.4316 - val_loss: 1822.7637\n",
      "Epoch 634/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1828.7627 - val_loss: 1822.2823\n",
      "Epoch 635/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1826.6682 - val_loss: 1822.3904\n",
      "Epoch 636/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1828.1079 - val_loss: 1821.7783\n",
      "Epoch 637/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1828.6396 - val_loss: 1822.2913\n",
      "Epoch 638/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1828.7168 - val_loss: 1822.2944\n",
      "Epoch 639/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1828.5361 - val_loss: 1821.8875\n",
      "Epoch 640/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1829.0929 - val_loss: 1822.1113\n",
      "Epoch 641/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1827.6998 - val_loss: 1821.9684\n",
      "Epoch 642/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1828.9792 - val_loss: 1822.1263\n",
      "Epoch 643/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1828.4568 - val_loss: 1821.9937\n",
      "Epoch 644/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1828.7061 - val_loss: 1821.5115\n",
      "Epoch 645/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1828.4525 - val_loss: 1821.1676\n",
      "Epoch 646/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1828.1935 - val_loss: 1822.5999\n",
      "Epoch 647/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1827.7124 - val_loss: 1821.2078\n",
      "Epoch 648/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1828.4724 - val_loss: 1821.0483\n",
      "Epoch 649/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1828.0753 - val_loss: 1821.5271\n",
      "Epoch 650/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1828.1907 - val_loss: 1821.0048\n",
      "Epoch 651/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1828.3549 - val_loss: 1821.1311\n",
      "Epoch 652/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1827.8289 - val_loss: 1821.6919\n",
      "Epoch 653/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1828.1727 - val_loss: 1821.6327\n",
      "Epoch 654/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1828.8191 - val_loss: 1821.3074\n",
      "Epoch 655/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1827.3789 - val_loss: 1822.0325\n",
      "Epoch 656/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1827.1056 - val_loss: 1821.2686\n",
      "Epoch 657/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1827.3488 - val_loss: 1821.5764\n",
      "Epoch 658/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1827.4919 - val_loss: 1821.0575\n",
      "Epoch 659/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1827.3717 - val_loss: 1820.7433\n",
      "Epoch 660/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1827.7357 - val_loss: 1821.0541\n",
      "Epoch 661/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1827.7874 - val_loss: 1820.8517\n",
      "Epoch 662/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1826.6459 - val_loss: 1820.9941\n",
      "Epoch 663/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1826.6123 - val_loss: 1821.4073\n",
      "Epoch 664/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1827.4846 - val_loss: 1820.9130\n",
      "Epoch 665/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1826.4873 - val_loss: 1821.2854\n",
      "Epoch 666/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1826.8079 - val_loss: 1820.7534\n",
      "Epoch 667/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1826.0814 - val_loss: 1820.6735\n",
      "Epoch 668/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1827.1765 - val_loss: 1820.0186\n",
      "Epoch 669/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1827.8755 - val_loss: 1820.5625\n",
      "Epoch 670/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1826.8275 - val_loss: 1820.3994\n",
      "Epoch 671/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1826.6077 - val_loss: 1820.3666\n",
      "Epoch 672/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1826.4305 - val_loss: 1819.8495\n",
      "Epoch 673/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1827.3740 - val_loss: 1820.0969\n",
      "Epoch 674/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1827.5341 - val_loss: 1820.4218\n",
      "Epoch 675/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1827.3364 - val_loss: 1820.0737\n",
      "Epoch 676/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.9775 - val_loss: 1820.3608\n",
      "Epoch 677/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1826.2000 - val_loss: 1820.4529\n",
      "Epoch 678/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1826.6107 - val_loss: 1819.9703\n",
      "Epoch 679/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1825.6942 - val_loss: 1820.2848\n",
      "Epoch 680/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1827.2839 - val_loss: 1820.4658\n",
      "Epoch 681/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1826.0978 - val_loss: 1819.5363\n",
      "Epoch 682/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1826.2720 - val_loss: 1820.4254\n",
      "Epoch 683/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1826.9427 - val_loss: 1820.1558\n",
      "Epoch 684/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1826.3163 - val_loss: 1820.7178\n",
      "Epoch 685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 57ms/step - loss: 1825.7207 - val_loss: 1819.2292\n",
      "Epoch 686/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.7484 - val_loss: 1819.3643\n",
      "Epoch 687/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.6002 - val_loss: 1820.0854\n",
      "Epoch 688/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1825.5331 - val_loss: 1820.3303\n",
      "Epoch 689/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1825.5494 - val_loss: 1819.6608\n",
      "Epoch 690/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1826.2686 - val_loss: 1819.8103\n",
      "Epoch 691/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1826.0276 - val_loss: 1818.9366\n",
      "Epoch 692/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1825.4542 - val_loss: 1820.1500\n",
      "Epoch 693/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1826.7611 - val_loss: 1819.5195\n",
      "Epoch 694/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1825.0166 - val_loss: 1819.7098\n",
      "Epoch 695/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.4320 - val_loss: 1819.6951\n",
      "Epoch 696/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1825.8527 - val_loss: 1819.0820\n",
      "Epoch 697/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1825.3146 - val_loss: 1819.2484\n",
      "Epoch 698/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1825.4836 - val_loss: 1819.4220\n",
      "Epoch 699/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1826.4497 - val_loss: 1819.4441\n",
      "Epoch 700/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1824.0870 - val_loss: 1819.3954\n",
      "Epoch 701/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1824.8342 - val_loss: 1818.9232\n",
      "Epoch 702/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1825.1498 - val_loss: 1819.4250\n",
      "Epoch 703/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1824.8873 - val_loss: 1819.5730\n",
      "Epoch 704/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1825.3368 - val_loss: 1819.2096\n",
      "Epoch 705/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1824.1074 - val_loss: 1819.1866\n",
      "Epoch 706/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1824.7279 - val_loss: 1819.0931\n",
      "Epoch 707/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1824.1516 - val_loss: 1818.9269\n",
      "Epoch 708/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1825.5192 - val_loss: 1818.7560\n",
      "Epoch 709/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1824.7341 - val_loss: 1818.9150\n",
      "Epoch 710/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1824.4890 - val_loss: 1818.9674\n",
      "Epoch 711/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1824.5752 - val_loss: 1819.7073\n",
      "Epoch 712/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1825.3076 - val_loss: 1819.4077\n",
      "Epoch 713/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1824.0184 - val_loss: 1820.9614\n",
      "Epoch 714/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1824.4799 - val_loss: 1820.2321\n",
      "Epoch 715/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1824.0853 - val_loss: 1819.4747\n",
      "Epoch 716/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1824.4385 - val_loss: 1820.7560\n",
      "Epoch 717/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1824.4696 - val_loss: 1819.5850\n",
      "Epoch 718/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1824.0389 - val_loss: 1819.2196\n",
      "Epoch 719/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1823.8457 - val_loss: 1819.6282\n",
      "Epoch 720/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1824.1061 - val_loss: 1819.0686\n",
      "Epoch 721/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1823.3499 - val_loss: 1819.3248\n",
      "Epoch 722/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1824.0160 - val_loss: 1818.5868\n",
      "Epoch 723/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1824.9247 - val_loss: 1818.8292\n",
      "Epoch 724/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1824.2283 - val_loss: 1819.5597\n",
      "Epoch 725/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1823.7148 - val_loss: 1818.7002\n",
      "Epoch 726/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1823.7271 - val_loss: 1819.2892\n",
      "Epoch 727/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1822.9269 - val_loss: 1817.9261\n",
      "Epoch 728/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1825.2501 - val_loss: 1818.6459\n",
      "Epoch 729/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1822.8873 - val_loss: 1818.0142\n",
      "Epoch 730/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1823.7686 - val_loss: 1818.1836\n",
      "Epoch 731/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1823.4218 - val_loss: 1818.0455\n",
      "Epoch 732/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1822.9678 - val_loss: 1817.9310\n",
      "Epoch 733/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1824.1484 - val_loss: 1818.2506\n",
      "Epoch 734/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1823.2362 - val_loss: 1817.9373\n",
      "Epoch 735/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1822.7664 - val_loss: 1818.0027\n",
      "Epoch 736/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1822.8282 - val_loss: 1818.5605\n",
      "Epoch 737/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1823.2288 - val_loss: 1818.4546\n",
      "Epoch 738/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1822.9025 - val_loss: 1818.7861\n",
      "Epoch 739/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1821.3107 - val_loss: 1818.6111\n",
      "Epoch 740/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1822.8136 - val_loss: 1818.1010\n",
      "Epoch 741/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1822.7322 - val_loss: 1817.8324\n",
      "Epoch 742/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1823.0571 - val_loss: 1817.6361\n",
      "Epoch 743/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1822.7483 - val_loss: 1818.0006\n",
      "Epoch 744/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1823.1064 - val_loss: 1817.3210\n",
      "Epoch 745/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1822.9323 - val_loss: 1817.5288\n",
      "Epoch 746/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1822.0596 - val_loss: 1818.3092\n",
      "Epoch 747/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1822.8013 - val_loss: 1817.1396\n",
      "Epoch 748/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1823.3275 - val_loss: 1817.2081\n",
      "Epoch 749/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1821.9875 - val_loss: 1816.9493\n",
      "Epoch 750/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1823.0486 - val_loss: 1817.3129\n",
      "Epoch 751/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1822.4321 - val_loss: 1816.8182\n",
      "Epoch 752/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1821.2111 - val_loss: 1817.0269\n",
      "Epoch 753/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1821.7988 - val_loss: 1816.9124\n",
      "Epoch 754/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1822.4753 - val_loss: 1817.3529\n",
      "Epoch 755/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1821.3302 - val_loss: 1816.1807\n",
      "Epoch 756/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1821.6582 - val_loss: 1816.3625\n",
      "Epoch 757/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1822.2135 - val_loss: 1816.1495\n",
      "Epoch 758/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1821.4010 - val_loss: 1816.5211\n",
      "Epoch 759/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1821.3737 - val_loss: 1816.3694\n",
      "Epoch 760/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1822.1715 - val_loss: 1816.2976\n",
      "Epoch 761/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 39ms/step - loss: 1821.2815 - val_loss: 1816.2806\n",
      "Epoch 762/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1821.7336 - val_loss: 1816.0975\n",
      "Epoch 763/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1820.7063 - val_loss: 1816.1506\n",
      "Epoch 764/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1821.0751 - val_loss: 1815.9810\n",
      "Epoch 765/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1820.8770 - val_loss: 1816.1537\n",
      "Epoch 766/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1821.0165 - val_loss: 1815.8879\n",
      "Epoch 767/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1821.1096 - val_loss: 1815.9187\n",
      "Epoch 768/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1821.5176 - val_loss: 1815.8258\n",
      "Epoch 769/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1821.4824 - val_loss: 1815.2588\n",
      "Epoch 770/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1820.8994 - val_loss: 1816.4469\n",
      "Epoch 771/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1821.1370 - val_loss: 1815.7323\n",
      "Epoch 772/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1821.3007 - val_loss: 1816.5914\n",
      "Epoch 773/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1821.0834 - val_loss: 1815.7861\n",
      "Epoch 774/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1820.4061 - val_loss: 1815.8870\n",
      "Epoch 775/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1820.3864 - val_loss: 1815.8987\n",
      "Epoch 776/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1820.6879 - val_loss: 1815.8656\n",
      "Epoch 777/10000\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 1820.2252 - val_loss: 1815.1152\n",
      "Epoch 778/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1821.1656 - val_loss: 1815.7711\n",
      "Epoch 779/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1820.6233 - val_loss: 1815.2200\n",
      "Epoch 780/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1821.2382 - val_loss: 1815.8147\n",
      "Epoch 781/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1820.9026 - val_loss: 1815.5779\n",
      "Epoch 782/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1819.7186 - val_loss: 1815.1731\n",
      "Epoch 783/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1820.4946 - val_loss: 1815.0190\n",
      "Epoch 784/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1820.2217 - val_loss: 1815.2087\n",
      "Epoch 785/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1819.9694 - val_loss: 1815.0105\n",
      "Epoch 786/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1820.2987 - val_loss: 1815.7681\n",
      "Epoch 787/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1820.1888 - val_loss: 1814.8877\n",
      "Epoch 788/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1819.7728 - val_loss: 1815.1765\n",
      "Epoch 789/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1819.8860 - val_loss: 1814.6154\n",
      "Epoch 790/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1819.2858 - val_loss: 1815.5752\n",
      "Epoch 791/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1818.8096 - val_loss: 1814.7205\n",
      "Epoch 792/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1818.5837 - val_loss: 1814.7161\n",
      "Epoch 793/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1818.7693 - val_loss: 1814.7166\n",
      "Epoch 794/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1819.9570 - val_loss: 1814.8481\n",
      "Epoch 795/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1819.9274 - val_loss: 1814.3778\n",
      "Epoch 796/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1818.3859 - val_loss: 1814.5568\n",
      "Epoch 797/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1818.4783 - val_loss: 1814.5439\n",
      "Epoch 798/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1818.5328 - val_loss: 1814.7607\n",
      "Epoch 799/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1819.5195 - val_loss: 1814.9901\n",
      "Epoch 800/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1819.2499 - val_loss: 1813.7662\n",
      "Epoch 801/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1818.4346 - val_loss: 1814.7091\n",
      "Epoch 802/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1819.4791 - val_loss: 1814.2162\n",
      "Epoch 803/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1819.1306 - val_loss: 1815.2021\n",
      "Epoch 804/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1819.5029 - val_loss: 1813.8904\n",
      "Epoch 805/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1819.1509 - val_loss: 1814.6517\n",
      "Epoch 806/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1818.4579 - val_loss: 1814.5801\n",
      "Epoch 807/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1818.6519 - val_loss: 1814.8945\n",
      "Epoch 808/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1819.0526 - val_loss: 1813.8923\n",
      "Epoch 809/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1818.1652 - val_loss: 1813.6863\n",
      "Epoch 810/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1818.3646 - val_loss: 1814.1396\n",
      "Epoch 811/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1819.0299 - val_loss: 1813.3866\n",
      "Epoch 812/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1817.3810 - val_loss: 1814.0509\n",
      "Epoch 813/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1817.8846 - val_loss: 1813.4213\n",
      "Epoch 814/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1816.9338 - val_loss: 1814.2742\n",
      "Epoch 815/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1818.7419 - val_loss: 1812.9453\n",
      "Epoch 816/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1818.0455 - val_loss: 1813.7933\n",
      "Epoch 817/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1818.1431 - val_loss: 1813.3802\n",
      "Epoch 818/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1817.7064 - val_loss: 1812.7283\n",
      "Epoch 819/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1818.6721 - val_loss: 1813.2537\n",
      "Epoch 820/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1818.1571 - val_loss: 1813.1826\n",
      "Epoch 821/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1817.3788 - val_loss: 1813.3551\n",
      "Epoch 822/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1818.9368 - val_loss: 1813.7493\n",
      "Epoch 823/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1818.0067 - val_loss: 1812.6890\n",
      "Epoch 824/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1816.9885 - val_loss: 1813.4545\n",
      "Epoch 825/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1818.8564 - val_loss: 1813.2526\n",
      "Epoch 826/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1817.4065 - val_loss: 1813.1379\n",
      "Epoch 827/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1817.5588 - val_loss: 1812.8329\n",
      "Epoch 828/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1817.7196 - val_loss: 1812.7944\n",
      "Epoch 829/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1816.4856 - val_loss: 1813.7827\n",
      "Epoch 830/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1816.9741 - val_loss: 1812.4067\n",
      "Epoch 831/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1816.7495 - val_loss: 1812.8364\n",
      "Epoch 832/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1816.8756 - val_loss: 1812.6390\n",
      "Epoch 833/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1817.3591 - val_loss: 1812.8438\n",
      "Epoch 834/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1817.1119 - val_loss: 1812.5165\n",
      "Epoch 835/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1817.3408 - val_loss: 1812.2451\n",
      "Epoch 836/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1817.1807 - val_loss: 1812.8728\n",
      "Epoch 837/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 56ms/step - loss: 1816.5023 - val_loss: 1812.0504\n",
      "Epoch 838/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1817.0242 - val_loss: 1812.5798\n",
      "Epoch 839/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1816.5516 - val_loss: 1812.4707\n",
      "Epoch 840/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1815.6782 - val_loss: 1812.3096\n",
      "Epoch 841/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1817.5299 - val_loss: 1814.0153\n",
      "Epoch 842/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1816.6509 - val_loss: 1813.0068\n",
      "Epoch 843/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1818.4807 - val_loss: 1812.2988\n",
      "Epoch 844/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1816.3258 - val_loss: 1811.7698\n",
      "Epoch 845/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1817.0184 - val_loss: 1811.5645\n",
      "Epoch 846/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1815.9198 - val_loss: 1811.5098\n",
      "Epoch 847/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1817.9471 - val_loss: 1811.2024\n",
      "Epoch 848/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1815.9012 - val_loss: 1811.4637\n",
      "Epoch 849/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1814.8904 - val_loss: 1810.9526\n",
      "Epoch 850/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1815.5615 - val_loss: 1811.2814\n",
      "Epoch 851/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1815.3781 - val_loss: 1810.9685\n",
      "Epoch 852/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1814.6055 - val_loss: 1810.5553\n",
      "Epoch 853/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1815.5995 - val_loss: 1810.3330\n",
      "Epoch 854/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1814.5260 - val_loss: 1810.3822\n",
      "Epoch 855/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1815.5674 - val_loss: 1809.4131\n",
      "Epoch 856/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1815.2424 - val_loss: 1810.0260\n",
      "Epoch 857/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1814.9948 - val_loss: 1809.8282\n",
      "Epoch 858/10000\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1815.1448 - val_loss: 1809.1194\n",
      "Epoch 859/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1814.9661 - val_loss: 1810.0989\n",
      "Epoch 860/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1815.1935 - val_loss: 1809.6196\n",
      "Epoch 861/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1813.5508 - val_loss: 1808.3353\n",
      "Epoch 862/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1813.2474 - val_loss: 1809.0624\n",
      "Epoch 863/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1814.7653 - val_loss: 1808.6996\n",
      "Epoch 864/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1813.6504 - val_loss: 1810.0934\n",
      "Epoch 865/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1815.1183 - val_loss: 1809.3826\n",
      "Epoch 866/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1813.9669 - val_loss: 1809.1921\n",
      "Epoch 867/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1814.0767 - val_loss: 1809.1655\n",
      "Epoch 868/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1814.3151 - val_loss: 1809.3066\n",
      "Epoch 869/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1814.4668 - val_loss: 1808.9476\n",
      "Epoch 870/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1813.1317 - val_loss: 1808.9929\n",
      "Epoch 871/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1813.3643 - val_loss: 1808.2686\n",
      "Epoch 872/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1812.8018 - val_loss: 1808.3862\n",
      "Epoch 873/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1811.6240 - val_loss: 1807.8041\n",
      "Epoch 874/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1814.4930 - val_loss: 1808.6705\n",
      "Epoch 875/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1813.4498 - val_loss: 1808.3141\n",
      "Epoch 876/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1813.3108 - val_loss: 1807.5830\n",
      "Epoch 877/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1812.7349 - val_loss: 1808.0225\n",
      "Epoch 878/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1813.0166 - val_loss: 1808.6827\n",
      "Epoch 879/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1812.2240 - val_loss: 1808.5369\n",
      "Epoch 880/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1812.4026 - val_loss: 1808.4403\n",
      "Epoch 881/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.5714 - val_loss: 1808.2810\n",
      "Epoch 882/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1812.1377 - val_loss: 1808.2743\n",
      "Epoch 883/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1813.8467 - val_loss: 1808.4912\n",
      "Epoch 884/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1813.3591 - val_loss: 1808.3510\n",
      "Epoch 885/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1812.8018 - val_loss: 1809.1901\n",
      "Epoch 886/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1810.7220 - val_loss: 1807.9059\n",
      "Epoch 887/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1811.8127 - val_loss: 1808.4834\n",
      "Epoch 888/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1813.4911 - val_loss: 1808.7301\n",
      "Epoch 889/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1812.0273 - val_loss: 1808.4169\n",
      "Epoch 890/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1812.9297 - val_loss: 1808.7872\n",
      "Epoch 891/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1811.9579 - val_loss: 1808.6713\n",
      "Epoch 892/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1813.3628 - val_loss: 1807.2247\n",
      "Epoch 893/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1812.3491 - val_loss: 1807.9591\n",
      "Epoch 894/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1812.2959 - val_loss: 1806.7861\n",
      "Epoch 895/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1812.3931 - val_loss: 1807.0374\n",
      "Epoch 896/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1811.4498 - val_loss: 1807.5006\n",
      "Epoch 897/10000\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 1812.2815 - val_loss: 1806.1439\n",
      "Epoch 898/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1810.8369 - val_loss: 1806.8754\n",
      "Epoch 899/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1812.4529 - val_loss: 1806.6377\n",
      "Epoch 900/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1810.5566 - val_loss: 1806.3031\n",
      "Epoch 901/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.7915 - val_loss: 1807.5797\n",
      "Epoch 902/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.2095 - val_loss: 1807.0856\n",
      "Epoch 903/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1809.1487 - val_loss: 1806.5392\n",
      "Epoch 904/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1811.2067 - val_loss: 1807.3064\n",
      "Epoch 905/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1811.3842 - val_loss: 1805.5448\n",
      "Epoch 906/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1811.3732 - val_loss: 1805.0945\n",
      "Epoch 907/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1811.6266 - val_loss: 1804.5175\n",
      "Epoch 908/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1811.5260 - val_loss: 1804.6194\n",
      "Epoch 909/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1812.3058 - val_loss: 1803.2427\n",
      "Epoch 910/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1813.0980 - val_loss: 1803.6791\n",
      "Epoch 911/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1812.0193 - val_loss: 1804.0352\n",
      "Epoch 912/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.0146 - val_loss: 1804.3938\n",
      "Epoch 913/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 39ms/step - loss: 1811.3799 - val_loss: 1803.7599\n",
      "Epoch 914/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1809.1810 - val_loss: 1804.5027\n",
      "Epoch 915/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1810.9282 - val_loss: 1803.4294\n",
      "Epoch 916/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1810.0175 - val_loss: 1803.2241\n",
      "Epoch 917/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1811.2526 - val_loss: 1803.2185\n",
      "Epoch 918/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.2731 - val_loss: 1804.0420\n",
      "Epoch 919/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1808.8835 - val_loss: 1802.1008\n",
      "Epoch 920/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1811.2061 - val_loss: 1804.0742\n",
      "Epoch 921/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1809.4410 - val_loss: 1802.6721\n",
      "Epoch 922/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1810.0800 - val_loss: 1802.7260\n",
      "Epoch 923/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1810.1057 - val_loss: 1802.4855\n",
      "Epoch 924/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1810.8615 - val_loss: 1802.0465\n",
      "Epoch 925/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1810.9701 - val_loss: 1802.5942\n",
      "Epoch 926/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1809.0590 - val_loss: 1802.0443\n",
      "Epoch 927/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1809.7781 - val_loss: 1801.8362\n",
      "Epoch 928/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1810.2283 - val_loss: 1801.9912\n",
      "Epoch 929/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1813.0857 - val_loss: 1806.0315\n",
      "Epoch 930/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1818.2328 - val_loss: 1806.6421\n",
      "Epoch 931/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1819.0936 - val_loss: 1808.0723\n",
      "Epoch 932/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1817.7275 - val_loss: 1808.8701\n",
      "Epoch 933/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1815.2628 - val_loss: 1808.3506\n",
      "Epoch 934/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1817.1312 - val_loss: 1809.2062\n",
      "Epoch 935/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1816.3745 - val_loss: 1809.4789\n",
      "Epoch 936/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1815.7330 - val_loss: 1809.7997\n",
      "Epoch 937/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1815.3674 - val_loss: 1807.8691\n",
      "Epoch 938/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1814.6541 - val_loss: 1808.3944\n",
      "Epoch 939/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1813.4152 - val_loss: 1807.4238\n",
      "Epoch 940/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1813.8544 - val_loss: 1808.5763\n",
      "Epoch 941/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1813.9277 - val_loss: 1806.8625\n",
      "Epoch 942/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1811.9948 - val_loss: 1807.5042\n",
      "Epoch 943/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1812.1466 - val_loss: 1806.8885\n",
      "Epoch 944/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1812.9033 - val_loss: 1806.3397\n",
      "Epoch 945/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1810.2264 - val_loss: 1805.7795\n",
      "Epoch 946/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1811.9932 - val_loss: 1807.4332\n",
      "Epoch 947/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1811.6940 - val_loss: 1804.8679\n",
      "Epoch 948/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1809.9241 - val_loss: 1805.3494\n",
      "Epoch 949/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1809.3435 - val_loss: 1804.5690\n",
      "Epoch 950/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1810.9329 - val_loss: 1804.6454\n",
      "Epoch 951/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1810.1804 - val_loss: 1804.2004\n",
      "Epoch 952/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1809.6313 - val_loss: 1804.2286\n",
      "Epoch 953/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1809.8672 - val_loss: 1803.9309\n",
      "Epoch 954/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1810.4469 - val_loss: 1805.0936\n",
      "Epoch 955/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1810.1810 - val_loss: 1803.4424\n",
      "Epoch 956/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1807.7484 - val_loss: 1803.2443\n",
      "Epoch 957/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1811.1104 - val_loss: 1803.2045\n",
      "Epoch 958/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1808.5276 - val_loss: 1803.1276\n",
      "Epoch 959/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1808.9022 - val_loss: 1803.0111\n",
      "Epoch 960/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1808.6292 - val_loss: 1803.9045\n",
      "Epoch 961/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1808.8645 - val_loss: 1802.3488\n",
      "Epoch 962/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1809.4836 - val_loss: 1803.8070\n",
      "Epoch 963/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1807.8018 - val_loss: 1803.7596\n",
      "Epoch 964/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1809.2266 - val_loss: 1804.4312\n",
      "Epoch 965/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1807.1991 - val_loss: 1805.0764\n",
      "Epoch 966/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1809.4202 - val_loss: 1804.7924\n",
      "Epoch 967/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1809.9512 - val_loss: 1807.0073\n",
      "Epoch 968/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1808.8635 - val_loss: 1808.1104\n",
      "Epoch 969/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1809.5557 - val_loss: 1807.7294\n",
      "Epoch 970/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1807.6104 - val_loss: 1804.8672\n",
      "Epoch 971/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1807.2200 - val_loss: 1801.9982\n",
      "Epoch 972/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1807.9553 - val_loss: 1803.6843\n",
      "Epoch 973/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1807.6544 - val_loss: 1801.4960\n",
      "Epoch 974/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1806.5469 - val_loss: 1801.7169\n",
      "Epoch 975/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1807.8942 - val_loss: 1801.4277\n",
      "Epoch 976/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1806.7780 - val_loss: 1802.5945\n",
      "Epoch 977/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1807.4495 - val_loss: 1802.1469\n",
      "Epoch 978/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1807.3577 - val_loss: 1802.8108\n",
      "Epoch 979/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1809.0049 - val_loss: 1801.9536\n",
      "Epoch 980/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1807.4429 - val_loss: 1802.0192\n",
      "Epoch 981/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1806.6576 - val_loss: 1802.1705\n",
      "Epoch 982/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1807.7578 - val_loss: 1801.4261\n",
      "Epoch 983/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1806.4081 - val_loss: 1800.4915\n",
      "Epoch 984/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1806.6792 - val_loss: 1800.6885\n",
      "Epoch 985/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1805.5165 - val_loss: 1800.9915\n",
      "Epoch 986/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1807.1084 - val_loss: 1800.9062\n",
      "Epoch 987/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1806.4139 - val_loss: 1801.4534\n",
      "Epoch 988/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1806.8107 - val_loss: 1812.1146\n",
      "Epoch 989/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 43ms/step - loss: 1810.6530 - val_loss: 1814.5144\n",
      "Epoch 990/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1809.3641 - val_loss: 1810.7021\n",
      "Epoch 991/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1807.6147 - val_loss: 1806.8469\n",
      "Epoch 992/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1809.1626 - val_loss: 1806.1575\n",
      "Epoch 993/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1808.4753 - val_loss: 1805.3837\n",
      "Epoch 994/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1807.6234 - val_loss: 1806.7457\n",
      "Epoch 995/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1807.6357 - val_loss: 1804.6154\n",
      "Epoch 996/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1808.2426 - val_loss: 1804.7815\n",
      "Epoch 997/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1806.2614 - val_loss: 1805.2295\n",
      "Epoch 998/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1807.4805 - val_loss: 1805.0270\n",
      "Epoch 999/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1807.7538 - val_loss: 1805.6561\n",
      "Epoch 1000/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1806.1223 - val_loss: 1802.8146\n",
      "Epoch 1001/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1805.5299 - val_loss: 1805.2737\n",
      "Epoch 1002/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1806.3376 - val_loss: 1803.8643\n",
      "Epoch 1003/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1805.6078 - val_loss: 1803.0889\n",
      "Epoch 1004/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1803.3136 - val_loss: 1803.2799\n",
      "Epoch 1005/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1805.0226 - val_loss: 1802.9332\n",
      "Epoch 1006/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1801.8289 - val_loss: 1802.6084\n",
      "Epoch 1007/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1802.6256 - val_loss: 1801.9425\n",
      "Epoch 1008/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1803.9766 - val_loss: 1801.1990\n",
      "Epoch 1009/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1804.2516 - val_loss: 1804.2869\n",
      "Epoch 1010/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1802.7158 - val_loss: 1802.0322\n",
      "Epoch 1011/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1803.1552 - val_loss: 1801.2991\n",
      "Epoch 1012/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1804.2811 - val_loss: 1802.0439\n",
      "Epoch 1013/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1800.8877 - val_loss: 1801.1385\n",
      "Epoch 1014/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1802.1426 - val_loss: 1801.2970\n",
      "Epoch 1015/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1803.5928 - val_loss: 1801.1500\n",
      "Epoch 1016/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1801.2721 - val_loss: 1800.3715\n",
      "Epoch 1017/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1802.6146 - val_loss: 1802.9971\n",
      "Epoch 1018/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1801.7770 - val_loss: 1800.1395\n",
      "Epoch 1019/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1802.5048 - val_loss: 1800.7438\n",
      "Epoch 1020/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1800.1895 - val_loss: 1800.8633\n",
      "Epoch 1021/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1801.7880 - val_loss: 1800.7374\n",
      "Epoch 1022/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1799.7163 - val_loss: 1800.5140\n",
      "Epoch 1023/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1801.3508 - val_loss: 1799.4038\n",
      "Epoch 1024/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1800.2799 - val_loss: 1800.4259\n",
      "Epoch 1025/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1799.4563 - val_loss: 1799.7393\n",
      "Epoch 1026/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1801.2601 - val_loss: 1799.2356\n",
      "Epoch 1027/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1800.9507 - val_loss: 1799.0509\n",
      "Epoch 1028/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1799.5925 - val_loss: 1799.1487\n",
      "Epoch 1029/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1800.3824 - val_loss: 1800.1907\n",
      "Epoch 1030/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1800.6855 - val_loss: 1798.6439\n",
      "Epoch 1031/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1801.2141 - val_loss: 1800.2983\n",
      "Epoch 1032/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1799.3301 - val_loss: 1800.7570\n",
      "Epoch 1033/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1800.2633 - val_loss: 1799.0840\n",
      "Epoch 1034/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1799.2650 - val_loss: 1802.7173\n",
      "Epoch 1035/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1800.6700 - val_loss: 1798.3296\n",
      "Epoch 1036/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1800.1116 - val_loss: 1798.8217\n",
      "Epoch 1037/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1799.7600 - val_loss: 1798.4678\n",
      "Epoch 1038/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1798.9216 - val_loss: 1798.1157\n",
      "Epoch 1039/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1798.7528 - val_loss: 1797.7394\n",
      "Epoch 1040/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1798.3435 - val_loss: 1798.7981\n",
      "Epoch 1041/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1798.3221 - val_loss: 1798.0612\n",
      "Epoch 1042/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1799.0435 - val_loss: 1797.6609\n",
      "Epoch 1043/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1799.3763 - val_loss: 1796.9692\n",
      "Epoch 1044/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1797.8561 - val_loss: 1797.2721\n",
      "Epoch 1045/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1798.3022 - val_loss: 1796.6639\n",
      "Epoch 1046/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1799.4659 - val_loss: 1800.6508\n",
      "Epoch 1047/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1800.8889 - val_loss: 1797.7885\n",
      "Epoch 1048/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1798.6265 - val_loss: 1797.2667\n",
      "Epoch 1049/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1798.3361 - val_loss: 1799.1042\n",
      "Epoch 1050/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1798.8678 - val_loss: 1797.3937\n",
      "Epoch 1051/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1797.5780 - val_loss: 1797.7930\n",
      "Epoch 1052/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1797.2302 - val_loss: 1797.3313\n",
      "Epoch 1053/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1798.3726 - val_loss: 1797.2759\n",
      "Epoch 1054/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1798.4019 - val_loss: 1797.6149\n",
      "Epoch 1055/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1797.4713 - val_loss: 1798.3672\n",
      "Epoch 1056/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1797.6942 - val_loss: 1796.6346\n",
      "Epoch 1057/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1797.1904 - val_loss: 1797.1184\n",
      "Epoch 1058/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1797.5387 - val_loss: 1795.7969\n",
      "Epoch 1059/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1795.6620 - val_loss: 1796.6013\n",
      "Epoch 1060/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.3619 - val_loss: 1797.2982\n",
      "Epoch 1061/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1797.5610 - val_loss: 1795.9453\n",
      "Epoch 1062/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1797.0579 - val_loss: 1797.8660\n",
      "Epoch 1063/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1797.0021 - val_loss: 1797.9252\n",
      "Epoch 1064/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1797.7665 - val_loss: 1796.2097\n",
      "Epoch 1065/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1796.3984 - val_loss: 1795.5820\n",
      "Epoch 1066/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1794.7529 - val_loss: 1795.1089\n",
      "Epoch 1067/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1797.4523 - val_loss: 1796.1984\n",
      "Epoch 1068/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1796.5862 - val_loss: 1795.2587\n",
      "Epoch 1069/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1798.0592 - val_loss: 1794.8892\n",
      "Epoch 1070/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1797.1348 - val_loss: 1795.0796\n",
      "Epoch 1071/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.0483 - val_loss: 1795.3103\n",
      "Epoch 1072/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1795.2665 - val_loss: 1796.2065\n",
      "Epoch 1073/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.6257 - val_loss: 1796.1016\n",
      "Epoch 1074/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1795.7981 - val_loss: 1795.3441\n",
      "Epoch 1075/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1796.3245 - val_loss: 1796.3274\n",
      "Epoch 1076/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.5195 - val_loss: 1796.6721\n",
      "Epoch 1077/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1796.1688 - val_loss: 1795.1610\n",
      "Epoch 1078/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1798.0393 - val_loss: 1794.9502\n",
      "Epoch 1079/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1797.1560 - val_loss: 1795.7898\n",
      "Epoch 1080/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1794.9084 - val_loss: 1795.6287\n",
      "Epoch 1081/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1796.2725 - val_loss: 1795.9424\n",
      "Epoch 1082/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1794.0894 - val_loss: 1796.0981\n",
      "Epoch 1083/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1795.1802 - val_loss: 1795.0707\n",
      "Epoch 1084/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1795.5510 - val_loss: 1794.3358\n",
      "Epoch 1085/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1793.5636 - val_loss: 1796.9287\n",
      "Epoch 1086/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1794.0856 - val_loss: 1795.4406\n",
      "Epoch 1087/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1795.0083 - val_loss: 1795.4055\n",
      "Epoch 1088/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1794.4860 - val_loss: 1794.3115\n",
      "Epoch 1089/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1794.5889 - val_loss: 1794.8519\n",
      "Epoch 1090/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1794.4133 - val_loss: 1794.8486\n",
      "Epoch 1091/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1794.5449 - val_loss: 1795.2384\n",
      "Epoch 1092/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1794.0168 - val_loss: 1795.1517\n",
      "Epoch 1093/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1792.9846 - val_loss: 1793.5947\n",
      "Epoch 1094/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1794.5752 - val_loss: 1794.1573\n",
      "Epoch 1095/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1792.8361 - val_loss: 1795.5908\n",
      "Epoch 1096/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1793.1685 - val_loss: 1794.3494\n",
      "Epoch 1097/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1794.6625 - val_loss: 1793.6803\n",
      "Epoch 1098/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.1979 - val_loss: 1793.8562\n",
      "Epoch 1099/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1793.4393 - val_loss: 1795.4307\n",
      "Epoch 1100/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1791.8767 - val_loss: 1795.0253\n",
      "Epoch 1101/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1793.6000 - val_loss: 1793.6973\n",
      "Epoch 1102/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1793.6901 - val_loss: 1793.6758\n",
      "Epoch 1103/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1792.5128 - val_loss: 1792.9795\n",
      "Epoch 1104/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1793.1285 - val_loss: 1794.1329\n",
      "Epoch 1105/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1791.5264 - val_loss: 1792.3210\n",
      "Epoch 1106/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1791.9991 - val_loss: 1793.3263\n",
      "Epoch 1107/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1791.8486 - val_loss: 1793.0125\n",
      "Epoch 1108/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1791.5562 - val_loss: 1792.8579\n",
      "Epoch 1109/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1792.1335 - val_loss: 1792.4113\n",
      "Epoch 1110/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1792.6560 - val_loss: 1792.5535\n",
      "Epoch 1111/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.9519 - val_loss: 1793.0166\n",
      "Epoch 1112/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1791.7014 - val_loss: 1792.1208\n",
      "Epoch 1113/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1791.7183 - val_loss: 1793.2019\n",
      "Epoch 1114/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1792.0795 - val_loss: 1793.7482\n",
      "Epoch 1115/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.9398 - val_loss: 1794.7542\n",
      "Epoch 1116/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1792.0344 - val_loss: 1796.2054\n",
      "Epoch 1117/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.1057 - val_loss: 1793.4695\n",
      "Epoch 1118/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.8741 - val_loss: 1794.2793\n",
      "Epoch 1119/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1793.0662 - val_loss: 1793.6885\n",
      "Epoch 1120/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1791.3545 - val_loss: 1793.7692\n",
      "Epoch 1121/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1791.0829 - val_loss: 1793.4170\n",
      "Epoch 1122/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1791.7371 - val_loss: 1794.0654\n",
      "Epoch 1123/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1791.3070 - val_loss: 1792.4526\n",
      "Epoch 1124/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1790.8795 - val_loss: 1793.2720\n",
      "Epoch 1125/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.8091 - val_loss: 1793.1121\n",
      "Epoch 1126/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1791.0378 - val_loss: 1793.7742\n",
      "Epoch 1127/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1789.4740 - val_loss: 1792.6694\n",
      "Epoch 1128/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.7760 - val_loss: 1793.5558\n",
      "Epoch 1129/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1788.7516 - val_loss: 1795.6870\n",
      "Epoch 1130/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1791.6331 - val_loss: 1794.0758\n",
      "Epoch 1131/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1791.8674 - val_loss: 1792.7260\n",
      "Epoch 1132/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1800.0836 - val_loss: 1801.9822\n",
      "Epoch 1133/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1804.7137 - val_loss: 1803.0735\n",
      "Epoch 1134/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1807.5267 - val_loss: 1803.6288\n",
      "Epoch 1135/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1804.1322 - val_loss: 1803.6288\n",
      "Epoch 1136/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1802.6707 - val_loss: 1802.9008\n",
      "Epoch 1137/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1800.9756 - val_loss: 1800.4308\n",
      "Epoch 1138/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1799.6421 - val_loss: 1799.8451\n",
      "Epoch 1139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 43ms/step - loss: 1801.9031 - val_loss: 1800.6680\n",
      "Epoch 1140/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1799.0054 - val_loss: 1798.6104\n",
      "Epoch 1141/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1800.2979 - val_loss: 1798.1710\n",
      "Epoch 1142/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1798.0813 - val_loss: 1798.7703\n",
      "Epoch 1143/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1797.3566 - val_loss: 1797.5420\n",
      "Epoch 1144/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1798.9677 - val_loss: 1797.1057\n",
      "Epoch 1145/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1797.9031 - val_loss: 1800.8567\n",
      "Epoch 1146/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1797.8721 - val_loss: 1796.0151\n",
      "Epoch 1147/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1798.0375 - val_loss: 1800.6826\n",
      "Epoch 1148/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1798.4122 - val_loss: 1797.1962\n",
      "Epoch 1149/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1796.5742 - val_loss: 1796.5511\n",
      "Epoch 1150/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1796.4087 - val_loss: 1796.3021\n",
      "Epoch 1151/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1795.4408 - val_loss: 1797.0771\n",
      "Epoch 1152/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.3076 - val_loss: 1796.0519\n",
      "Epoch 1153/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1795.2761 - val_loss: 1797.5962\n",
      "Epoch 1154/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.4734 - val_loss: 1795.4847\n",
      "Epoch 1155/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1796.1232 - val_loss: 1795.6487\n",
      "Epoch 1156/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1796.0752 - val_loss: 1794.8057\n",
      "Epoch 1157/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1794.2764 - val_loss: 1795.7736\n",
      "Epoch 1158/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1793.9001 - val_loss: 1795.9518\n",
      "Epoch 1159/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1794.4685 - val_loss: 1795.5543\n",
      "Epoch 1160/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1794.6444 - val_loss: 1795.8441\n",
      "Epoch 1161/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.5116 - val_loss: 1794.0732\n",
      "Epoch 1162/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.6498 - val_loss: 1793.6196\n",
      "Epoch 1163/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1793.4921 - val_loss: 1794.0862\n",
      "Epoch 1164/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1793.6194 - val_loss: 1792.9740\n",
      "Epoch 1165/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1793.4314 - val_loss: 1794.3004\n",
      "Epoch 1166/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1792.8705 - val_loss: 1792.8202\n",
      "Epoch 1167/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1795.4224 - val_loss: 1793.6787\n",
      "Epoch 1168/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1792.7677 - val_loss: 1794.5240\n",
      "Epoch 1169/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1792.3610 - val_loss: 1793.2755\n",
      "Epoch 1170/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1792.7396 - val_loss: 1794.0682\n",
      "Epoch 1171/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1791.3035 - val_loss: 1793.2013\n",
      "Epoch 1172/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1794.2019 - val_loss: 1792.4541\n",
      "Epoch 1173/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1792.2875 - val_loss: 1792.1063\n",
      "Epoch 1174/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1792.9717 - val_loss: 1792.0381\n",
      "Epoch 1175/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1792.4448 - val_loss: 1793.4882\n",
      "Epoch 1176/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1791.8099 - val_loss: 1791.9572\n",
      "Epoch 1177/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1792.0613 - val_loss: 1794.7758\n",
      "Epoch 1178/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1792.2224 - val_loss: 1791.9451\n",
      "Epoch 1179/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1791.3213 - val_loss: 1791.5869\n",
      "Epoch 1180/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1792.1475 - val_loss: 1790.6934\n",
      "Epoch 1181/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1791.4393 - val_loss: 1790.4321\n",
      "Epoch 1182/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1791.1021 - val_loss: 1792.6467\n",
      "Epoch 1183/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.5966 - val_loss: 1790.7705\n",
      "Epoch 1184/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1790.6139 - val_loss: 1790.8976\n",
      "Epoch 1185/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1791.2164 - val_loss: 1791.7151\n",
      "Epoch 1186/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1789.6904 - val_loss: 1790.4054\n",
      "Epoch 1187/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1791.0950 - val_loss: 1791.5640\n",
      "Epoch 1188/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1791.1041 - val_loss: 1791.2258\n",
      "Epoch 1189/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1791.6520 - val_loss: 1791.0836\n",
      "Epoch 1190/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1790.1866 - val_loss: 1790.8113\n",
      "Epoch 1191/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1789.3947 - val_loss: 1792.5281\n",
      "Epoch 1192/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1790.3346 - val_loss: 1790.0198\n",
      "Epoch 1193/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1788.9182 - val_loss: 1791.0179\n",
      "Epoch 1194/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1790.8621 - val_loss: 1791.5916\n",
      "Epoch 1195/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1790.4873 - val_loss: 1790.1598\n",
      "Epoch 1196/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.4374 - val_loss: 1790.7001\n",
      "Epoch 1197/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1789.7926 - val_loss: 1790.2511\n",
      "Epoch 1198/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1788.9485 - val_loss: 1790.3159\n",
      "Epoch 1199/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.0702 - val_loss: 1790.1178\n",
      "Epoch 1200/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1790.4563 - val_loss: 1791.9542\n",
      "Epoch 1201/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1788.4164 - val_loss: 1789.9020\n",
      "Epoch 1202/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1789.5673 - val_loss: 1790.8248\n",
      "Epoch 1203/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1788.8951 - val_loss: 1789.9062\n",
      "Epoch 1204/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.3427 - val_loss: 1790.0850\n",
      "Epoch 1205/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1790.4923 - val_loss: 1790.4280\n",
      "Epoch 1206/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.2333 - val_loss: 1790.4072\n",
      "Epoch 1207/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1787.6445 - val_loss: 1788.8541\n",
      "Epoch 1208/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1789.3185 - val_loss: 1790.4197\n",
      "Epoch 1209/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1789.5885 - val_loss: 1789.3231\n",
      "Epoch 1210/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1787.5925 - val_loss: 1789.2628\n",
      "Epoch 1211/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1786.8883 - val_loss: 1790.4835\n",
      "Epoch 1212/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1788.5559 - val_loss: 1790.8613\n",
      "Epoch 1213/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1791.2719 - val_loss: 1789.1399\n",
      "Epoch 1214/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1788.3784 - val_loss: 1789.1423\n",
      "Epoch 1215/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1787.3885 - val_loss: 1789.7302\n",
      "Epoch 1216/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1787.2130 - val_loss: 1788.1409\n",
      "Epoch 1217/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1787.5239 - val_loss: 1788.5149\n",
      "Epoch 1218/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1786.6733 - val_loss: 1788.9731\n",
      "Epoch 1219/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1787.6025 - val_loss: 1787.3895\n",
      "Epoch 1220/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1788.8538 - val_loss: 1788.6591\n",
      "Epoch 1221/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1787.4865 - val_loss: 1789.5066\n",
      "Epoch 1222/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1786.0494 - val_loss: 1789.9087\n",
      "Epoch 1223/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1787.2721 - val_loss: 1791.4619\n",
      "Epoch 1224/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1788.2577 - val_loss: 1788.0038\n",
      "Epoch 1225/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1787.5433 - val_loss: 1789.6139\n",
      "Epoch 1226/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1786.6058 - val_loss: 1787.8789\n",
      "Epoch 1227/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1785.5510 - val_loss: 1789.0186\n",
      "Epoch 1228/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1786.5426 - val_loss: 1788.3057\n",
      "Epoch 1229/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1785.5001 - val_loss: 1789.1583\n",
      "Epoch 1230/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1785.8916 - val_loss: 1787.7239\n",
      "Epoch 1231/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1785.5518 - val_loss: 1787.6290\n",
      "Epoch 1232/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1786.9037 - val_loss: 1788.8022\n",
      "Epoch 1233/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1787.5096 - val_loss: 1789.6006\n",
      "Epoch 1234/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1785.0142 - val_loss: 1787.8817\n",
      "Epoch 1235/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1786.6116 - val_loss: 1788.3373\n",
      "Epoch 1236/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1787.1027 - val_loss: 1789.6007\n",
      "Epoch 1237/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1784.5107 - val_loss: 1788.9908\n",
      "Epoch 1238/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1785.3473 - val_loss: 1788.6512\n",
      "Epoch 1239/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1787.3472 - val_loss: 1787.3822\n",
      "Epoch 1240/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1786.4404 - val_loss: 1788.7744\n",
      "Epoch 1241/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1784.9629 - val_loss: 1787.7135\n",
      "Epoch 1242/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1784.7255 - val_loss: 1787.5289\n",
      "Epoch 1243/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1783.8864 - val_loss: 1787.1460\n",
      "Epoch 1244/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1785.1101 - val_loss: 1789.4923\n",
      "Epoch 1245/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1786.8821 - val_loss: 1787.5474\n",
      "Epoch 1246/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1785.5685 - val_loss: 1786.6821\n",
      "Epoch 1247/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1783.8435 - val_loss: 1786.7792\n",
      "Epoch 1248/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1785.0431 - val_loss: 1788.0128\n",
      "Epoch 1249/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1783.5862 - val_loss: 1787.5680\n",
      "Epoch 1250/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1783.9191 - val_loss: 1787.0751\n",
      "Epoch 1251/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1783.8781 - val_loss: 1788.6770\n",
      "Epoch 1252/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1786.4125 - val_loss: 1788.5660\n",
      "Epoch 1253/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1784.2892 - val_loss: 1787.4800\n",
      "Epoch 1254/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1785.2118 - val_loss: 1788.8059\n",
      "Epoch 1255/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1784.6337 - val_loss: 1785.7377\n",
      "Epoch 1256/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1785.2843 - val_loss: 1788.1649\n",
      "Epoch 1257/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1784.6941 - val_loss: 1787.1248\n",
      "Epoch 1258/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1783.9237 - val_loss: 1785.9933\n",
      "Epoch 1259/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1784.5270 - val_loss: 1787.8840\n",
      "Epoch 1260/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1784.6193 - val_loss: 1786.0730\n",
      "Epoch 1261/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1784.5344 - val_loss: 1790.1312\n",
      "Epoch 1262/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1784.3160 - val_loss: 1787.5884\n",
      "Epoch 1263/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1784.6149 - val_loss: 1786.9999\n",
      "Epoch 1264/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1782.8995 - val_loss: 1785.3156\n",
      "Epoch 1265/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1784.1097 - val_loss: 1786.4993\n",
      "Epoch 1266/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1781.5220 - val_loss: 1787.2233\n",
      "Epoch 1267/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1784.4279 - val_loss: 1788.3765\n",
      "Epoch 1268/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1784.7361 - val_loss: 1785.4525\n",
      "Epoch 1269/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1782.5741 - val_loss: 1787.9521\n",
      "Epoch 1270/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1784.4911 - val_loss: 1789.9646\n",
      "Epoch 1271/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1783.3827 - val_loss: 1784.9883\n",
      "Epoch 1272/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1782.0052 - val_loss: 1789.3940\n",
      "Epoch 1273/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1783.7738 - val_loss: 1784.3829\n",
      "Epoch 1274/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1782.4346 - val_loss: 1787.7482\n",
      "Epoch 1275/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1784.5806 - val_loss: 1788.8994\n",
      "Epoch 1276/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1782.6287 - val_loss: 1785.3008\n",
      "Epoch 1277/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1783.6974 - val_loss: 1788.3663\n",
      "Epoch 1278/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1783.8966 - val_loss: 1784.4200\n",
      "Epoch 1279/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1783.1860 - val_loss: 1788.4963\n",
      "Epoch 1280/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1783.7487 - val_loss: 1785.6064\n",
      "Epoch 1281/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1781.8928 - val_loss: 1785.1516\n",
      "Epoch 1282/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1782.5833 - val_loss: 1787.3977\n",
      "Epoch 1283/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1781.3549 - val_loss: 1785.2196\n",
      "Epoch 1284/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1782.2345 - val_loss: 1784.7451\n",
      "Epoch 1285/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1781.4185 - val_loss: 1788.4482\n",
      "Epoch 1286/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1783.3162 - val_loss: 1785.4655\n",
      "Epoch 1287/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1782.6154 - val_loss: 1784.6022\n",
      "Epoch 1288/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1781.9445 - val_loss: 1783.9292\n",
      "Epoch 1289/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 39ms/step - loss: 1781.9648 - val_loss: 1789.2914\n",
      "Epoch 1290/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1781.2039 - val_loss: 1784.1608\n",
      "Epoch 1291/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1780.5221 - val_loss: 1784.2418\n",
      "Epoch 1292/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1782.2089 - val_loss: 1785.1064\n",
      "Epoch 1293/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1783.0017 - val_loss: 1786.7085\n",
      "Epoch 1294/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1782.1050 - val_loss: 1786.6743\n",
      "Epoch 1295/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1781.0483 - val_loss: 1786.5422\n",
      "Epoch 1296/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1780.3937 - val_loss: 1784.8646\n",
      "Epoch 1297/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1779.4062 - val_loss: 1784.6807\n",
      "Epoch 1298/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1779.8307 - val_loss: 1783.6628\n",
      "Epoch 1299/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1780.3536 - val_loss: 1786.4185\n",
      "Epoch 1300/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1781.3351 - val_loss: 1786.1652\n",
      "Epoch 1301/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1780.1121 - val_loss: 1785.6703\n",
      "Epoch 1302/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1779.8413 - val_loss: 1784.4359\n",
      "Epoch 1303/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1780.8730 - val_loss: 1786.3130\n",
      "Epoch 1304/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1780.1179 - val_loss: 1784.4196\n",
      "Epoch 1305/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1780.3424 - val_loss: 1785.4066\n",
      "Epoch 1306/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1781.2606 - val_loss: 1784.3091\n",
      "Epoch 1307/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1780.8798 - val_loss: 1783.0341\n",
      "Epoch 1308/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1781.5972 - val_loss: 1787.4437\n",
      "Epoch 1309/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1783.1770 - val_loss: 1793.0614\n",
      "Epoch 1310/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1779.8319 - val_loss: 1782.3691\n",
      "Epoch 1311/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1781.3259 - val_loss: 1788.9340\n",
      "Epoch 1312/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1780.2081 - val_loss: 1784.2273\n",
      "Epoch 1313/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1780.6698 - val_loss: 1783.4240\n",
      "Epoch 1314/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1779.4415 - val_loss: 1787.2736\n",
      "Epoch 1315/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1780.1437 - val_loss: 1784.5309\n",
      "Epoch 1316/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1778.2803 - val_loss: 1782.8831\n",
      "Epoch 1317/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1778.8857 - val_loss: 1785.5096\n",
      "Epoch 1318/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1780.6604 - val_loss: 1785.1118\n",
      "Epoch 1319/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1779.1747 - val_loss: 1789.8969\n",
      "Epoch 1320/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1780.3336 - val_loss: 1784.3096\n",
      "Epoch 1321/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.7667 - val_loss: 1783.0410\n",
      "Epoch 1322/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1779.2369 - val_loss: 1785.7448\n",
      "Epoch 1323/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1779.1490 - val_loss: 1782.7368\n",
      "Epoch 1324/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1779.4484 - val_loss: 1784.4181\n",
      "Epoch 1325/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1779.5238 - val_loss: 1785.2472\n",
      "Epoch 1326/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.3109 - val_loss: 1786.0154\n",
      "Epoch 1327/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1778.8534 - val_loss: 1783.8442\n",
      "Epoch 1328/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1781.3790 - val_loss: 1782.7659\n",
      "Epoch 1329/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1778.9656 - val_loss: 1786.5052\n",
      "Epoch 1330/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1779.8074 - val_loss: 1784.0006\n",
      "Epoch 1331/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.9906 - val_loss: 1785.6781\n",
      "Epoch 1332/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1779.6488 - val_loss: 1787.2308\n",
      "Epoch 1333/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1780.2430 - val_loss: 1786.4878\n",
      "Epoch 1334/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1779.0403 - val_loss: 1784.4812\n",
      "Epoch 1335/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1778.2322 - val_loss: 1782.3270\n",
      "Epoch 1336/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1778.5078 - val_loss: 1786.7689\n",
      "Epoch 1337/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1778.7386 - val_loss: 1782.7120\n",
      "Epoch 1338/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1778.2836 - val_loss: 1784.9341\n",
      "Epoch 1339/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1776.6997 - val_loss: 1784.1135\n",
      "Epoch 1340/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1777.1296 - val_loss: 1782.4534\n",
      "Epoch 1341/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1777.3428 - val_loss: 1781.8826\n",
      "Epoch 1342/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1778.4539 - val_loss: 1788.5740\n",
      "Epoch 1343/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1777.5763 - val_loss: 1784.0074\n",
      "Epoch 1344/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1778.0790 - val_loss: 1783.4913\n",
      "Epoch 1345/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1778.1864 - val_loss: 1783.2584\n",
      "Epoch 1346/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1776.7941 - val_loss: 1786.4545\n",
      "Epoch 1347/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1777.8333 - val_loss: 1782.1464\n",
      "Epoch 1348/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1778.6456 - val_loss: 1783.5990\n",
      "Epoch 1349/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1777.0585 - val_loss: 1785.3149\n",
      "Epoch 1350/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1777.1951 - val_loss: 1784.6422\n",
      "Epoch 1351/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1778.4534 - val_loss: 1784.3917\n",
      "Epoch 1352/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1776.5583 - val_loss: 1783.2736\n",
      "Epoch 1353/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1776.4785 - val_loss: 1783.1787\n",
      "Epoch 1354/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1776.6692 - val_loss: 1783.4559\n",
      "Epoch 1355/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1777.4845 - val_loss: 1783.2910\n",
      "Epoch 1356/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1777.7462 - val_loss: 1781.9274\n",
      "Epoch 1357/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1776.2112 - val_loss: 1784.5505\n",
      "Epoch 1358/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1778.9940 - val_loss: 1784.4307\n",
      "Epoch 1359/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1777.5741 - val_loss: 1782.9957\n",
      "Epoch 1360/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1777.2836 - val_loss: 1780.5760\n",
      "Epoch 1361/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.9706 - val_loss: 1783.1490\n",
      "Epoch 1362/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.5659 - val_loss: 1785.2628\n",
      "Epoch 1363/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1776.5765 - val_loss: 1782.5381\n",
      "Epoch 1364/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1777.1094 - val_loss: 1784.1947\n",
      "Epoch 1365/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1777.1820 - val_loss: 1782.0369\n",
      "Epoch 1366/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1776.1484 - val_loss: 1780.6416\n",
      "Epoch 1367/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1777.5231 - val_loss: 1782.4437\n",
      "Epoch 1368/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1778.2444 - val_loss: 1782.7311\n",
      "Epoch 1369/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.2997 - val_loss: 1785.0454\n",
      "Epoch 1370/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1779.1482 - val_loss: 1788.5459\n",
      "Epoch 1371/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1776.8394 - val_loss: 1783.0876\n",
      "Epoch 1372/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1779.3728 - val_loss: 1781.5361\n",
      "Epoch 1373/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1778.4924 - val_loss: 1780.9971\n",
      "Epoch 1374/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1775.8951 - val_loss: 1784.3951\n",
      "Epoch 1375/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1777.1765 - val_loss: 1786.4799\n",
      "Epoch 1376/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1778.6924 - val_loss: 1796.0863\n",
      "Epoch 1377/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1780.6494 - val_loss: 1789.9927\n",
      "Epoch 1378/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1779.3297 - val_loss: 1784.4443\n",
      "Epoch 1379/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1778.6204 - val_loss: 1783.1624\n",
      "Epoch 1380/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1776.9597 - val_loss: 1780.8511\n",
      "Epoch 1381/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1775.6432 - val_loss: 1782.1699\n",
      "Epoch 1382/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1774.9362 - val_loss: 1783.3685\n",
      "Epoch 1383/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1775.4252 - val_loss: 1782.5009\n",
      "Epoch 1384/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1776.0360 - val_loss: 1781.5796\n",
      "Epoch 1385/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.1758 - val_loss: 1782.8431\n",
      "Epoch 1386/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1775.8834 - val_loss: 1785.2312\n",
      "Epoch 1387/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1775.2258 - val_loss: 1782.7587\n",
      "Epoch 1388/10000\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 1775.4509 - val_loss: 1780.1603\n",
      "Epoch 1389/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1774.8717 - val_loss: 1782.3708\n",
      "Epoch 1390/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.5555 - val_loss: 1782.0149\n",
      "Epoch 1391/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1774.4268 - val_loss: 1781.9270\n",
      "Epoch 1392/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1774.6940 - val_loss: 1781.2485\n",
      "Epoch 1393/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1773.7834 - val_loss: 1782.9512\n",
      "Epoch 1394/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1773.5153 - val_loss: 1781.7178\n",
      "Epoch 1395/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1773.9036 - val_loss: 1780.2382\n",
      "Epoch 1396/10000\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 1775.1646 - val_loss: 1778.8949\n",
      "Epoch 1397/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1775.3060 - val_loss: 1783.5018\n",
      "Epoch 1398/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1774.8116 - val_loss: 1780.1691\n",
      "Epoch 1399/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.1992 - val_loss: 1782.7754\n",
      "Epoch 1400/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1774.1799 - val_loss: 1786.1500\n",
      "Epoch 1401/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1774.0924 - val_loss: 1781.3679\n",
      "Epoch 1402/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1774.7906 - val_loss: 1780.0854\n",
      "Epoch 1403/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1774.8352 - val_loss: 1784.1007\n",
      "Epoch 1404/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.9250 - val_loss: 1786.9963\n",
      "Epoch 1405/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1774.7295 - val_loss: 1784.3087\n",
      "Epoch 1406/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1774.7476 - val_loss: 1781.9877\n",
      "Epoch 1407/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1774.2649 - val_loss: 1782.8625\n",
      "Epoch 1408/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.2469 - val_loss: 1781.3358\n",
      "Epoch 1409/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1774.2979 - val_loss: 1781.2716\n",
      "Epoch 1410/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1773.4747 - val_loss: 1782.0637\n",
      "Epoch 1411/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1775.4580 - val_loss: 1779.5815\n",
      "Epoch 1412/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1775.8938 - val_loss: 1781.5906\n",
      "Epoch 1413/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1775.3865 - val_loss: 1787.6326\n",
      "Epoch 1414/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1775.1754 - val_loss: 1782.5068\n",
      "Epoch 1415/10000\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1773.9180 - val_loss: 1778.8492\n",
      "Epoch 1416/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1774.0151 - val_loss: 1780.6849\n",
      "Epoch 1417/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1772.4900 - val_loss: 1782.0715\n",
      "Epoch 1418/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1773.7106 - val_loss: 1781.1406\n",
      "Epoch 1419/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1772.0693 - val_loss: 1781.4441\n",
      "Epoch 1420/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1773.2229 - val_loss: 1784.3381\n",
      "Epoch 1421/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1774.9601 - val_loss: 1783.8517\n",
      "Epoch 1422/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1773.7510 - val_loss: 1780.8811\n",
      "Epoch 1423/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1773.4514 - val_loss: 1781.4048\n",
      "Epoch 1424/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1771.8488 - val_loss: 1781.7094\n",
      "Epoch 1425/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1773.6980 - val_loss: 1778.9863\n",
      "Epoch 1426/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1773.1719 - val_loss: 1779.5272\n",
      "Epoch 1427/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1774.2867 - val_loss: 1778.2437\n",
      "Epoch 1428/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1773.7822 - val_loss: 1778.8667\n",
      "Epoch 1429/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1772.5734 - val_loss: 1781.8237\n",
      "Epoch 1430/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1773.3610 - val_loss: 1784.8219\n",
      "Epoch 1431/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1773.6897 - val_loss: 1780.6449\n",
      "Epoch 1432/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1773.0873 - val_loss: 1782.6139\n",
      "Epoch 1433/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1773.3170 - val_loss: 1780.1416\n",
      "Epoch 1434/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1772.6377 - val_loss: 1778.6533\n",
      "Epoch 1435/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1772.8043 - val_loss: 1781.1467\n",
      "Epoch 1436/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.8271 - val_loss: 1779.7780\n",
      "Epoch 1437/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1772.7568 - val_loss: 1778.9056\n",
      "Epoch 1438/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1772.1268 - val_loss: 1783.2515\n",
      "Epoch 1439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.5170 - val_loss: 1779.3529\n",
      "Epoch 1440/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.4669 - val_loss: 1785.5398\n",
      "Epoch 1441/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.7545 - val_loss: 1782.5371\n",
      "Epoch 1442/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.1235 - val_loss: 1781.5536\n",
      "Epoch 1443/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1772.0693 - val_loss: 1778.5071\n",
      "Epoch 1444/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1771.4896 - val_loss: 1780.0605\n",
      "Epoch 1445/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1771.4281 - val_loss: 1779.6409\n",
      "Epoch 1446/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.8734 - val_loss: 1785.0258\n",
      "Epoch 1447/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.0986 - val_loss: 1783.9772\n",
      "Epoch 1448/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.2736 - val_loss: 1783.3370\n",
      "Epoch 1449/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.1178 - val_loss: 1779.0598\n",
      "Epoch 1450/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1772.1925 - val_loss: 1782.4053\n",
      "Epoch 1451/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1772.4659 - val_loss: 1780.3013\n",
      "Epoch 1452/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1772.1921 - val_loss: 1779.2189\n",
      "Epoch 1453/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.9545 - val_loss: 1779.2211\n",
      "Epoch 1454/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1772.1602 - val_loss: 1779.3385\n",
      "Epoch 1455/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.0671 - val_loss: 1785.0369\n",
      "Epoch 1456/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.8623 - val_loss: 1784.4905\n",
      "Epoch 1457/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.4053 - val_loss: 1784.6528\n",
      "Epoch 1458/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1772.6007 - val_loss: 1786.9507\n",
      "Epoch 1459/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.3999 - val_loss: 1783.8590\n",
      "Epoch 1460/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.5780 - val_loss: 1779.1754\n",
      "Epoch 1461/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.5549 - val_loss: 1786.1144\n",
      "Epoch 1462/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1771.4474 - val_loss: 1780.6223\n",
      "Epoch 1463/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1771.9763 - val_loss: 1783.9696\n",
      "Epoch 1464/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.6375 - val_loss: 1780.3906\n",
      "Epoch 1465/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1770.7327 - val_loss: 1781.7839\n",
      "Epoch 1466/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.7686 - val_loss: 1784.8026\n",
      "Epoch 1467/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.3789 - val_loss: 1784.6448\n",
      "Epoch 1468/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1772.9207 - val_loss: 1782.8420\n",
      "Epoch 1469/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1771.4595 - val_loss: 1779.7924\n",
      "Epoch 1470/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.2725 - val_loss: 1779.5715\n",
      "Epoch 1471/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.0608 - val_loss: 1779.8401\n",
      "Epoch 1472/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.9434 - val_loss: 1781.4647\n",
      "Epoch 1473/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.0469 - val_loss: 1781.1835\n",
      "Epoch 1474/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.9983 - val_loss: 1781.7393\n",
      "Epoch 1475/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.2240 - val_loss: 1782.6830\n",
      "Epoch 1476/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.5339 - val_loss: 1782.4277\n",
      "Epoch 1477/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.8115 - val_loss: 1781.4628\n",
      "Epoch 1478/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1771.5312 - val_loss: 1780.6874\n",
      "Epoch 1479/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1770.5763 - val_loss: 1780.8812\n",
      "Epoch 1480/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1770.6122 - val_loss: 1779.2538\n",
      "Epoch 1481/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1770.7335 - val_loss: 1779.0735\n",
      "Epoch 1482/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1772.3008 - val_loss: 1783.3339\n",
      "Epoch 1483/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.9498 - val_loss: 1784.6672\n",
      "Epoch 1484/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1770.7983 - val_loss: 1780.1326\n",
      "Epoch 1485/10000\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 1769.7251 - val_loss: 1778.1664\n",
      "Epoch 1486/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1770.7698 - val_loss: 1778.8523\n",
      "Epoch 1487/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1769.7781 - val_loss: 1779.8447\n",
      "Epoch 1488/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1769.1631 - val_loss: 1780.8518\n",
      "Epoch 1489/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.4940 - val_loss: 1781.6840\n",
      "Epoch 1490/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1770.3633 - val_loss: 1779.3224\n",
      "Epoch 1491/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1770.0577 - val_loss: 1780.7435\n",
      "Epoch 1492/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1769.3309 - val_loss: 1780.5186\n",
      "Epoch 1493/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1768.8564 - val_loss: 1778.8938\n",
      "Epoch 1494/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1769.8379 - val_loss: 1780.2424\n",
      "Epoch 1495/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1770.4719 - val_loss: 1780.6182\n",
      "Epoch 1496/10000\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1770.7943 - val_loss: 1782.0215\n",
      "Epoch 1497/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.9164 - val_loss: 1781.9395\n",
      "Epoch 1498/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1768.8489 - val_loss: 1781.1006\n",
      "Epoch 1499/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1770.5645 - val_loss: 1780.1949\n",
      "Epoch 1500/10000\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 1770.3823 - val_loss: 1777.6555\n",
      "Epoch 1501/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1770.0988 - val_loss: 1779.9811\n",
      "Epoch 1502/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.6946 - val_loss: 1779.5164\n",
      "Epoch 1503/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1768.9585 - val_loss: 1780.3999\n",
      "Epoch 1504/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1768.2810 - val_loss: 1780.3503\n",
      "Epoch 1505/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.1013 - val_loss: 1790.1506\n",
      "Epoch 1506/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.5399 - val_loss: 1779.6737\n",
      "Epoch 1507/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1769.9497 - val_loss: 1778.3539\n",
      "Epoch 1508/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1768.5680 - val_loss: 1780.6830\n",
      "Epoch 1509/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.0277 - val_loss: 1779.9526\n",
      "Epoch 1510/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.1598 - val_loss: 1782.2419\n",
      "Epoch 1511/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1769.0516 - val_loss: 1781.6699\n",
      "Epoch 1512/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.1356 - val_loss: 1782.2267\n",
      "Epoch 1513/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1770.2704 - val_loss: 1780.5884\n",
      "Epoch 1514/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.3264 - val_loss: 1783.6942\n",
      "Epoch 1515/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.1904 - val_loss: 1780.7716\n",
      "Epoch 1516/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1770.5881 - val_loss: 1778.0225\n",
      "Epoch 1517/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1772.3732 - val_loss: 1786.8131\n",
      "Epoch 1518/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1779.8506 - val_loss: 1786.4452\n",
      "Epoch 1519/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1778.3945 - val_loss: 1783.1305\n",
      "Epoch 1520/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1778.6798 - val_loss: 1787.6959\n",
      "Epoch 1521/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1777.4795 - val_loss: 1784.2255\n",
      "Epoch 1522/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1774.1913 - val_loss: 1782.2769\n",
      "Epoch 1523/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1774.1455 - val_loss: 1779.8763\n",
      "Epoch 1524/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1773.5215 - val_loss: 1783.7050\n",
      "Epoch 1525/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1773.3931 - val_loss: 1783.3441\n",
      "Epoch 1526/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1773.6782 - val_loss: 1784.0161\n",
      "Epoch 1527/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1773.3685 - val_loss: 1781.2465\n",
      "Epoch 1528/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.6052 - val_loss: 1781.7520\n",
      "Epoch 1529/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1771.9766 - val_loss: 1781.5056\n",
      "Epoch 1530/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1772.5094 - val_loss: 1781.5297\n",
      "Epoch 1531/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.7964 - val_loss: 1779.2092\n",
      "Epoch 1532/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.1548 - val_loss: 1779.4452\n",
      "Epoch 1533/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.2677 - val_loss: 1778.4193\n",
      "Epoch 1534/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.8513 - val_loss: 1778.8138\n",
      "Epoch 1535/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1771.8184 - val_loss: 1777.8588\n",
      "Epoch 1536/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1770.3669 - val_loss: 1780.9583\n",
      "Epoch 1537/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.9678 - val_loss: 1778.8518\n",
      "Epoch 1538/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1771.4059 - val_loss: 1776.8796\n",
      "Epoch 1539/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.5927 - val_loss: 1779.1219\n",
      "Epoch 1540/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1770.5681 - val_loss: 1783.2812\n",
      "Epoch 1541/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1772.8307 - val_loss: 1783.8076\n",
      "Epoch 1542/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1770.4625 - val_loss: 1777.3135\n",
      "Epoch 1543/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1770.3016 - val_loss: 1776.8324\n",
      "Epoch 1544/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.1302 - val_loss: 1778.0416\n",
      "Epoch 1545/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1768.9208 - val_loss: 1780.4697\n",
      "Epoch 1546/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1770.2516 - val_loss: 1777.7419\n",
      "Epoch 1547/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1769.4071 - val_loss: 1782.7487\n",
      "Epoch 1548/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.6283 - val_loss: 1780.5729\n",
      "Epoch 1549/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1771.6124 - val_loss: 1781.1035\n",
      "Epoch 1550/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1770.6885 - val_loss: 1778.5769\n",
      "Epoch 1551/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.0485 - val_loss: 1779.2786\n",
      "Epoch 1552/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.9741 - val_loss: 1778.1659\n",
      "Epoch 1553/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1768.4333 - val_loss: 1778.6565\n",
      "Epoch 1554/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.3221 - val_loss: 1781.2739\n",
      "Epoch 1555/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.5144 - val_loss: 1777.3875\n",
      "Epoch 1556/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1771.1831 - val_loss: 1779.3329\n",
      "Epoch 1557/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.8021 - val_loss: 1778.5229\n",
      "Epoch 1558/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1770.3558 - val_loss: 1778.9945\n",
      "Epoch 1559/10000\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 1773.5111 - val_loss: 1775.5001\n",
      "Epoch 1560/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1771.0762 - val_loss: 1776.5005\n",
      "Epoch 1561/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1769.5464 - val_loss: 1777.1609\n",
      "Epoch 1562/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1768.2561 - val_loss: 1778.6030\n",
      "Epoch 1563/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1768.9698 - val_loss: 1779.6318\n",
      "Epoch 1564/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.8462 - val_loss: 1781.6771\n",
      "Epoch 1565/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.0663 - val_loss: 1780.0737\n",
      "Epoch 1566/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.1450 - val_loss: 1776.8606\n",
      "Epoch 1567/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1768.3463 - val_loss: 1778.6221\n",
      "Epoch 1568/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.4047 - val_loss: 1779.9752\n",
      "Epoch 1569/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.2817 - val_loss: 1777.6656\n",
      "Epoch 1570/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.6742 - val_loss: 1776.2555\n",
      "Epoch 1571/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.2009 - val_loss: 1780.7430\n",
      "Epoch 1572/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.2832 - val_loss: 1778.7654\n",
      "Epoch 1573/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.4368 - val_loss: 1782.5099\n",
      "Epoch 1574/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1768.9795 - val_loss: 1779.4135\n",
      "Epoch 1575/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1768.9113 - val_loss: 1778.8816\n",
      "Epoch 1576/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1768.5731 - val_loss: 1780.9834\n",
      "Epoch 1577/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1767.6208 - val_loss: 1780.0350\n",
      "Epoch 1578/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1768.0283 - val_loss: 1782.0244\n",
      "Epoch 1579/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.6943 - val_loss: 1778.9681\n",
      "Epoch 1580/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1767.1791 - val_loss: 1779.9883\n",
      "Epoch 1581/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.4622 - val_loss: 1776.7161\n",
      "Epoch 1582/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1767.3350 - val_loss: 1777.6440\n",
      "Epoch 1583/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1767.9573 - val_loss: 1777.3002\n",
      "Epoch 1584/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1767.9615 - val_loss: 1776.8186\n",
      "Epoch 1585/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1767.2626 - val_loss: 1778.7295\n",
      "Epoch 1586/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1768.4755 - val_loss: 1779.5437\n",
      "Epoch 1587/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.4253 - val_loss: 1780.7965\n",
      "Epoch 1588/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1767.6228 - val_loss: 1779.0846\n",
      "Epoch 1589/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 40ms/step - loss: 1767.6473 - val_loss: 1779.7222\n",
      "Epoch 1590/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1767.3707 - val_loss: 1777.7369\n",
      "Epoch 1591/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1767.2172 - val_loss: 1775.8813\n",
      "Epoch 1592/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1767.4927 - val_loss: 1776.2145\n",
      "Epoch 1593/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1767.0630 - val_loss: 1777.6296\n",
      "Epoch 1594/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.8759 - val_loss: 1776.5211\n",
      "Epoch 1595/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.9399 - val_loss: 1778.1241\n",
      "Epoch 1596/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1767.0260 - val_loss: 1778.7291\n",
      "Epoch 1597/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1768.2670 - val_loss: 1784.3745\n",
      "Epoch 1598/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.3958 - val_loss: 1782.3214\n",
      "Epoch 1599/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.6653 - val_loss: 1785.2618\n",
      "Epoch 1600/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1769.0818 - val_loss: 1776.1791\n",
      "Epoch 1601/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1769.3040 - val_loss: 1780.0398\n",
      "Epoch 1602/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.2775 - val_loss: 1776.6346\n",
      "Epoch 1603/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1767.6821 - val_loss: 1776.6029\n",
      "Epoch 1604/10000\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 1767.6831 - val_loss: 1775.6969\n",
      "Epoch 1605/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1767.3033 - val_loss: 1776.4004\n",
      "Epoch 1606/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1766.6500 - val_loss: 1777.6085\n",
      "Epoch 1607/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.8428 - val_loss: 1778.9437\n",
      "Epoch 1608/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.7620 - val_loss: 1778.6761\n",
      "Epoch 1609/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.9189 - val_loss: 1777.1963\n",
      "Epoch 1610/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1767.4583 - val_loss: 1779.0154\n",
      "Epoch 1611/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.9111 - val_loss: 1776.0518\n",
      "Epoch 1612/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.6865 - val_loss: 1778.1901\n",
      "Epoch 1613/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.7405 - val_loss: 1778.9711\n",
      "Epoch 1614/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.6885 - val_loss: 1777.1066\n",
      "Epoch 1615/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1767.1179 - val_loss: 1775.7909\n",
      "Epoch 1616/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.2183 - val_loss: 1777.6958\n",
      "Epoch 1617/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1766.7925 - val_loss: 1778.5122\n",
      "Epoch 1618/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1768.1768 - val_loss: 1780.3425\n",
      "Epoch 1619/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.1561 - val_loss: 1777.3693\n",
      "Epoch 1620/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1766.2511 - val_loss: 1779.0780\n",
      "Epoch 1621/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.3217 - val_loss: 1781.4731\n",
      "Epoch 1622/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1767.3613 - val_loss: 1780.8105\n",
      "Epoch 1623/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.7666 - val_loss: 1777.9365\n",
      "Epoch 1624/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.5941 - val_loss: 1776.4041\n",
      "Epoch 1625/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1767.1079 - val_loss: 1775.7001\n",
      "Epoch 1626/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1765.8560 - val_loss: 1775.6912\n",
      "Epoch 1627/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.9362 - val_loss: 1776.1715\n",
      "Epoch 1628/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.4951 - val_loss: 1776.9438\n",
      "Epoch 1629/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.3474 - val_loss: 1776.6417\n",
      "Epoch 1630/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1765.8744 - val_loss: 1777.2754\n",
      "Epoch 1631/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1766.3141 - val_loss: 1777.0774\n",
      "Epoch 1632/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.8545 - val_loss: 1780.9272\n",
      "Epoch 1633/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.4991 - val_loss: 1777.5465\n",
      "Epoch 1634/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.6471 - val_loss: 1778.4132\n",
      "Epoch 1635/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1767.0781 - val_loss: 1780.8384\n",
      "Epoch 1636/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1766.6193 - val_loss: 1782.1404\n",
      "Epoch 1637/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1766.8594 - val_loss: 1777.0835\n",
      "Epoch 1638/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1766.3514 - val_loss: 1776.4683\n",
      "Epoch 1639/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1765.4777 - val_loss: 1777.1669\n",
      "Epoch 1640/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1765.6229 - val_loss: 1780.2311\n",
      "Epoch 1641/10000\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 1766.4535 - val_loss: 1775.4274\n",
      "Epoch 1642/10000\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 1765.4485 - val_loss: 1773.9460\n",
      "Epoch 1643/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1765.6569 - val_loss: 1774.7635\n",
      "Epoch 1644/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1765.5491 - val_loss: 1776.3092\n",
      "Epoch 1645/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1765.1959 - val_loss: 1775.8064\n",
      "Epoch 1646/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1764.2800 - val_loss: 1777.4669\n",
      "Epoch 1647/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.9568 - val_loss: 1778.2870\n",
      "Epoch 1648/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1765.0726 - val_loss: 1777.6666\n",
      "Epoch 1649/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.7041 - val_loss: 1776.7478\n",
      "Epoch 1650/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.0881 - val_loss: 1775.5157\n",
      "Epoch 1651/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1765.6420 - val_loss: 1777.8284\n",
      "Epoch 1652/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.3843 - val_loss: 1777.5338\n",
      "Epoch 1653/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.6016 - val_loss: 1778.1240\n",
      "Epoch 1654/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1764.1941 - val_loss: 1776.6755\n",
      "Epoch 1655/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.9279 - val_loss: 1776.1703\n",
      "Epoch 1656/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.1567 - val_loss: 1776.7067\n",
      "Epoch 1657/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1763.9207 - val_loss: 1775.4246\n",
      "Epoch 1658/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1764.0088 - val_loss: 1774.1130\n",
      "Epoch 1659/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.4368 - val_loss: 1776.6664\n",
      "Epoch 1660/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.0199 - val_loss: 1779.4705\n",
      "Epoch 1661/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.2738 - val_loss: 1782.1361\n",
      "Epoch 1662/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.7736 - val_loss: 1777.8624\n",
      "Epoch 1663/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1766.0918 - val_loss: 1780.3513\n",
      "Epoch 1664/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1766.9215 - val_loss: 1780.0612\n",
      "Epoch 1665/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1769.3502 - val_loss: 1779.3029\n",
      "Epoch 1666/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.1187 - val_loss: 1779.3745\n",
      "Epoch 1667/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1770.0270 - val_loss: 1782.3497\n",
      "Epoch 1668/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1768.7029 - val_loss: 1780.0535\n",
      "Epoch 1669/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1767.7225 - val_loss: 1789.5763\n",
      "Epoch 1670/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1768.3328 - val_loss: 1780.0732\n",
      "Epoch 1671/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1768.0061 - val_loss: 1780.2760\n",
      "Epoch 1672/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1765.5981 - val_loss: 1776.2744\n",
      "Epoch 1673/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1766.6774 - val_loss: 1774.4595\n",
      "Epoch 1674/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1765.4775 - val_loss: 1776.0099\n",
      "Epoch 1675/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.6370 - val_loss: 1776.7881\n",
      "Epoch 1676/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.8582 - val_loss: 1777.6416\n",
      "Epoch 1677/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1765.6615 - val_loss: 1779.6718\n",
      "Epoch 1678/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1767.9287 - val_loss: 1785.5001\n",
      "Epoch 1679/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.0481 - val_loss: 1780.6628\n",
      "Epoch 1680/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1766.9967 - val_loss: 1775.1031\n",
      "Epoch 1681/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1765.7545 - val_loss: 1774.2603\n",
      "Epoch 1682/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.9443 - val_loss: 1775.3000\n",
      "Epoch 1683/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.0404 - val_loss: 1774.9775\n",
      "Epoch 1684/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1764.9611 - val_loss: 1774.2482\n",
      "Epoch 1685/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1765.9760 - val_loss: 1774.4489\n",
      "Epoch 1686/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.7495 - val_loss: 1776.0869\n",
      "Epoch 1687/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1764.5947 - val_loss: 1778.8530\n",
      "Epoch 1688/10000\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 1763.6631 - val_loss: 1773.4979\n",
      "Epoch 1689/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.9525 - val_loss: 1774.4698\n",
      "Epoch 1690/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1763.2842 - val_loss: 1773.6904\n",
      "Epoch 1691/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1763.4004 - val_loss: 1774.8477\n",
      "Epoch 1692/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1764.0645 - val_loss: 1775.8546\n",
      "Epoch 1693/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1763.8237 - val_loss: 1774.1370\n",
      "Epoch 1694/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.5071 - val_loss: 1774.3585\n",
      "Epoch 1695/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1764.0972 - val_loss: 1774.9229\n",
      "Epoch 1696/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.4635 - val_loss: 1779.7213\n",
      "Epoch 1697/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1764.5427 - val_loss: 1776.3380\n",
      "Epoch 1698/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.4207 - val_loss: 1774.2911\n",
      "Epoch 1699/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.1742 - val_loss: 1775.6221\n",
      "Epoch 1700/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1763.5828 - val_loss: 1780.0439\n",
      "Epoch 1701/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1764.2045 - val_loss: 1777.2197\n",
      "Epoch 1702/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.9725 - val_loss: 1774.9863\n",
      "Epoch 1703/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.9634 - val_loss: 1776.7950\n",
      "Epoch 1704/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1765.3431 - val_loss: 1779.5052\n",
      "Epoch 1705/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1766.8073 - val_loss: 1775.8131\n",
      "Epoch 1706/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1765.0790 - val_loss: 1775.9478\n",
      "Epoch 1707/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.8989 - val_loss: 1774.0117\n",
      "Epoch 1708/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1763.5273 - val_loss: 1773.5875\n",
      "Epoch 1709/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.5996 - val_loss: 1776.0684\n",
      "Epoch 1710/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1763.0557 - val_loss: 1774.3068\n",
      "Epoch 1711/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.7704 - val_loss: 1774.3461\n",
      "Epoch 1712/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1763.9283 - val_loss: 1773.9949\n",
      "Epoch 1713/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.7808 - val_loss: 1777.6971\n",
      "Epoch 1714/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1763.2987 - val_loss: 1778.6180\n",
      "Epoch 1715/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1763.8345 - val_loss: 1775.0332\n",
      "Epoch 1716/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1763.2590 - val_loss: 1777.7466\n",
      "Epoch 1717/10000\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 1764.2732 - val_loss: 1773.1279\n",
      "Epoch 1718/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.5706 - val_loss: 1776.1168\n",
      "Epoch 1719/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.2108 - val_loss: 1777.3643\n",
      "Epoch 1720/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.6288 - val_loss: 1776.5509\n",
      "Epoch 1721/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.3361 - val_loss: 1779.1700\n",
      "Epoch 1722/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.0961 - val_loss: 1777.3402\n",
      "Epoch 1723/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1764.7759 - val_loss: 1776.8036\n",
      "Epoch 1724/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1765.3245 - val_loss: 1777.1327\n",
      "Epoch 1725/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1765.3604 - val_loss: 1778.1056\n",
      "Epoch 1726/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1764.8075 - val_loss: 1783.5018\n",
      "Epoch 1727/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.0834 - val_loss: 1778.3589\n",
      "Epoch 1728/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1764.1442 - val_loss: 1777.1433\n",
      "Epoch 1729/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.9760 - val_loss: 1773.9009\n",
      "Epoch 1730/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1763.4249 - val_loss: 1774.6864\n",
      "Epoch 1731/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1763.2073 - val_loss: 1775.6671\n",
      "Epoch 1732/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1762.8567 - val_loss: 1776.6726\n",
      "Epoch 1733/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.6013 - val_loss: 1774.4183\n",
      "Epoch 1734/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1763.1357 - val_loss: 1775.5911\n",
      "Epoch 1735/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.3965 - val_loss: 1778.3773\n",
      "Epoch 1736/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.9443 - val_loss: 1776.3595\n",
      "Epoch 1737/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.8802 - val_loss: 1775.8938\n",
      "Epoch 1738/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1761.9561 - val_loss: 1776.4818\n",
      "Epoch 1739/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 40ms/step - loss: 1762.3174 - val_loss: 1775.6346\n",
      "Epoch 1740/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.7415 - val_loss: 1774.5830\n",
      "Epoch 1741/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.1322 - val_loss: 1776.7395\n",
      "Epoch 1742/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.2526 - val_loss: 1775.6591\n",
      "Epoch 1743/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1762.4899 - val_loss: 1773.7865\n",
      "Epoch 1744/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1762.7263 - val_loss: 1776.2314\n",
      "Epoch 1745/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1762.6289 - val_loss: 1775.3849\n",
      "Epoch 1746/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1761.7842 - val_loss: 1775.7463\n",
      "Epoch 1747/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.5378 - val_loss: 1773.8046\n",
      "Epoch 1748/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1763.4781 - val_loss: 1774.8141\n",
      "Epoch 1749/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.9341 - val_loss: 1775.7343\n",
      "Epoch 1750/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.8717 - val_loss: 1779.3213\n",
      "Epoch 1751/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.0693 - val_loss: 1775.8521\n",
      "Epoch 1752/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.3635 - val_loss: 1775.2147\n",
      "Epoch 1753/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1764.0752 - val_loss: 1781.5420\n",
      "Epoch 1754/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1762.6188 - val_loss: 1776.4840\n",
      "Epoch 1755/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.2742 - val_loss: 1775.4746\n",
      "Epoch 1756/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.2065 - val_loss: 1778.2419\n",
      "Epoch 1757/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.5663 - val_loss: 1777.3329\n",
      "Epoch 1758/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1763.4684 - val_loss: 1776.3154\n",
      "Epoch 1759/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.9795 - val_loss: 1781.3187\n",
      "Epoch 1760/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.7574 - val_loss: 1777.0074\n",
      "Epoch 1761/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1762.3961 - val_loss: 1775.2655\n",
      "Epoch 1762/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.5132 - val_loss: 1775.7350\n",
      "Epoch 1763/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1761.3500 - val_loss: 1778.0121\n",
      "Epoch 1764/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.7158 - val_loss: 1778.0785\n",
      "Epoch 1765/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1763.6853 - val_loss: 1774.7256\n",
      "Epoch 1766/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1763.5011 - val_loss: 1782.7549\n",
      "Epoch 1767/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.9973 - val_loss: 1776.1117\n",
      "Epoch 1768/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1764.4319 - val_loss: 1779.5918\n",
      "Epoch 1769/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1764.1481 - val_loss: 1777.5679\n",
      "Epoch 1770/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1762.9757 - val_loss: 1778.2780\n",
      "Epoch 1771/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1762.7113 - val_loss: 1779.0116\n",
      "Epoch 1772/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1762.9679 - val_loss: 1775.7483\n",
      "Epoch 1773/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1761.5044 - val_loss: 1776.7991\n",
      "Epoch 1774/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1760.9633 - val_loss: 1777.6390\n",
      "Epoch 1775/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1762.0902 - val_loss: 1775.0769\n",
      "Epoch 1776/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.2866 - val_loss: 1778.1285\n",
      "Epoch 1777/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1761.6373 - val_loss: 1773.6067\n",
      "Epoch 1778/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1763.4067 - val_loss: 1774.0071\n",
      "Epoch 1779/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1761.3651 - val_loss: 1777.1763\n",
      "Epoch 1780/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1761.3815 - val_loss: 1775.8383\n",
      "Epoch 1781/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1762.3054 - val_loss: 1775.1466\n",
      "Epoch 1782/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.3763 - val_loss: 1774.9301\n",
      "Epoch 1783/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1761.8436 - val_loss: 1775.8634\n",
      "Epoch 1784/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.3846 - val_loss: 1775.0577\n",
      "Epoch 1785/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1761.4700 - val_loss: 1775.5605\n",
      "Epoch 1786/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.8175 - val_loss: 1777.7231\n",
      "Epoch 1787/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1760.3239 - val_loss: 1775.3344\n",
      "Epoch 1788/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.7524 - val_loss: 1777.9064\n",
      "Epoch 1789/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.5673 - val_loss: 1779.7946\n",
      "Epoch 1790/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.9498 - val_loss: 1778.6055\n",
      "Epoch 1791/10000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1761.9694 - val_loss: 1777.0890\n",
      "Epoch 1792/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.9377 - val_loss: 1777.0774\n",
      "Epoch 1793/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1763.1943 - val_loss: 1777.9603\n",
      "Epoch 1794/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1763.1399 - val_loss: 1779.9209\n",
      "Epoch 1795/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.2809 - val_loss: 1775.8148\n",
      "Epoch 1796/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1760.8339 - val_loss: 1775.3812\n",
      "Epoch 1797/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1760.2253 - val_loss: 1775.1307\n",
      "Epoch 1798/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1761.0875 - val_loss: 1778.1770\n",
      "Epoch 1799/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.7505 - val_loss: 1777.7075\n",
      "Epoch 1800/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.9702 - val_loss: 1781.0225\n",
      "Epoch 1801/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.7169 - val_loss: 1777.3381\n",
      "Epoch 1802/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1761.2231 - val_loss: 1779.5580\n",
      "Epoch 1803/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1761.2992 - val_loss: 1777.0183\n",
      "Epoch 1804/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1761.3573 - val_loss: 1780.5372\n",
      "Epoch 1805/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1761.4199 - val_loss: 1774.6600\n",
      "Epoch 1806/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1766.8927 - val_loss: 1783.9916\n",
      "Epoch 1807/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1771.1122 - val_loss: 1780.0834\n",
      "Epoch 1808/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1769.6512 - val_loss: 1784.1570\n",
      "Epoch 1809/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1765.7258 - val_loss: 1781.6760\n",
      "Epoch 1810/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.2837 - val_loss: 1778.5421\n",
      "Epoch 1811/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1763.1619 - val_loss: 1779.4437\n",
      "Epoch 1812/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1762.6942 - val_loss: 1778.1453\n",
      "Epoch 1813/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1762.4344 - val_loss: 1776.6847\n",
      "Epoch 1814/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1762.1945 - val_loss: 1780.2463\n",
      "Epoch 1815/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1761.7352 - val_loss: 1777.9331\n",
      "Epoch 1816/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1761.7865 - val_loss: 1783.3186\n",
      "Epoch 1817/10000\n",
      "9/9 [==============================] - ETA: 0s - loss: 1763.4581Restoring model weights from the end of the best epoch: 1717.\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1763.4581 - val_loss: 1778.3726\n",
      "Epoch 1817: early stopping\n"
     ]
    }
   ],
   "source": [
    "fp_latent1024_model_history=fp_latent1024_model.fit([x_train, inputs2decoder_latent1024_train], x_train, batch_size = BATCH_SIZE, epochs=10000, \n",
    "          callbacks = lfadfp_latent1024_callbacks,\n",
    "          validation_data=([x_val, inputs2decoder_latent1024_val], x_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e80e9",
   "metadata": {},
   "source": [
    "# test increase encoder dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ac06e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff41c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs2decoder_train shape:  (136, 73, 64)\n",
      "inputs2decoder_val shape:  (17, 73, 64)\n"
     ]
    }
   ],
   "source": [
    "inputs2decoder_encoder1024_train, inputs2decoder_encoder1024_val = get_decoder_input(decoder_dim=decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f3806f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_encoder1024_model = create_fpmodel(encoder_dim=1024, decoder_dim = decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ab0449ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)          [(None, 73, 70)]     0           []                               \n",
      "                                                                                                  \n",
      " initial_dropout (Dropout)      (None, 73, 70)       0           ['input_22[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder_BidirectionalGRU (Bidi  [(None, 2048),      6733824     ['initial_dropout[0][0]']        \n",
      " rectional)                      (None, 1024),                                                    \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " postencoder_dropout (Dropout)  (None, 2048)         0           ['Encoder_BidirectionalGRU[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 73, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_latent (Dense)           (None, 64)           131136      ['postencoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " DecoderGRU (GRU)               (None, 73, 64)       24960       ['input_23[0][0]',               \n",
      "                                                                  'dense_latent[0][0]']           \n",
      "                                                                                                  \n",
      " postdecoder_dropout (Dropout)  (None, 73, 64)       0           ['DecoderGRU[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 73, 4)        256         ['postdecoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " nerual_dense (Dense)           (None, 73, 70)       350         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,890,526\n",
      "Trainable params: 6,890,526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fp_encoder1024_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed3972",
   "metadata": {},
   "source": [
    "# train\n",
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b930213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(\"fp_log.csv\", separator=\",\", append=False)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"lfadfp.h5\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    save_weights_only= False\n",
    ")\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lfadfp_encoder1024_callbacks=[csv_logger, model_check, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "907b0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-2,\n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0f84eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_encoder1024_model.compile(\n",
    "    loss = poisson_loglike_loss,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "752e8c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "9/9 [==============================] - 1s 47ms/step - loss: 18580084736.0000 - val_loss: 30069.4863\n",
      "Epoch 2/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 14850472960.0000 - val_loss: 14066029.0000\n",
      "Epoch 3/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 135977975808.0000 - val_loss: 12542960.0000\n",
      "Epoch 4/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1493950398464.0000 - val_loss: 1632980.5000\n",
      "Epoch 5/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 270346338304.0000 - val_loss: 1323359.6250\n",
      "Epoch 6/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 7534167552.0000 - val_loss: 472962.5938\n",
      "Epoch 7/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2478222336.0000 - val_loss: 2655280.7500\n",
      "Epoch 8/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1887852416.0000 - val_loss: 28736.5410\n",
      "Epoch 9/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 73417440.0000 - val_loss: 100511.2656\n",
      "Epoch 10/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 299187328.0000 - val_loss: 97982.4141\n",
      "Epoch 11/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1077871378432.0000 - val_loss: 24345550.0000\n",
      "Epoch 12/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 3513356032.0000 - val_loss: 1486110.5000\n",
      "Epoch 13/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 188440080.0000 - val_loss: 1212918.0000\n",
      "Epoch 14/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 878047488.0000 - val_loss: 717546.5625\n",
      "Epoch 15/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 257769616.0000 - val_loss: 394062.9688\n",
      "Epoch 16/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 9486885888.0000 - val_loss: 232164.1250\n",
      "Epoch 17/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 141732176.0000 - val_loss: 301565.2812\n",
      "Epoch 18/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 53051612.0000 - val_loss: 276148.8438\n",
      "Epoch 19/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 36723644.0000 - val_loss: 62641.6602\n",
      "Epoch 20/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 42215424.0000 - val_loss: 4421.3105\n",
      "Epoch 21/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 152578.5469 - val_loss: 4396.4092\n",
      "Epoch 22/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 441177.7500 - val_loss: 4386.2202\n",
      "Epoch 23/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 123486.1875 - val_loss: 4378.7480\n",
      "Epoch 24/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 123220.1016 - val_loss: 4371.2451\n",
      "Epoch 25/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1014419.1875 - val_loss: 4362.3271\n",
      "Epoch 26/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 247164.1406 - val_loss: 4357.4312\n",
      "Epoch 27/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 110420.0781 - val_loss: 4352.7773\n",
      "Epoch 28/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 210092.0469 - val_loss: 4348.1250\n",
      "Epoch 29/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 1009656.0000 - val_loss: 4340.5342\n",
      "Epoch 30/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 897967.1250 - val_loss: 4337.2227\n",
      "Epoch 31/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 68419.6562 - val_loss: 4333.6357\n",
      "Epoch 32/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1213996.6250 - val_loss: 4329.8086\n",
      "Epoch 33/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 85462.6250 - val_loss: 4326.5513\n",
      "Epoch 34/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 103970.3672 - val_loss: 4318.8608\n",
      "Epoch 35/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 8828442.0000 - val_loss: 4317.0640\n",
      "Epoch 36/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 152128.5781 - val_loss: 4314.1406\n",
      "Epoch 37/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 640291.3125 - val_loss: 4306.9722\n",
      "Epoch 38/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 201432.8438 - val_loss: 4303.3262\n",
      "Epoch 39/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 371697.8750 - val_loss: 4300.1680\n",
      "Epoch 40/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 34140.8242 - val_loss: 4297.1030\n",
      "Epoch 41/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 302949.7188 - val_loss: 4290.1787\n",
      "Epoch 42/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 313424.1875 - val_loss: 4286.0513\n",
      "Epoch 43/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 73281.8125 - val_loss: 4282.8794\n",
      "Epoch 44/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 3002875.2500 - val_loss: 4275.5615\n",
      "Epoch 45/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 69497.6016 - val_loss: 4272.2739\n",
      "Epoch 46/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2798000.0000 - val_loss: 4269.1064\n",
      "Epoch 47/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1443085.0000 - val_loss: 4260.8237\n",
      "Epoch 48/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 4709026.5000 - val_loss: 4254.7827\n",
      "Epoch 49/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 310745.2812 - val_loss: 4251.2544\n",
      "Epoch 50/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 14580376.0000 - val_loss: 4237.2959\n",
      "Epoch 51/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1211268.0000 - val_loss: 4202.9248\n",
      "Epoch 52/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 755149.5000 - val_loss: 4197.1924\n",
      "Epoch 53/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 1451484.6250 - val_loss: 4194.3145\n",
      "Epoch 54/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 4041955.2500 - val_loss: 4191.3770\n",
      "Epoch 55/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 5623797.5000 - val_loss: 4184.6221\n",
      "Epoch 56/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 467385.7500 - val_loss: 4178.9258\n",
      "Epoch 57/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 255465.3594 - val_loss: 4176.5952\n",
      "Epoch 58/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2853233.2500 - val_loss: 4172.3843\n",
      "Epoch 59/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 1925463.7500 - val_loss: 4168.3872\n",
      "Epoch 60/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1708301.0000 - val_loss: 4153.9365\n",
      "Epoch 61/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 221449.8906 - val_loss: 4146.8711\n",
      "Epoch 62/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 71267.5391 - val_loss: 4143.8867\n",
      "Epoch 63/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 330075.4062 - val_loss: 4141.5903\n",
      "Epoch 64/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 207219.7031 - val_loss: 4136.1675\n",
      "Epoch 65/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 585403.3125 - val_loss: 4133.9473\n",
      "Epoch 66/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 509757.4688 - val_loss: 4127.9863\n",
      "Epoch 67/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 70486.3125 - val_loss: 4125.1348\n",
      "Epoch 68/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 804148.6250 - val_loss: 4122.7075\n",
      "Epoch 69/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 325752.2500 - val_loss: 4117.6992\n",
      "Epoch 70/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 103233.7500 - val_loss: 4115.2949\n",
      "Epoch 71/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2071227.7500 - val_loss: 4113.3525\n",
      "Epoch 72/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 297918.9375 - val_loss: 4108.1807\n",
      "Epoch 73/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 431608.2500 - val_loss: 4105.6074\n",
      "Epoch 74/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 2330031.5000 - val_loss: 4106.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1618072.0000 - val_loss: 4098.1709\n",
      "Epoch 76/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3840727.0000 - val_loss: 4095.2468\n",
      "Epoch 77/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 4824847.0000 - val_loss: 4089.2109\n",
      "Epoch 78/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 426782.6250 - val_loss: 4083.1499\n",
      "Epoch 79/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3285831.0000 - val_loss: 4079.6807\n",
      "Epoch 80/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1235307.8750 - val_loss: 4073.5713\n",
      "Epoch 81/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 62056.4336 - val_loss: 4071.5801\n",
      "Epoch 82/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 203778.4531 - val_loss: 4069.6230\n",
      "Epoch 83/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3817082.0000 - val_loss: 4062.1182\n",
      "Epoch 84/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 356110.0625 - val_loss: 4055.2573\n",
      "Epoch 85/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 386470.9375 - val_loss: 4051.5801\n",
      "Epoch 86/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 691697.3750 - val_loss: 4046.6240\n",
      "Epoch 87/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 174767.7812 - val_loss: 4041.0610\n",
      "Epoch 88/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 113522.3750 - val_loss: 4039.6724\n",
      "Epoch 89/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1320995.5000 - val_loss: 4036.9260\n",
      "Epoch 90/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 206441.1875 - val_loss: 4031.2280\n",
      "Epoch 91/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 14780768.0000 - val_loss: 4024.8691\n",
      "Epoch 92/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 78984.1562 - val_loss: 4017.3547\n",
      "Epoch 93/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 245837.0938 - val_loss: 4013.6016\n",
      "Epoch 94/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2420045.7500 - val_loss: 4006.5723\n",
      "Epoch 95/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 189875.3438 - val_loss: 4004.3694\n",
      "Epoch 96/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 346844.6250 - val_loss: 3999.6626\n",
      "Epoch 97/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3071023.5000 - val_loss: 3997.7239\n",
      "Epoch 98/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1033908.1250 - val_loss: 3995.0134\n",
      "Epoch 99/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 20127334.0000 - val_loss: 3996.3135\n",
      "Epoch 100/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 146253.7344 - val_loss: 3993.8296\n",
      "Epoch 101/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 600375.0625 - val_loss: 3992.5125\n",
      "Epoch 102/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 5491289.5000 - val_loss: 3990.1526\n",
      "Epoch 103/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 759754.1875 - val_loss: 3987.7803\n",
      "Epoch 104/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1015874.5625 - val_loss: 3986.1985\n",
      "Epoch 105/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1496106.7500 - val_loss: 3983.0574\n",
      "Epoch 106/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 417908.5938 - val_loss: 3973.1504\n",
      "Epoch 107/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 413511.5938 - val_loss: 3968.9907\n",
      "Epoch 108/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 160961.6094 - val_loss: 3964.5579\n",
      "Epoch 109/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 107996.8281 - val_loss: 3961.8057\n",
      "Epoch 110/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 194097.8594 - val_loss: 3959.9941\n",
      "Epoch 111/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1159752.1250 - val_loss: 3954.7324\n",
      "Epoch 112/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 70161.7422 - val_loss: 3932.3970\n",
      "Epoch 113/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 230757.7031 - val_loss: 3917.6177\n",
      "Epoch 114/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 45462.1406 - val_loss: 3906.5137\n",
      "Epoch 115/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 208461.7031 - val_loss: 3890.6042\n",
      "Epoch 116/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 163428.2344 - val_loss: 3864.4282\n",
      "Epoch 117/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 201074.0000 - val_loss: 3841.6804\n",
      "Epoch 118/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 178591.9531 - val_loss: 3827.5928\n",
      "Epoch 119/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 128934.5859 - val_loss: 3795.3101\n",
      "Epoch 120/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 213820.3281 - val_loss: 3764.6062\n",
      "Epoch 121/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 36577.6328 - val_loss: 3749.1458\n",
      "Epoch 122/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 251423.0625 - val_loss: 3741.0488\n",
      "Epoch 123/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 449288.5312 - val_loss: 3752.4055\n",
      "Epoch 124/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 494464.4688 - val_loss: 3766.5247\n",
      "Epoch 125/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 928533.0625 - val_loss: 3667.9080\n",
      "Epoch 126/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 67905.0781 - val_loss: 3654.8184\n",
      "Epoch 127/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 56725.2812 - val_loss: 3651.5398\n",
      "Epoch 128/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 73977.5312 - val_loss: 3650.2920\n",
      "Epoch 129/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 31080.8301 - val_loss: 3648.9163\n",
      "Epoch 130/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1332972.8750 - val_loss: 3646.3406\n",
      "Epoch 131/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 430549.6250 - val_loss: 3644.2483\n",
      "Epoch 132/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 64510.7734 - val_loss: 3643.6038\n",
      "Epoch 133/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 111995.0391 - val_loss: 3642.2307\n",
      "Epoch 134/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 44562.6758 - val_loss: 3640.8030\n",
      "Epoch 135/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 261411.2656 - val_loss: 3638.2476\n",
      "Epoch 136/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 287946.4375 - val_loss: 3637.5725\n",
      "Epoch 137/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 50719.6328 - val_loss: 3635.6885\n",
      "Epoch 138/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 187893.4531 - val_loss: 3634.1018\n",
      "Epoch 139/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 186248.7969 - val_loss: 3632.6729\n",
      "Epoch 140/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 14692.9199 - val_loss: 3631.4958\n",
      "Epoch 141/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2023259.2500 - val_loss: 3629.4109\n",
      "Epoch 142/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 61035.0312 - val_loss: 3627.2271\n",
      "Epoch 143/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1107797.1250 - val_loss: 3625.8564\n",
      "Epoch 144/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 297540.7188 - val_loss: 3624.0532\n",
      "Epoch 145/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 32763.6953 - val_loss: 3623.8845\n",
      "Epoch 146/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 456923.0000 - val_loss: 3621.8965\n",
      "Epoch 147/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 43266.8594 - val_loss: 3620.5767\n",
      "Epoch 148/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 46503.1133 - val_loss: 3619.4668\n",
      "Epoch 149/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2506805.2500 - val_loss: 3620.3542\n",
      "Epoch 150/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 368655.1875 - val_loss: 3626.8298\n",
      "Epoch 151/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1372017.0000 - val_loss: 3636.7161\n",
      "Epoch 152/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 565809.0625 - val_loss: 3653.0154\n",
      "Epoch 153/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 146144.5312 - val_loss: 3658.8538\n",
      "Epoch 154/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 40331.3555 - val_loss: 3655.5320\n",
      "Epoch 155/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 114835.0156 - val_loss: 3654.6357\n",
      "Epoch 156/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 80977.0703 - val_loss: 3652.1414\n",
      "Epoch 157/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 35818.7031 - val_loss: 3651.5833\n",
      "Epoch 158/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 47381.0742 - val_loss: 3646.9009\n",
      "Epoch 159/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 17545.9531 - val_loss: 3643.9365\n",
      "Epoch 160/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 35101.0508 - val_loss: 3641.4751\n",
      "Epoch 161/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2214253.0000 - val_loss: 3736.4944\n",
      "Epoch 162/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 108154.9531 - val_loss: 3789.3486\n",
      "Epoch 163/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1122152.2500 - val_loss: 3758.1157\n",
      "Epoch 164/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 72763.2188 - val_loss: 3720.8677\n",
      "Epoch 165/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 94239.6953 - val_loss: 3702.3887\n",
      "Epoch 166/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 111223.0391 - val_loss: 3692.9956\n",
      "Epoch 167/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 160599.4844 - val_loss: 3682.7449\n",
      "Epoch 168/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 52896.2070 - val_loss: 3676.0605\n",
      "Epoch 169/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 532709.9375 - val_loss: 3691.3738\n",
      "Epoch 170/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 872062.7500 - val_loss: 3721.4509\n",
      "Epoch 171/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 381903.7188 - val_loss: 3733.5388\n",
      "Epoch 172/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 45871.2188 - val_loss: 3735.2117\n",
      "Epoch 173/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 122279.1953 - val_loss: 3679.9551\n",
      "Epoch 174/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 661180.0625 - val_loss: 3605.5459\n",
      "Epoch 175/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 521344.8125 - val_loss: 3590.9585\n",
      "Epoch 176/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 252736.8750 - val_loss: 3593.0901\n",
      "Epoch 177/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 61151.9688 - val_loss: 3608.1448\n",
      "Epoch 178/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 3482407.0000 - val_loss: 3632.7236\n",
      "Epoch 179/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 523318.7500 - val_loss: 3661.1934\n",
      "Epoch 180/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 205651.8281 - val_loss: 3644.2771\n",
      "Epoch 181/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 103373.1094 - val_loss: 3635.7314\n",
      "Epoch 182/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 62178.9844 - val_loss: 3625.4468\n",
      "Epoch 183/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 446796.2500 - val_loss: 3620.7422\n",
      "Epoch 184/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 310701.7188 - val_loss: 3616.2493\n",
      "Epoch 185/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 34846.9805 - val_loss: 3612.9019\n",
      "Epoch 186/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 49053.2969 - val_loss: 3609.1997\n",
      "Epoch 187/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 39378.7461 - val_loss: 3603.9338\n",
      "Epoch 188/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 25132.0293 - val_loss: 3602.4453\n",
      "Epoch 189/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 101395.7812 - val_loss: 3592.2295\n",
      "Epoch 190/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 31430.6836 - val_loss: 3584.9380\n",
      "Epoch 191/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 160440.4688 - val_loss: 3583.6587\n",
      "Epoch 192/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 462567.1875 - val_loss: 3591.5876\n",
      "Epoch 193/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 585792.1875 - val_loss: 3609.5339\n",
      "Epoch 194/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 173084.2812 - val_loss: 3615.0913\n",
      "Epoch 195/10000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 65840.5000 - val_loss: 3610.7390\n",
      "Epoch 196/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 112740.8984 - val_loss: 3609.1882\n",
      "Epoch 197/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 205485.2969 - val_loss: 3598.1687\n",
      "Epoch 198/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 39832.9219 - val_loss: 3575.7080\n",
      "Epoch 199/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 126535.9375 - val_loss: 3569.7910\n",
      "Epoch 200/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 22310.2227 - val_loss: 3565.0508\n",
      "Epoch 201/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 39591.8555 - val_loss: 3562.8186\n",
      "Epoch 202/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 514398.4062 - val_loss: 3528.1074\n",
      "Epoch 203/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 347557.0625 - val_loss: 3526.9673\n",
      "Epoch 204/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1192760.3750 - val_loss: 3523.8440\n",
      "Epoch 205/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 46893.4922 - val_loss: 3520.8257\n",
      "Epoch 206/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2480657.0000 - val_loss: 3518.5254\n",
      "Epoch 207/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 111554.2891 - val_loss: 3516.3538\n",
      "Epoch 208/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 30884.9590 - val_loss: 3514.6021\n",
      "Epoch 209/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 310407.7812 - val_loss: 3513.1875\n",
      "Epoch 210/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 3769494.0000 - val_loss: 3513.3223\n",
      "Epoch 211/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 78759.0000 - val_loss: 3512.3809\n",
      "Epoch 212/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 55485.7812 - val_loss: 3511.8501\n",
      "Epoch 213/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2051032.7500 - val_loss: 3509.5505\n",
      "Epoch 214/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 207082.9688 - val_loss: 3507.7961\n",
      "Epoch 215/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 299587.9062 - val_loss: 3505.5215\n",
      "Epoch 216/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 324312.5938 - val_loss: 3504.1555\n",
      "Epoch 217/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 298252.2188 - val_loss: 3502.7122\n",
      "Epoch 218/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 488074.1562 - val_loss: 3501.3010\n",
      "Epoch 219/10000\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 66910.2812 - val_loss: 3500.1331\n",
      "Epoch 220/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 133590.4062 - val_loss: 3498.6394\n",
      "Epoch 221/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 276639.3438 - val_loss: 3497.3743\n",
      "Epoch 222/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 945661.5625 - val_loss: 3495.7625\n",
      "Epoch 223/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 24866.7402 - val_loss: 3494.2964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 60264.7891 - val_loss: 3492.2783\n",
      "Epoch 225/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 32048.0469 - val_loss: 3491.2332\n",
      "Epoch 226/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 15188.0088 - val_loss: 3490.0557\n",
      "Epoch 227/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1274286.1250 - val_loss: 3488.7676\n",
      "Epoch 228/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 367032.5312 - val_loss: 3486.6240\n",
      "Epoch 229/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 65500.8984 - val_loss: 3485.2598\n",
      "Epoch 230/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 82076.7812 - val_loss: 3481.9929\n",
      "Epoch 231/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 319723.6250 - val_loss: 3480.2676\n",
      "Epoch 232/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 113248.6406 - val_loss: 3479.1018\n",
      "Epoch 233/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 351008.5938 - val_loss: 3477.4246\n",
      "Epoch 234/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 525926.1250 - val_loss: 3476.0894\n",
      "Epoch 235/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 188647.3281 - val_loss: 3474.7981\n",
      "Epoch 236/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 64195.1406 - val_loss: 3472.9976\n",
      "Epoch 237/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 86469.1719 - val_loss: 3471.9707\n",
      "Epoch 238/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 109652.9609 - val_loss: 3470.3152\n",
      "Epoch 239/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 46436.8984 - val_loss: 3469.3071\n",
      "Epoch 240/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 241093.2969 - val_loss: 3467.4111\n",
      "Epoch 241/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 136484.1250 - val_loss: 3466.4702\n",
      "Epoch 242/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 32789.6797 - val_loss: 3465.3652\n",
      "Epoch 243/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 23258.9238 - val_loss: 3464.3376\n",
      "Epoch 244/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 70341.6875 - val_loss: 3463.3379\n",
      "Epoch 245/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 121173.9609 - val_loss: 3461.8850\n",
      "Epoch 246/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 81084.6797 - val_loss: 3460.9600\n",
      "Epoch 247/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 562992.7500 - val_loss: 3458.9395\n",
      "Epoch 248/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 48725.9180 - val_loss: 3457.4731\n",
      "Epoch 249/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 9249.2637 - val_loss: 3456.4207\n",
      "Epoch 250/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 46953.7812 - val_loss: 3455.1824\n",
      "Epoch 251/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 29490.1328 - val_loss: 3454.2695\n",
      "Epoch 252/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 185797.8906 - val_loss: 3452.6316\n",
      "Epoch 253/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 336243.1250 - val_loss: 3451.5308\n",
      "Epoch 254/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 3660162.0000 - val_loss: 3447.9468\n",
      "Epoch 255/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 168736.8594 - val_loss: 3445.9062\n",
      "Epoch 256/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 148391.4375 - val_loss: 3444.3547\n",
      "Epoch 257/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1114494.0000 - val_loss: 3441.1733\n",
      "Epoch 258/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 26575.1855 - val_loss: 3436.8823\n",
      "Epoch 259/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 36657.7930 - val_loss: 3435.4871\n",
      "Epoch 260/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 19538.1055 - val_loss: 3434.3315\n",
      "Epoch 261/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 182431.3281 - val_loss: 3433.0811\n",
      "Epoch 262/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1519365.1250 - val_loss: 3431.7676\n",
      "Epoch 263/10000\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 107380.7500 - val_loss: 3429.7009\n",
      "Epoch 264/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 140545.2656 - val_loss: 3428.5588\n",
      "Epoch 265/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 46241.7188 - val_loss: 3427.2046\n",
      "Epoch 266/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 704000.0000 - val_loss: 3425.6504\n",
      "Epoch 267/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 400737.4062 - val_loss: 3424.1592\n",
      "Epoch 268/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 56049.8945 - val_loss: 3423.0249\n",
      "Epoch 269/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 125064.5469 - val_loss: 3421.6558\n",
      "Epoch 270/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 81911.0469 - val_loss: 3420.7449\n",
      "Epoch 271/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 69599.7031 - val_loss: 3419.7834\n",
      "Epoch 272/10000\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 26372.3652 - val_loss: 3418.8074\n",
      "Epoch 273/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 135184.4688 - val_loss: 3417.7646\n",
      "Epoch 274/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 21561.3262 - val_loss: 3416.7139\n",
      "Epoch 275/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1567954.0000 - val_loss: 3414.4106\n",
      "Epoch 276/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 148818.3750 - val_loss: 3412.2578\n",
      "Epoch 277/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 61534.2969 - val_loss: 3411.1104\n",
      "Epoch 278/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 40383.1914 - val_loss: 3409.9021\n",
      "Epoch 279/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 124508.0859 - val_loss: 3408.8547\n",
      "Epoch 280/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1051608.1250 - val_loss: 3407.2034\n",
      "Epoch 281/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 47655.7109 - val_loss: 3405.3062\n",
      "Epoch 282/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 3286327.0000 - val_loss: 3403.6069\n",
      "Epoch 283/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 13548.0840 - val_loss: 3398.8901\n",
      "Epoch 284/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 16222.7812 - val_loss: 3395.9651\n",
      "Epoch 285/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 21142.2812 - val_loss: 3394.9531\n",
      "Epoch 286/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 28620.3027 - val_loss: 3393.4692\n",
      "Epoch 287/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 88204.7344 - val_loss: 3392.6055\n",
      "Epoch 288/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 15476.3203 - val_loss: 3391.5667\n",
      "Epoch 289/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 36812.4531 - val_loss: 3390.6489\n",
      "Epoch 290/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 10599.4277 - val_loss: 3389.4785\n",
      "Epoch 291/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 40789.9961 - val_loss: 3388.4102\n",
      "Epoch 292/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 21812.3535 - val_loss: 3387.6892\n",
      "Epoch 293/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 26575.6582 - val_loss: 3386.8459\n",
      "Epoch 294/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 966029.3125 - val_loss: 3385.9233\n",
      "Epoch 295/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 69754.6797 - val_loss: 3384.1445\n",
      "Epoch 296/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 503571.8750 - val_loss: 3382.9453\n",
      "Epoch 297/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 286301.0938 - val_loss: 3381.9692\n",
      "Epoch 298/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 136489.3281 - val_loss: 3379.9724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 107105.6328 - val_loss: 3378.5320\n",
      "Epoch 300/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 398720.8750 - val_loss: 3377.3210\n",
      "Epoch 301/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 53020.2188 - val_loss: 3375.9509\n",
      "Epoch 302/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 236618.3594 - val_loss: 3375.0232\n",
      "Epoch 303/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 18379.3965 - val_loss: 3373.8157\n",
      "Epoch 304/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 18227.0332 - val_loss: 3372.6748\n",
      "Epoch 305/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 96401.8984 - val_loss: 3372.0332\n",
      "Epoch 306/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 46841.4727 - val_loss: 3371.1880\n",
      "Epoch 307/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 125431.5625 - val_loss: 3370.1890\n",
      "Epoch 308/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 420892.5000 - val_loss: 3368.9082\n",
      "Epoch 309/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 66905.7891 - val_loss: 3367.5115\n",
      "Epoch 310/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 49043.9805 - val_loss: 3366.3340\n",
      "Epoch 311/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 40487.1992 - val_loss: 3365.4658\n",
      "Epoch 312/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 266557.7500 - val_loss: 3364.7756\n",
      "Epoch 313/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 52947.0820 - val_loss: 3363.5613\n",
      "Epoch 314/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 185930.9375 - val_loss: 3362.3599\n",
      "Epoch 315/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 26152.8555 - val_loss: 3360.0352\n",
      "Epoch 316/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 72411.2969 - val_loss: 3358.6707\n",
      "Epoch 317/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 546101.1250 - val_loss: 3357.0544\n",
      "Epoch 318/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 163079.5938 - val_loss: 3355.2771\n",
      "Epoch 319/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 165600.2031 - val_loss: 3354.6025\n",
      "Epoch 320/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 46535.1562 - val_loss: 3353.3748\n",
      "Epoch 321/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 396229.5000 - val_loss: 3351.9377\n",
      "Epoch 322/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 43768.1367 - val_loss: 3350.4707\n",
      "Epoch 323/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 83793.7266 - val_loss: 3349.5220\n",
      "Epoch 324/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 65632.4922 - val_loss: 3348.8279\n",
      "Epoch 325/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 13587.6807 - val_loss: 3347.7749\n",
      "Epoch 326/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 31875.0840 - val_loss: 3347.0767\n",
      "Epoch 327/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 23874.2344 - val_loss: 3346.1001\n",
      "Epoch 328/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 58952.8164 - val_loss: 3345.0496\n",
      "Epoch 329/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 21619.5039 - val_loss: 3344.5645\n",
      "Epoch 330/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 12915.4453 - val_loss: 3343.7273\n",
      "Epoch 331/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 98610.3125 - val_loss: 3342.9883\n",
      "Epoch 332/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 2904730.2500 - val_loss: 3340.6750\n",
      "Epoch 333/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 16573.0742 - val_loss: 3337.3164\n",
      "Epoch 334/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 62122.0430 - val_loss: 3336.0833\n",
      "Epoch 335/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 176796.7188 - val_loss: 3333.2371\n",
      "Epoch 336/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 62128.1172 - val_loss: 3332.5688\n",
      "Epoch 337/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 460983.0000 - val_loss: 3331.3291\n",
      "Epoch 338/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 52821.0859 - val_loss: 3330.0322\n",
      "Epoch 339/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 11182.3584 - val_loss: 3329.2498\n",
      "Epoch 340/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 15367.5957 - val_loss: 3328.3970\n",
      "Epoch 341/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 3871409.7500 - val_loss: 3325.7446\n",
      "Epoch 342/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 28220.3730 - val_loss: 3322.3003\n",
      "Epoch 343/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 330902.3750 - val_loss: 3318.2178\n",
      "Epoch 344/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 251517.2344 - val_loss: 3317.0764\n",
      "Epoch 345/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3257276.7500 - val_loss: 3312.0449\n",
      "Epoch 346/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 70623.2891 - val_loss: 3308.5688\n",
      "Epoch 347/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 65696.0234 - val_loss: 3307.0435\n",
      "Epoch 348/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 23981.1484 - val_loss: 3306.0479\n",
      "Epoch 349/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 144064.1719 - val_loss: 3304.4348\n",
      "Epoch 350/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 413476.5938 - val_loss: 3303.8005\n",
      "Epoch 351/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1078177.7500 - val_loss: 3302.5818\n",
      "Epoch 352/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 79955.7109 - val_loss: 3302.3608\n",
      "Epoch 353/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 132099.8125 - val_loss: 3301.8577\n",
      "Epoch 354/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 13691.8789 - val_loss: 3301.1213\n",
      "Epoch 355/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 59312.1484 - val_loss: 3300.3054\n",
      "Epoch 356/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 13790486.0000 - val_loss: 3284.4551\n",
      "Epoch 357/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 177821.2969 - val_loss: 3276.3035\n",
      "Epoch 358/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 636772.5000 - val_loss: 3272.4456\n",
      "Epoch 359/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 49243.2734 - val_loss: 3271.4438\n",
      "Epoch 360/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 266271.1250 - val_loss: 3270.0479\n",
      "Epoch 361/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 76249.2656 - val_loss: 3269.0078\n",
      "Epoch 362/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 13700.9980 - val_loss: 3268.4722\n",
      "Epoch 363/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 106590.1172 - val_loss: 3267.3799\n",
      "Epoch 364/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 63579.3594 - val_loss: 3266.7300\n",
      "Epoch 365/10000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 34472.8711 - val_loss: 3266.2983\n",
      "Epoch 366/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 10365.4512 - val_loss: 3265.3586\n",
      "Epoch 367/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 37524.5938 - val_loss: 3264.4805\n",
      "Epoch 368/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 17474.9492 - val_loss: 3263.7805\n",
      "Epoch 369/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 30504.2949 - val_loss: 3263.0762\n",
      "Epoch 370/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 39906.4219 - val_loss: 3262.4126\n",
      "Epoch 371/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 19149.9004 - val_loss: 3261.8342\n",
      "Epoch 372/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 43865.8359 - val_loss: 3260.8208\n",
      "Epoch 373/10000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 133662.5156 - val_loss: 3260.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 23949.1875 - val_loss: 3259.3457\n",
      "Epoch 375/10000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 72686.3281 - val_loss: 3258.5332\n",
      "Epoch 376/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 74562.7031 - val_loss: 3257.7480\n",
      "Epoch 377/10000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 174843.3281 - val_loss: 3257.0249\n",
      "Epoch 378/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 37159.9922 - val_loss: 3255.9734\n",
      "Epoch 379/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 35738.4570 - val_loss: 3255.3562\n",
      "Epoch 380/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 204508.9688 - val_loss: 3253.5750\n",
      "Epoch 381/10000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 44163.2461 - val_loss: 3252.8511\n",
      "Epoch 382/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 108925.1875 - val_loss: 3252.0967\n",
      "Epoch 383/10000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 20652.3477 - val_loss: 3251.1116\n",
      "Epoch 384/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 131296.1250 - val_loss: 3250.6204\n",
      "Epoch 385/10000\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 709549.4375 - val_loss: 3247.6663\n",
      "Epoch 386/10000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 3017914.0000 - val_loss: 3243.8835\n",
      "Epoch 387/10000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 107880.5234 - val_loss: 3241.0420\n",
      "Epoch 388/10000\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 27198.9238 - val_loss: 3239.2129\n",
      "Epoch 389/10000\n",
      "8/9 [=========================>....] - ETA: 0s - loss: 57783.0078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fp_encoder1024_model_history\u001b[38;5;241m=\u001b[39m\u001b[43mfp_encoder1024_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs2decoder_encoder1024_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlfadfp_latent1024_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs2decoder_encoder1024_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1715\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1716\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1717\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1718\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1525\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_function\u001b[39m(iterator):\n\u001b[0;32m   1524\u001b[0m   \u001b[38;5;124;03m\"\"\"Runs a test execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1513\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     model\u001b[38;5;241m.\u001b[39m_test_counter\u001b[38;5;241m.\u001b[39massign_add(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m-> 1513\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1514\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(run_step, args\u001b[38;5;241m=\u001b[39m(data,))\n\u001b[0;32m   1515\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1516\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:836\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    835\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:819\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 819\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2917\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   2916\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2917\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2918\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2919\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   2921\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fp_encoder1024_model_history=fp_encoder1024_model.fit([x_train, inputs2decoder_encoder1024_train], x_train, batch_size = BATCH_SIZE, epochs=10000, \n",
    "          callbacks = lfadfp_latent1024_callbacks,\n",
    "          validation_data=([x_val, inputs2decoder_encoder1024_val], x_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9942a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import QGRU, QDense\n",
    "from tensorflow.keras.layers import Input, Dropout, Bidirectional, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911bb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qmodel(act_total_bits=8, act_int_bits=2, \n",
    "                 qgru_total_bits=8, qgru_int_bits=2, qgru_sigmoid_bits=8, qgru_tanh_bits=8, drop=0.05\n",
    "                ):\n",
    "    \n",
    "    # keras tuner params:\n",
    "    \n",
    "    act_quan = \"quantized_bits({},{},alpha=1)\".format(act_total_bits, act_int_bits)\n",
    "    quan = \"quantized_bits({},{},alpha=1)\".format(qgru_total_bits, qgru_int_bits)\n",
    "    q_sigmoid = \"quantized_sigmoid({})\".format(qgru_sigmoid_bits)\n",
    "    q_tanh = \"quantized_tanh({})\".format(qgru_tanh_bits)\n",
    "       \n",
    "    # input layer\n",
    "    inputLayer =  Input(shape=(73, 70))    \n",
    "    # no need to quantize the input layer, already qunaitzed  \n",
    "    \n",
    "    x = Dropout(drop, name = 'initial_dropout')(inputLayer)\n",
    "    \n",
    "    # encoder\n",
    "    # reset_after is false for default qgru\n",
    "    # reset_after True to apply reset gate after/before matrix multiplication\n",
    "    forward_layer = QGRU(\n",
    "            64, \n",
    "            activation=q_tanh,\n",
    "            recurrent_activation=q_sigmoid,\n",
    "            kernel_quantizer=quan,\n",
    "            recurrent_quantizer=quan,\n",
    "            bias_quantizer=quan,\n",
    "            state_quantizer=act_quan,\n",
    "            kernel_regularizer=layers_settings['encoder']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['encoder']['kernel_initializer'],\n",
    "            reset_after = True,\n",
    "           time_major=False, name=\"EncoderGRUForward\", return_state=True)\n",
    "    \n",
    "    backward_layer = QGRU(\n",
    "            64, \n",
    "            activation=q_tanh,\n",
    "            recurrent_activation=q_sigmoid,\n",
    "            kernel_quantizer=quan,\n",
    "            recurrent_quantizer=quan,\n",
    "            bias_quantizer=quan,\n",
    "            state_quantizer=act_quan,\n",
    "            kernel_regularizer=layers_settings['encoder']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['encoder']['kernel_initializer'],\n",
    "            reset_after = True,\n",
    "            time_major=False, name=\"EncoderGRUBackward\", return_state=True, go_backwards=True)\n",
    "        \n",
    "        \n",
    "    x = Bidirectional(\n",
    "        forward_layer, \n",
    "        backward_layer=backward_layer,\n",
    "        merge_mode='concat', \n",
    "        name = 'Encoder_BidirectionalGRU'\n",
    "        )(x)[0]    \n",
    "    x = QActivation(act_quan, name = \"active_bits0\")(x)\n",
    "    \n",
    "    x = Dropout(drop, name = 'postencoder_dropout')(x)\n",
    "    \n",
    "    # latent space, no mean and var \n",
    "    x = QDense(64, \n",
    "               kernel_quantizer=quan,\n",
    "                bias_quantizer=quan,\n",
    "               kernel_regularizer=layers_settings['dense_mean']['kernel_regularizer'],\n",
    "               kernel_initializer=layers_settings['dense_mean']['kernel_initializer'],\n",
    "               name='dense_latent'\n",
    "              )(x)\n",
    "    x = QActivation(act_quan, name = \"active_bits1\")(x)\n",
    "    \n",
    "    # decoder\n",
    "    input_decoder = Input(shape=(73, 64))\n",
    "    \n",
    "    x = QGRU(                        \n",
    "            64, \n",
    "            activation=q_tanh,\n",
    "            recurrent_activation=q_sigmoid,\n",
    "            kernel_quantizer=quan,\n",
    "            recurrent_quantizer=quan,\n",
    "            bias_quantizer=quan,\n",
    "            state_quantizer=act_quan,\n",
    "            kernel_regularizer=layers_settings['decoder']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['decoder']['kernel_initializer'],\n",
    "            reset_after = True,\n",
    "            return_sequences=True, time_major=False, name='DecoderGRU'\n",
    "    )(input_decoder, initial_state = x)\n",
    "    x = QActivation(act_quan, name = \"active_bits2\")(x)\n",
    "    \n",
    "    x = Dropout(drop, name = 'postdecoder_dropout')(x)\n",
    "    z = QDense(4, \n",
    "            kernel_quantizer=quan,\n",
    "            bias_quantizer=quan,\n",
    "            use_bias=False, \n",
    "            kernel_regularizer=layers_settings['dense']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['dense']['kernel_initializer'],\n",
    "            name=\"dense\"\n",
    "            )(x)\n",
    "    z = QActivation(act_quan, name = \"active_bits3\")(z)\n",
    "    \n",
    "    log_f = QDense(70, \n",
    "            kernel_quantizer=quan,\n",
    "            bias_quantizer=quan,\n",
    "            #use_bias=False, \n",
    "            kernel_regularizer=layers_settings['nerual_dense']['kernel_regularizer'],\n",
    "            kernel_initializer=layers_settings['nerual_dense']['kernel_initializer'],\n",
    "                   name='nerual_dense')(z)\n",
    "    \n",
    "    z = QActivation(act_quan, name = \"active_bits4\")(log_f)\n",
    "\n",
    "    model = Model(inputs = [inputLayer,input_decoder], outputs =z)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91e213",
   "metadata": {},
   "source": [
    "# train a 16bits model\n",
    "## no regulization loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "297365b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_qmodel(act_total_bits=16, \n",
    "                     act_int_bits=5, \n",
    "                 qgru_total_bits=16, \n",
    "                     qgru_int_bits=5, \n",
    "                     qgru_sigmoid_bits=16, \n",
    "                     qgru_tanh_bits=16, \n",
    "                     drop=dropout, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27231813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 73, 70)]     0           []                               \n",
      "                                                                                                  \n",
      " initial_dropout (Dropout)      (None, 73, 70)       0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder_BidirectionalGRU (Bidi  [(None, 128),       52224       ['initial_dropout[0][0]']        \n",
      " rectional)                      (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " active_bits0 (QActivation)     (None, 128)          0           ['Encoder_BidirectionalGRU[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " postencoder_dropout (Dropout)  (None, 128)          0           ['active_bits0[0][0]']           \n",
      "                                                                                                  \n",
      " dense_latent (QDense)          (None, 64)           8256        ['postencoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 73, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " active_bits1 (QActivation)     (None, 64)           0           ['dense_latent[0][0]']           \n",
      "                                                                                                  \n",
      " DecoderGRU (QGRU)              (None, 73, 64)       24960       ['input_4[0][0]',                \n",
      "                                                                  'active_bits1[0][0]']           \n",
      "                                                                                                  \n",
      " active_bits2 (QActivation)     (None, 73, 64)       0           ['DecoderGRU[0][0]']             \n",
      "                                                                                                  \n",
      " postdecoder_dropout (Dropout)  (None, 73, 64)       0           ['active_bits2[0][0]']           \n",
      "                                                                                                  \n",
      " dense (QDense)                 (None, 73, 4)        256         ['postdecoder_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " active_bits3 (QActivation)     (None, 73, 4)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " nerual_dense (QDense)          (None, 73, 70)       280         ['active_bits3[0][0]']           \n",
      "                                                                                                  \n",
      " active_bits4 (QActivation)     (None, 73, 70)       0           ['nerual_dense[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 85,976\n",
      "Trainable params: 85,976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23ef8a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c6862",
   "metadata": {},
   "source": [
    "# train\n",
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e214021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(\"lfad16bits_log.csv\", separator=\",\", append=False)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"lfad16bits.h5\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    save_weights_only= False\n",
    ")\n",
    "\n",
    "\n",
    "lfad16bits_callbacks=[csv_logger, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a9ffafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = poisson_loglike_loss,\n",
    "    optimizer = optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be95995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 46174.2305 - val_loss: 42105.2344\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 40827.6836 - val_loss: 36840.7734\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 36422.1641 - val_loss: 33349.9805\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 33510.9453 - val_loss: 31130.3594\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 31764.6621 - val_loss: 29949.9121\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 30762.6914 - val_loss: 29146.1758\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 29955.3203 - val_loss: 28462.5781\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 29318.7500 - val_loss: 27919.8770\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28799.0078 - val_loss: 27563.4277\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28555.0059 - val_loss: 27441.1211\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28502.8320 - val_loss: 27467.1406\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28486.9395 - val_loss: 27432.0840\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28477.4277 - val_loss: 27425.3574\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28454.6094 - val_loss: 27418.8887\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28384.1465 - val_loss: 27392.1094\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28363.9766 - val_loss: 27376.5859\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28350.5078 - val_loss: 27397.7344\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28330.3535 - val_loss: 27413.1172\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28349.4961 - val_loss: 27364.3652\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28288.8105 - val_loss: 27350.6406\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28280.0918 - val_loss: 27347.2402\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28262.8594 - val_loss: 27329.9258\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28246.9375 - val_loss: 27323.7051\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28245.6582 - val_loss: 27312.9355\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28166.4121 - val_loss: 27310.3750\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28173.4297 - val_loss: 27337.3301\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28198.6074 - val_loss: 27277.0625\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28176.0488 - val_loss: 27283.1406\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28166.3398 - val_loss: 27366.4844\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28164.2559 - val_loss: 27269.7969\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28146.1387 - val_loss: 27321.2520\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28188.9805 - val_loss: 27394.7988\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28217.7344 - val_loss: 27232.4238\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28150.7285 - val_loss: 27245.6172\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28104.1250 - val_loss: 27238.1582\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28100.5625 - val_loss: 27214.6719\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28072.3770 - val_loss: 27206.4844\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28077.9395 - val_loss: 27231.3047\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28053.1387 - val_loss: 27196.0898\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28063.8145 - val_loss: 27192.6406\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28078.0547 - val_loss: 27221.8770\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28061.3027 - val_loss: 27178.7109\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28061.7637 - val_loss: 27185.3535\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28054.3594 - val_loss: 27184.3379\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28051.3516 - val_loss: 27146.1777\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28033.7617 - val_loss: 27159.4531\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28027.0996 - val_loss: 27194.9160\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28055.9766 - val_loss: 27146.0957\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28055.1113 - val_loss: 27136.4316\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28044.5547 - val_loss: 27164.7539\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28034.0723 - val_loss: 27175.7363\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28035.6973 - val_loss: 27157.0156\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28039.7480 - val_loss: 27154.2246\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28027.4863 - val_loss: 27170.2285\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28023.2891 - val_loss: 27154.2461\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28022.7090 - val_loss: 27141.7910\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28005.0117 - val_loss: 27170.6387\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28000.8652 - val_loss: 27147.8555\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 27989.7871 - val_loss: 27153.6133\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28019.6074 - val_loss: 27177.9141\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28031.5098 - val_loss: 27122.9277\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28042.6777 - val_loss: 27137.5898\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28033.7949 - val_loss: 27168.5645\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28102.8730 - val_loss: 27178.8652\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28069.8750 - val_loss: 27181.2285\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28045.4414 - val_loss: 27194.4609\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28093.8594 - val_loss: 27252.5332\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28030.0996 - val_loss: 27175.7656\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28074.2051 - val_loss: 27189.5312\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28067.9492 - val_loss: 27165.2422\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28045.7227 - val_loss: 27168.0742\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28050.1172 - val_loss: 27169.0234\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28027.6582 - val_loss: 27164.5664\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28009.4023 - val_loss: 27167.1641\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28025.5977 - val_loss: 27131.9922\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28031.9668 - val_loss: 27188.9199\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28068.9805 - val_loss: 27173.1133\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28058.9453 - val_loss: 27205.5664\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28097.1445 - val_loss: 27185.7656\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28042.5625 - val_loss: 27193.7227\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28079.7031 - val_loss: 27181.9980\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28050.8105 - val_loss: 27207.4121\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28026.1777 - val_loss: 27155.1387\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28050.4551 - val_loss: 27257.4824\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28056.8672 - val_loss: 27163.6758\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28041.8164 - val_loss: 27191.7461\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28020.5781 - val_loss: 27188.0156\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28013.5859 - val_loss: 27170.4277\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28015.6230 - val_loss: 27183.4336\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28045.9492 - val_loss: 27196.0449\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28009.3828 - val_loss: 27165.9336\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 27995.2520 - val_loss: 27204.3320\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28034.5703 - val_loss: 27151.2031\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28018.1504 - val_loss: 27145.5430\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28037.1152 - val_loss: 27169.4141\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28065.8672 - val_loss: 27183.4512\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28027.7812 - val_loss: 27196.4746\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28034.6973 - val_loss: 27170.2168\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28041.3770 - val_loss: 27244.2988\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28087.8008 - val_loss: 27155.1230\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28072.6289 - val_loss: 27173.6426\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28077.0430 - val_loss: 27267.7090\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28052.7871 - val_loss: 27182.9004\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28071.6426 - val_loss: 27249.6504\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28043.6816 - val_loss: 27179.5059\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28040.5645 - val_loss: 27221.2090\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28038.2812 - val_loss: 27193.1973\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28016.6113 - val_loss: 27168.4121\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28034.9395 - val_loss: 27165.8379\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28015.0703 - val_loss: 27155.9297\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28018.3828 - val_loss: 27155.9688\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28025.8945 - val_loss: 27141.3145\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 27999.3359 - val_loss: 27140.7910\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 27998.0059 - val_loss: 27153.4316\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28014.0977 - val_loss: 27151.7891\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28019.1035 - val_loss: 27183.1562\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28015.2285 - val_loss: 27152.8359\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28093.2344 - val_loss: 27387.7695\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28278.5781 - val_loss: 27281.3867\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28241.0723 - val_loss: 27386.2773\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28245.0781 - val_loss: 27308.9316\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28266.1191 - val_loss: 27382.5273\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28315.2148 - val_loss: 27475.2363\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28314.8340 - val_loss: 27396.3418\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28384.4570 - val_loss: 27457.8672\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28344.4219 - val_loss: 27396.7344\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28225.8301 - val_loss: 27343.0977\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28206.1289 - val_loss: 27598.5195\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28215.2422 - val_loss: 27316.5469\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28164.2422 - val_loss: 27337.9922\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28197.4844 - val_loss: 27428.1250\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28238.5410 - val_loss: 27272.1113\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28113.8672 - val_loss: 27259.4551\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28110.5801 - val_loss: 27255.7598\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28120.0566 - val_loss: 27197.2969\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28124.7246 - val_loss: 27317.6289\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28130.4629 - val_loss: 27234.4785\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28142.5488 - val_loss: 27252.0684\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28116.5430 - val_loss: 27221.8730\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28079.2617 - val_loss: 27187.5781\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28099.2031 - val_loss: 27182.3262\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28091.0781 - val_loss: 27225.9336\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28098.4277 - val_loss: 27202.4668\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28099.0938 - val_loss: 27192.0605\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28098.0039 - val_loss: 27250.5801\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28099.8516 - val_loss: 27236.3555\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28111.4609 - val_loss: 27217.2363\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28085.3477 - val_loss: 27213.6797\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28073.2188 - val_loss: 27226.4902\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28077.6133 - val_loss: 27207.1387\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28073.9414 - val_loss: 27223.9551\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28070.2988 - val_loss: 27297.4922\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28131.2754 - val_loss: 27343.7559\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28113.8281 - val_loss: 27292.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28058.3828 - val_loss: 27303.8652\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28093.8047 - val_loss: 27299.5508\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28107.3438 - val_loss: 27287.8105\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28095.8691 - val_loss: 27369.2754\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28152.2637 - val_loss: 27516.2695\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28239.6367 - val_loss: 27277.8047\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28114.2852 - val_loss: 27256.5703\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28139.7930 - val_loss: 27267.2070\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28110.0234 - val_loss: 27238.6250\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28076.8926 - val_loss: 27252.6465\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28077.8711 - val_loss: 27224.8926\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28088.2539 - val_loss: 27242.3730\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28084.6172 - val_loss: 27208.5469\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28070.1270 - val_loss: 27210.5488\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28046.1406 - val_loss: 27196.0156\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28071.8750 - val_loss: 27220.9395\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28116.6562 - val_loss: 27217.3984\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28070.1094 - val_loss: 27245.9531\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28078.8945 - val_loss: 27221.6113\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28090.6074 - val_loss: 27203.7441\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28066.1875 - val_loss: 27206.7090\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 31s 4s/step - loss: 28063.0527 - val_loss: 27210.0957\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28027.0469 - val_loss: 27203.8242\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28044.0273 - val_loss: 27181.5684\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28054.5449 - val_loss: 27184.8438\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28051.6055 - val_loss: 27203.0801\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28074.5840 - val_loss: 27201.7598\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28054.8262 - val_loss: 27219.1094\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28076.8750 - val_loss: 27221.8320\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28084.3613 - val_loss: 27186.3418\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28044.2363 - val_loss: 27212.3281\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28026.9824 - val_loss: 27178.8125\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28058.7949 - val_loss: 27220.3496\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28080.4648 - val_loss: 27167.8496\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28074.8965 - val_loss: 27202.3672\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28040.4883 - val_loss: 27175.2969\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28040.3594 - val_loss: 27193.1914\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28032.5371 - val_loss: 27178.0977\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28029.5879 - val_loss: 27167.3516\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28053.3359 - val_loss: 27250.7070\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28038.4219 - val_loss: 27169.4844\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28044.2227 - val_loss: 27175.3730\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28033.6230 - val_loss: 27203.5547\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 31s 3s/step - loss: 28013.5117 - val_loss: 27213.7031\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 29s 3s/step - loss: 28029.0977 - val_loss: 27234.8633\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 30s 3s/step - loss: 28025.8438 - val_loss: 27186.0918\n"
     ]
    }
   ],
   "source": [
    "qmodel_history=model.fit([x_train, inputs2decoder_train], x_train, batch_size = BATCH_SIZE, epochs=200, \n",
    "          callbacks = lfad16bits_callbacks,\n",
    "          validation_data=([x_val, inputs2decoder_val], x_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "747e9fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(qmodel_history.history['loss'])\n",
    "plt.plot(qmodel_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16a683",
   "metadata": {},
   "source": [
    "# search with keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    act_total_bits = hp.Int(\"act_total_bits\", min_value=2, max_value=16, step=2)\n",
    "    act_int_bits = hp.Int(\" act_int_bits\", min_value=0, max_value=act_total_bits-1, step=1)\n",
    "    qgru_total_bits = hp.Int(\"qgru_total_bits\", min_value=2, max_value=16, step=2)\n",
    "    qgru_int_bits = hp.Int(\"qgru_int_bits\", min_value=0, max_value=qgru_total_bits-1, step=1)\n",
    "    qgru_sigmoid_bits = hp.Int(\"qgru_sigmoid_bits\", min_value=2, max_value=16, step=2)\n",
    "    qgru_tanh_bits = hp.Int(\"qgru_tanh_bits\", min_value=2, max_value=16, step=2)\n",
    "    #activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    #dropout = hp.Boolean(\"dropout\")\n",
    "    #dropout = hp.Float(\"drop\", min_value=0.05, max_value=0.2, step=0.05)\n",
    "    \n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = create_model(\n",
    "                        act_total_bits = act_total_bits,\n",
    "                        act_int_bits = act_int_bits,\n",
    "                        qgru_total_bits=qgru_total_bits, \n",
    "                         qgru_int_bits=qgru_int_bits, \n",
    "                         qgru_sigmoid_bits=qgru_sigmoid_bits, \n",
    "                         qgru_tanh_bits=qgru_tanh_bits, \n",
    "                         drop=dropout, \n",
    "                         )\n",
    "    \n",
    "    model.compile(\n",
    "    loss = poisson_loglike_loss,\n",
    "    optimizer = optimizer\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc99429",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2, #reduce results variance\n",
    "    overwrite=True,\n",
    "    directory=\"Q_RAE\",\n",
    "    project_name=\"Keras_Tuner_Q_RAE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ccf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search([x_train, inputs2decoder_train], x_train, batch_size = 16, epochs=5, validation_data=([x_val, inputs2decoder_val], x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(2)\n",
    "# Build the model with the best hp.\n",
    "model_best = build_model(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608aae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.autoqkeras.utils import print_qmodel_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304228a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_qmodel_summary(model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d87f44",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"q_rae.h5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c37f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_history = model_best.fit([x_train, inputs2decoder_train], \n",
    "               y_train, \n",
    "               batch_size = 16, \n",
    "               epochs=100, \n",
    "               validation_data=([x_val, inputs2decoder_val], y_val),\n",
    "               callbacks = model_checkpoint_callback\n",
    "              \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_history2 = model_best.fit([x_train, inputs2decoder_train], \n",
    "               y_train, \n",
    "               batch_size = 16, \n",
    "               epochs=100, \n",
    "               validation_data=([x_val, inputs2decoder_val], y_val),\n",
    "               callbacks = model_checkpoint_callback\n",
    "              \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6c401",
   "metadata": {},
   "source": [
    "# Train fp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3dcbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fp_model(drop = 0.05, initializer=None, regularizer=None):\n",
    "    inputLayer =  Input(shape=(73,70))\n",
    "    x = Dropout(drop, name = 'initial_dropout')(inputLayer)\n",
    "    x = Bidirectional(GRU(64, time_major=False, \n",
    "                            return_state=True, kernel_regularizer=regularizer, \n",
    "                            kernel_initializer=initializer), \n",
    "                        backward_layer=GRU(64, time_major=False, \n",
    "                                           return_state=True, go_backwards=True, \n",
    "                                           kernel_regularizer=regularizer, kernel_initializer=initializer), \n",
    "                        merge_mode='concat', name = 'Encoder_BidirectionalGRU')(x)[0]\n",
    "    x = Dropout(drop, name = 'postencoder_dropout')(x)\n",
    "    x = Dense(64, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense_mean')(x)\n",
    "\n",
    "    input_decoder = Input(shape=(73, 64))\n",
    "    x = GRU(64, return_sequences=True, \n",
    "          time_major=False, kernel_initializer=initializer, \n",
    "          kernel_regularizer=regularizer, name='decoder_GRU')(input_decoder, initial_state = x)\n",
    "    x = Dropout(drop, name = 'postdecoder_dropout')(x)\n",
    "    out = Dense(2, use_bias = False, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense')(x)\n",
    "\n",
    "    model = Model(inputs = [inputLayer,input_decoder], outputs = out)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"mean_squared_error\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_model = get_fp_model(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"fp_rae.h5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b752fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_model_history = fp_model.fit([x_train, inputs2decoder_train], \n",
    "               y_train, \n",
    "               batch_size = 16, \n",
    "               epochs=100, \n",
    "               validation_data=([x_val, inputs2decoder_val], y_val),\n",
    "               callbacks = fp_model_checkpoint_callback\n",
    "              \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ba193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Flatten, GRU, Activation, Embedding, Bidirectional, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import hls4ml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "initializer = tf.keras.initializers.VarianceScaling(distribution='normal')\n",
    "regularizer = tf.keras.regularizers.L2(l=1)\n",
    "inputs2model = test_neural_data # 17, 73, 70\n",
    "inputDim = 136\n",
    "inputs2decoder = tf.stack([tf.zeros_like(inputs2model)[:, :, -1]\n",
    "            for i in range(64)], axis=-1)\n",
    "\n",
    "# if isinstance(inputs2model, np.ndarray):\n",
    "#   print(\"inputs2model IS numpy array\")\n",
    "# else:\n",
    "#   print(\"inputs2model IS NOT numpy array\")\n",
    "\n",
    "# if isinstance(inputs2decoder, np.ndarray):\n",
    "#   print(\"inputs2decoder IS numpy array\")\n",
    "# else:\n",
    "#   print(\"inputs2decoder IS NOT numpy array\")\n",
    "\n",
    "# if isinstance(inputs2decoder, list):\n",
    "#   print(\"inputs2decoder IS list\")\n",
    "# else:\n",
    "#   print(\"inputs2decoder IS NOT list\")\n",
    "\n",
    "inputs2decoder_np = np.array(inputs2decoder)\n",
    "\n",
    "if isinstance(inputs2decoder, np.ndarray):\n",
    "  print(\"inputs2decoder IS numpy array\")\n",
    "else:\n",
    "  print(\"inputs2decoder IS NOT numpy array\")\n",
    "\n",
    "# inputs2decoder = np.zeros((17,73,64))\n",
    "def create_model(inputs2model, inputs2decoder, initializer, regularizer):\n",
    "  \n",
    "  inputLayer =  Input(shape=inputs2model[0].shape)\n",
    "  x = Dropout(0.05, name = 'initial_dropout')(inputLayer)\n",
    "  x = Bidirectional(GRU(64, time_major=False, \n",
    "                        return_state=True, kernel_regularizer=regularizer, \n",
    "                        kernel_initializer=initializer), \n",
    "                    backward_layer=GRU(64, time_major=False, \n",
    "                                       return_state=True, go_backwards=True, \n",
    "                                       kernel_regularizer=regularizer, kernel_initializer=initializer), \n",
    "                    merge_mode='concat', name = 'Encoder_BidirectionalGRU')(x)[0]\n",
    "  x = Dropout(0.05, name = 'postencoder_dropout')(x)\n",
    "  x = Dense(64, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense_mean')(x)\n",
    "  input_decoder = Input(shape=inputs2decoder[0].shape)\n",
    "  x = GRU(64, return_sequences=True, \n",
    "          time_major=False, kernel_initializer=initializer, \n",
    "          kernel_regularizer=regularizer, name='decoder_GRU')(input_decoder, initial_state = x)\n",
    "  x = Dropout(0.05, name = 'postdecoder_dropout')(x)\n",
    "  z = Dense(4, use_bias = False, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense')(x)\n",
    "  log_f = Dense(70, kernel_regularizer=regularizer, kernel_initializer=initializer, name='nerual_dense')(z)\n",
    "  # z = Flatten()(z)\n",
    "  # temp_1 = Dense(5,name='dense_temp1')(z)\n",
    "  # log_f = Flatten()(log_f)\n",
    "  # temp_2 = Dense(5,name='dense_temp2')(log_f)\n",
    "  out = Concatenate()([z,log_f])\n",
    "\n",
    " # return Model(inputs = [inputLayer,input_decoder], outputs =[z, log_f])\n",
    "  return Model(inputs = [inputLayer,input_decoder], outputs =out)\n",
    "\n",
    "LFADs_keras = create_model(inputs2model,inputs2decoder, initializer, regularizer)\n",
    "# LFADs_keras.summary()\n",
    "LFADs_keras.compile()\n",
    "\n",
    "LFADs = tf.keras.models.load_model(\"/home/xiaohan/HLS4ML_side_branch/hls4ml/test_LFADs/3_3.h5\")\n",
    "# LFADs.summary()\n",
    "\n",
    "LFADs_keras.layers[2].set_weights(LFADs.layers[2].get_weights())\n",
    "LFADs_keras.layers[5].set_weights(LFADs.layers[5].get_weights())\n",
    "LFADs_keras.layers[6].set_weights(LFADs.layers[6].get_weights())\n",
    "LFADs_keras.layers[8].set_weights(LFADs.layers[8].get_weights())\n",
    "LFADs_keras.layers[9].set_weights(LFADs.layers[9].get_weights())\n",
    "\n",
    "lfads_out = LFADs_keras.predict([inputs2model, inputs2decoder_np])\n",
    "print(\"lfads_out prediction by keras is:\")\n",
    "print(lfads_out.shape)\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(LFADs_keras, granularity='model', default_precision='ap_fixed<32,16>')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "'''plotting.print_dict(config)'''\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(LFADs_keras,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='/home/xiaohan/HLS4ML_side_branch/hls4ml/test_LFADs',\n",
    "                                                       part='xc7v2000tflg1925-2')\n",
    "print(\"done\")\n",
    "hls_model.compile()\n",
    "hls_out = hls_model.predict([inputs2model, inputs2decoder_np])\n",
    "hls_out = np.reshape(hls_out, (17,73,74))\n",
    "print(hls_out)\n",
    "#hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)\n",
    "# hls_model.build(csim=False)\n",
    "hls_out_z = hls_out[:,:,:4]\n",
    "hls_out_log_f = hls_out[:,:,4:]\n",
    "print(hls_out_z.shape)\n",
    "print(hls_out_log_f.shape)\n",
    "print(\"z\", hls_out_z)\n",
    "print(\"log_f\",hls_out_log_f)\n",
    "np.savetxt(\"/home/xiaohan/HLS4ML_side_branch/hls4ml/test_LFADs/hls_out_z_32_16.txt\", hls_out_z.reshape((-1, hls_out_z.shape[-1])))\n",
    "np.savetxt(\"/home/xiaohan/HLS4ML_side_branch/hls4ml/test_LFADs/hls_out_log_f_32_16.txt\", hls_out_log_f.reshape((-1, hls_out_log_f.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9080e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "input_shape = (73, 70)  # Shape of the 'inputs' tensor \n",
    "# input_shape = (5, 2) # for testing\n",
    "batch_size = 136  # Batch size\n",
    "inputs_data = np.random.rand(batch_size, *input_shape)\n",
    "# print(inputs_data)\n",
    "load_test_data = np.loadtxt(\"/home/xiaohan/HLS4ML_side_branch/hls4ml/test_LFADs/test_nerual_data.txt\")\n",
    "test_neural_data = load_test_data.reshape((17,73,70))\n",
    "print(test_neural_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a9d83-e8ad-4510-acec-0824b792c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# center behaviour at zero, using first time step (not strictly required)\n",
    "b_mean = np.mean(np.vstack((behavioural_data, test_behavioural_data, valid_behavioural_data))[:,0,:],axis=0)\n",
    "for i in range(2):\n",
    "    behavioural_data[:,:,i] = behavioural_data[:,:,i]-b_mean[i]\n",
    "    valid_behavioural_data[:,:,i] = valid_behavioural_data[:,:,i]-b_mean[i]\n",
    "    test_behavioural_data[:,:,i] = test_behavioural_data[:,:,i]-b_mean[i]\n",
    "\n",
    "# for plotting\n",
    "d_all = np.concatenate((dataset['train_target_direction'], dataset['test_target_direction'], dataset['valid_target_direction']))\n",
    "d = dataset['train_target_direction']\n",
    "direction_index_train = np.array([sorted(set(d_all)).index(i) for i in d])\n",
    "d = dataset['test_target_direction']\n",
    "direction_index_test = np.array([sorted(set(d_all)).index(i) for i in d])\n",
    "direction_index_all = np.concatenate((direction_index_test, direction_index_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfc37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioural_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b9011-2934-4c02-aeea-101242151d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "\n",
    "# l2 regulariser for the recurrent decoder weights\n",
    "l2_reg = .1\n",
    "initial_neural_weight = 1.0 # weight of neural nll\n",
    "initial_behaviour_weight = .2 # weight of behaviour loss\n",
    "lambda_q = 100.0\n",
    "update_rate = .0005\n",
    "dropout = .15\n",
    "seed = 0\n",
    "GRU_pre_activation = False\n",
    "var_min = 0.0001\n",
    "prior_variance = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-2,\n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08)\n",
    "\n",
    "layers_settings=defaultdict(lambda: dict(\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "        scale=1.0, mode='fan_in', distribution='normal'),\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(l=0.0)\n",
    "))\n",
    "\n",
    "layers_settings['encoder'].update(dict(var_min=var_min, var_trainable=True))\n",
    "layers_settings['decoder'].update(dict(kernel_regularizer=tf.keras.regularizers.l2(l=0),\n",
    "                                      recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                      original_cell=False))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ddc0fe",
   "metadata": {},
   "source": [
    "# for Qkeras\n",
    "# 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_settings['quantizer'] = \"quantized_bits(8,0,1,alpha=1.0)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003ee5b-e0f5-4d83-bc53-632e65f67abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = datetime.today().strftime(\"%y_%m_%d_%X\")\n",
    "\n",
    "logdir = os.path.join( spike_data_dir, 'lfads_log_l2_reg_'+str(l2_reg)+'_'+T)\n",
    "modeldir = os.path.join( spike_data_dir, 'lfads_model_l2_reg_'+str(l2_reg)+'_'+T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537bdff-f267-4fde-b31b-d3d5f34da2e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "T0 = datetime.now()\n",
    "\n",
    "model, history, x_train, y_train, (x_test, y_test) = Runtime.train(\n",
    "    model_type=ModelType.LFADS,\n",
    "    adaptive_lr=dict(factor=0.95, patience=10, min_lr=1e-5),\n",
    "    model_settings=dict(\n",
    "        factors=4,\n",
    "        encoded_dim=64,\n",
    "        max_grad_norm=200,\n",
    "        dropout=dropout,\n",
    "        prior_variance=prior_variance,\n",
    "        GRU_pre_activation=GRU_pre_activation, #NEW\n",
    "        timestep=settings['step'],\n",
    "        seed=seed\n",
    "    ),\n",
    "    layers_settings=layers_settings,\n",
    "    optimizer=optimizer, \n",
    "    epochs=1, \n",
    "    logdir=logdir,\n",
    "    train_dataset=(neural_data, behavioural_data), \n",
    "    val_dataset=(valid_neural_data, valid_behavioural_data),\n",
    "    adaptive_weights=AdaptiveWeights(\n",
    "        initial=[initial_neural_weight, initial_behaviour_weight, .0, .0, lambda_q, .0], #changed\n",
    "        update_start=[0, 0, 0, 1000, 1000, 0],\n",
    "        update_rate=[0., 0., update_rate, update_rate, 0.0, update_rate],\n",
    "        min_weight=[initial_neural_weight, initial_behaviour_weight, 0.0, 0.0, lambda_q, 0.0],#changed\n",
    "        max_weight=[initial_neural_weight, initial_behaviour_weight, 1.0, 1.0, lambda_q, 1.0],#changed\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    verbose=2 # set to 2 to see the losses during training\n",
    ")\n",
    "\n",
    "#model.save(modeldir)\n",
    "\n",
    "print('Training took '+str(datetime.now()-T0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodergru = model.layers[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodergru.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodergru.cell.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodergru.cell.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e624351",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodergru.cell.recurrent_quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc40011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e72c2f",
   "metadata": {},
   "source": [
    "# Rebuild "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import QGRU, QDense\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout, RNN, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16366cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_in = Input(shape = neural_data.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensor_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs2model, inputs2decoder, initializer, regularizer):\n",
    "  \n",
    "  inputLayer =  Input(shape=inputs2model[0].shape)\n",
    "  x = Dropout(0.05, name = 'initial_dropout')(inputLayer)\n",
    "  x = Bidirectional(GRU(64, time_major=False, \n",
    "                        return_state=True, kernel_regularizer=regularizer, \n",
    "                        kernel_initializer=initializer), \n",
    "                    backward_layer=GRU(64, time_major=False, \n",
    "                                       return_state=True, go_backwards=True, \n",
    "                                       kernel_regularizer=regularizer, kernel_initializer=initializer), \n",
    "                    merge_mode='concat', name = 'Encoder_BidirectionalGRU')(x)[0]\n",
    "  x = Dropout(0.05, name = 'postencoder_dropout')(x)\n",
    "  x = Dense(64, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense_mean')(x)\n",
    "  input_decoder = Input(shape=inputs2decoder[0].shape)\n",
    "  x = GRU(64, return_sequences=True, \n",
    "          time_major=False, kernel_initializer=initializer, \n",
    "          kernel_regularizer=regularizer, name='decoder_GRU')(input_decoder, initial_state = x)\n",
    "  x = Dropout(0.05, name = 'postdecoder_dropout')(x)\n",
    "  z = Dense(4, use_bias = False, kernel_regularizer=regularizer, kernel_initializer=initializer, name='dense')(x)\n",
    "  log_f = Dense(70, kernel_regularizer=regularizer, kernel_initializer=initializer, name='nerual_dense')(z)\n",
    "  # z = Flatten()(z)\n",
    "  # temp_1 = Dense(5,name='dense_temp1')(z)\n",
    "  # log_f = Flatten()(log_f)\n",
    "  # temp_2 = Dense(5,name='dense_temp2')(log_f)\n",
    "  out = Concatenate()([z,log_f])\n",
    "\n",
    " # return Model(inputs = [inputLayer,input_decoder], outputs =[z, log_f])\n",
    "  return Model(inputs = [inputLayer,input_decoder], outputs =out)\n",
    "\n",
    "LFADs_keras = create_model(inputs2model,inputs2decoder, initializer, regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770ebf8-abcf-4641-ab68-e6912de205bc",
   "metadata": {},
   "source": [
    "# Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84a787-3ee6-4f6b-bdba-263aea1cc211",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866305e-40b7-4687-a3d9-3783261e770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_f, (g0, mean, logvar), z =  model(neural_data.astype('float'), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioural_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984983e6-3220-45c9-896c-2c8739fcdeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent variables\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.subplot(221)\n",
    "proj = PCA(n_components=2, whiten=True).fit_transform(mean)\n",
    "plt.scatter(proj[:,0], proj[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('PCA factor 1')\n",
    "plt.ylabel('PCA factor 2')\n",
    "plt.title('Factors')\n",
    "\n",
    "plt.subplot(222)\n",
    "ics_embedded = TSNE(n_components=2, n_jobs=2, random_state=12).fit_transform(mean)\n",
    "plt.scatter(ics_embedded[:,0], ics_embedded[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('T-SNE factor 1')\n",
    "plt.ylabel('T-SNE factor 2')\n",
    "plt.title('Factors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6c1e-c6c2-4b86-82f4-f257780909d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent factors\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_all_2factors(z, direction_index_train)\n",
    "plt.figure(figsize=(8,1.5))\n",
    "plot_all_1factors(z, direction_index_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294ce0-3578-4950-9657-8961241125df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "factors_reconstruct = np.arange(4)\n",
    "\n",
    "X = np.transpose(z.numpy()[:,:,factors_reconstruct], (0,2,1)).reshape((z.shape[0], -1))\n",
    "y = np.transpose(behavioural_data, (0,2,1)).reshape((behavioural_data.shape[0], -1))\n",
    "\n",
    "Xt = X\n",
    "yt = y\n",
    "\n",
    "reg = Ridge(normalize=True, fit_intercept=True).fit(X, y)\n",
    "print(reg.score(Xt, yt))\n",
    "beh_fit = reg.predict(Xt)\n",
    "b = np.zeros_like(behavioural_data)\n",
    "b[:,:,0] = beh_fit[:,:behavioural_data.shape[1]]\n",
    "b[:,:,1] = beh_fit[:,behavioural_data.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14269fb4-9bdb-4dac-8dd1-387d635152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour reconstruction\n",
    "plt.figure(figsize=(6,6));\n",
    "plot_behaviour(b, behavioural_data, direction_index_train, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc7b3f-3ea6-49a9-b456-1be4d3b813cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.transpose(b, (0,2,1)).reshape((b.shape[0], -1))\n",
    "yt = np.transpose(behavioural_data, (0,2,1)).reshape((behavioural_data.shape[0], -1))\n",
    "print('R2 score behaviour: {:.3%}'.format(r2_score( yt, Xt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d701cd3-d88d-416b-928c-99b101355ce4",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffffd8-26b0-4abb-8a1c-6754685b16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_f_t, (g0_t, mean_t, logvar_t), z_t = \\\n",
    "    model(test_neural_data.astype('float'), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88094aef-9b59-4bd2-afec-8484661814ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent variables\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.subplot(221)\n",
    "proj = PCA(n_components=2, whiten=True).fit_transform(np.vstack((mean,mean_t)))\n",
    "plt.scatter(proj[:,0], proj[:,1], alpha=.8, color=direction_colors[np.concatenate((direction_index_train, direction_index_test))])\n",
    "plt.axis('equal')\n",
    "plt.ylabel('PCA factor 2')\n",
    "plt.title('Factors')\n",
    "\n",
    "plt.subplot(222)\n",
    "ics_embedded = TSNE(n_components=2, n_jobs=2, random_state=12).fit_transform(np.vstack((mean,mean_t)))\n",
    "plt.scatter(ics_embedded[:,0], ics_embedded[:,1], alpha=.8, color=direction_colors[np.concatenate((direction_index_train, direction_index_test))])\n",
    "plt.axis('equal')\n",
    "plt.ylabel('T-SNE factor 2')\n",
    "plt.title('Factors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abbda3-737b-433b-ae50-21ccfb54c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant factors\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_all_2factors(z_t, direction_index_test)\n",
    "# relevant factors\n",
    "plt.figure(figsize=(8,1.5))\n",
    "plot_all_1factors(z_t, direction_index_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dce614-76e9-4c7b-b6ca-3a32410955db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "factors_reconstruct = np.arange(4)\n",
    "\n",
    "X = np.transpose(z.numpy()[:,:,factors_reconstruct], (0,2,1)).reshape((z.shape[0], -1))\n",
    "y = np.transpose(behavioural_data, (0,2,1)).reshape((behavioural_data.shape[0], -1))\n",
    "\n",
    "Xt = np.transpose(z_t.numpy()[:,:,factors_reconstruct], (0,2,1)).reshape((z_t.shape[0], -1))\n",
    "yt = np.transpose(test_behavioural_data, (0,2,1)).reshape((test_behavioural_data.shape[0], -1))\n",
    "\n",
    "reg = Ridge(normalize=True, fit_intercept=True).fit(X, y)\n",
    "print(reg.score(Xt, yt))\n",
    "beh_fit = reg.predict(Xt)\n",
    "b_t = np.zeros_like(test_behavioural_data)\n",
    "b_t[:,:,0] = beh_fit[:,:test_behavioural_data.shape[1]]\n",
    "b_t[:,:,1] = beh_fit[:,test_behavioural_data.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d1cd0-8a6b-4c47-8518-823063b620a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour reconstruction\n",
    "plt.figure(figsize=(6,6));\n",
    "plot_behaviour(b_t, test_behavioural_data, direction_index_test, num=100)\n",
    "# plot_behaviour(b, behavioural_data, direction_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae2385-d408-4e1d-8192-daf595c4e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.transpose(b_t, (0,2,1)).reshape((b_t.shape[0], -1))\n",
    "yt = np.transpose(test_behavioural_data, (0,2,1)).reshape((test_behavioural_data.shape[0], -1))\n",
    "print('R2 score behaviour: {:.3%}'.format(r2_score( yt, Xt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a011344-9a6c-4c44-b4f4-cb343b5c29dc",
   "metadata": {},
   "source": [
    "# Trial-averaged firing rates and predictions\n",
    "Computed from test+train data for better averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4313f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "colors = plt.cm.nipy_spectral(np.arange(8)/8)\n",
    "a = []\n",
    "for i in range(8):\n",
    "    data = np.vstack((test_neural_data, neural_data))[direction_index_all==i,:,:]\n",
    "\n",
    "    for i_n,n in enumerate(range(0,70)):\n",
    "        ax = fig.add_subplot(8, 70, i*70+i_n+1)\n",
    "        pred = np.vstack((np.exp(log_f_t)*settings['step'], np.exp(log_f)*settings['step']))[np.array(direction_index_all)==i,:,n]\n",
    "        x = np.arange(data.shape[1])\n",
    "        ax.plot(x,np.mean(data,axis=0)[:,n],'k',alpha=0.5);\n",
    "        data_mean = np.mean(data,axis=0)\n",
    "        data_mean_test = np.mean(data,axis=0)[:,n]\n",
    "#         print(\"n\",n)\n",
    "#         print(pred.shape)\n",
    "#         print(data_mean_test.shape)\n",
    "        \n",
    "        ax.fill_between(x,np.mean(data,axis=0)[:,n]-np.std(data,axis=0)[:,n], np.mean(data,axis=0)[:,n]+np.std(data,axis=0)[:,n], alpha=0.2, color='k');\n",
    "        ax.plot(x,np.mean(pred,axis=0),lw=3, color=colors[i]);\n",
    "        pred_test = np.mean(pred,axis=0)\n",
    "#         print(pred_test.shape)\n",
    "\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        plt.ylim(0,1.5)\n",
    "        \n",
    "        data4mse = data_mean_test\n",
    "        pred4mse = pred_test\n",
    "        diff = mean_squared_error(data4mse,pred4mse)\n",
    "        a.append(diff)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(a) / len(a))\n",
    "print(max(a))\n",
    "print(min(a))\n",
    "print(log_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_all = dataset['test_target_direction']\n",
    "\n",
    "d = dataset['test_target_direction']\n",
    "direction_index_test = np.array([sorted(set(d_all)).index(i) for i in d])\n",
    "direction_index_all =direction_index_test\n",
    "print(direction_index_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d4a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
