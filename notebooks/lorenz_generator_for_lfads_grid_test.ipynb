{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latentneural.lorenz import LorenzGenerator, ic\n",
    "from latentneural.data import DataManager\n",
    "from latentneural.utils import logger\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import yaml\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.01 # Time step in the simulatio (in seconds)\n",
    "stop = 1 # Final time for the simulation (in seconds)\n",
    "neurons = 30 # Number of neurons\n",
    "base_rate = 5 # Base frequency (in Hz)\n",
    "latent_dim = 3 # Lorenz latent variables encoded in neural activity (relevant+irrelevant)\n",
    "relevant_dim = 2 # Lorenz latent variables encoded in behavioural activity (relevant)\n",
    "behaviour_dim = 4 # Behavioural channels\n",
    "conditions = 1 # Number of conditions to be tested (each condition has different weight matrices to convert latent variables into firing rates and behaviour)\n",
    "trials = 1000 # Number of trials to be tested for each condition\n",
    "initial_conditions = ic.uniform(low=-10, high=10) # Sample initial conditions of Lorenz system from uniform distribution\n",
    "behaviour_sigma=1 # Standard deviation noise added to behaviour\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'behavioural_keys': {'test': 'test_behaviours', 'train': 'train_behaviours', 'validation': 'valid_behaviours'}, 'dataset_filename': 'dataset.h5', 'directory': './latentneural/data/storage/lorenz/grid/{{name}}', 'latent_keys': {'test': 'test_latent', 'train': 'train_latent', 'validation': 'valid_latent'}, 'metadata_filename': 'metadata.json', 'neural_keys': {'test': 'test_data', 'train': 'train_data', 'validation': 'valid_data'}}, 'model': {'settings': {'default_layer_settings': {'kernel_initializer': {'arguments': {'distribution': 'normal', 'mode': 'fan_in', 'scale': 1.0}, 'type': 'variance_scaling'}, 'kernel_regularizer': {'arguments': {'l': 0.1}, 'type': 'l2'}}, 'encoded_dim': 64, 'layers': {'encoder': {'dropout': 0.05, 'var_max': 0.1, 'var_min': 0.1}, 'decoder': {'kernel_initializer': {'arguments': {'distribution': 'normal', 'mode': 'fan_in', 'scale': 1.0}, 'type': 'variance_scaling'}, 'kernel_regularizer': {'arguments': {'l': 1}, 'type': 'l2'}, 'original_cell': False, 'recurrent_regularizer': {'arguments': {'l': 1}, 'type': 'l2'}}}, 'max_grad_norm': 200, 'factors': 3, 'timestep': 0.01}, 'type': 'lfads'}, 'output': {'directory': './latentneural/data/storage/lorenz/grid/{{name}}/results'}, 'runtime': {'batch_size': 16, 'epochs': 10000, 'learning_rate': {'factor': 0.95, 'initial': 0.01, 'min_lr': 1e-05, 'patience': 6, 'terminating': 1e-05}, 'optimizer': {'arguments': {'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 0.1}, 'type': 'adam'}, 'weights': {'initial': [1.0, 0.0, 0.0], 'min_weight': [1.0, 0.0, 0.0], 'update_rate': [0.0, 0.0005, 0.0005], 'update_start': [0, 2000, 0], 'max_weight': [1.0, 1.0, 1.0]}}, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..', 'latentneural', 'data', 'storage', \\\n",
    "                       'lorenz', 'grid', 'settings_template.yaml'), 'r') as f:\n",
    "   training_settings_template = yaml.safe_load(f)\n",
    "print(training_settings_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:57:00.079] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.088] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.088] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=5|behaviour_sigma=0.5\n",
      "[18:57:00.089] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.096] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.097] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=5|behaviour_sigma=0.5\n",
      "[18:57:00.097] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.105] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.105] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=5|behaviour_sigma=0.5\n",
      "[18:57:00.106] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.113] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.115] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=10|behaviour_sigma=0.5\n",
      "[18:57:00.115] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.122] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.125] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=10|behaviour_sigma=0.5\n",
      "[18:57:00.125] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.132] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.133] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=10|behaviour_sigma=0.5\n",
      "[18:57:00.134] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.141] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.141] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=15|behaviour_sigma=0.5\n",
      "[18:57:00.142] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.150] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.150] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=15|behaviour_sigma=0.5\n",
      "[18:57:00.151] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.158] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.159] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=15|behaviour_sigma=0.5\n",
      "[18:57:00.160] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.168] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.168] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=5|behaviour_sigma=1.0\n",
      "[18:57:00.169] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.180] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.181] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=5|behaviour_sigma=1.0\n",
      "[18:57:00.182] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.192] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.193] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=5|behaviour_sigma=1.0\n",
      "[18:57:00.194] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.201] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.202] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=10|behaviour_sigma=1.0\n",
      "[18:57:00.203] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.211] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.212] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=10|behaviour_sigma=1.0\n",
      "[18:57:00.212] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.219] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.220] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=10|behaviour_sigma=1.0\n",
      "[18:57:00.221] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.229] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.230] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=15|behaviour_sigma=1.0\n",
      "[18:57:00.231] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.239] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.240] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=15|behaviour_sigma=1.0\n",
      "[18:57:00.241] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.250] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.250] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=15|behaviour_sigma=1.0\n",
      "[18:57:00.251] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.258] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.259] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=5|behaviour_sigma=2.0\n",
      "[18:57:00.260] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.267] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.268] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=5|behaviour_sigma=2.0\n",
      "[18:57:00.269] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.276] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.277] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=5|behaviour_sigma=2.0\n",
      "[18:57:00.277] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.285] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.286] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=10|behaviour_sigma=2.0\n",
      "[18:57:00.287] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.294] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.295] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=10|behaviour_sigma=2.0\n",
      "[18:57:00.296] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.304] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.304] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=10|behaviour_sigma=2.0\n",
      "[18:57:00.305] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.312] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.313] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=50|baselinerate=15|behaviour_sigma=2.0\n",
      "[18:57:00.313] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.321] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.322] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=100|baselinerate=15|behaviour_sigma=2.0\n",
      "[18:57:00.323] INFO [latentneural.utils.logging.<module>:66] Dataset stored.\n",
      "[18:57:00.331] INFO [latentneural.utils.logging.<module>:84] Training settings stored.\n",
      "[18:57:00.332] INFO [latentneural.utils.logging.<module>:85] Stored train_trials=200|baselinerate=15|behaviour_sigma=2.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "for behaviour_sigma in [0.5, 1, 2]:\n",
    "    for base_rate in [5, 10, 15]:\n",
    "        for train_num in [50, 100, 200]:\n",
    "            inner_seed = np.random.randint(0, 2**32 - 1)\n",
    "            g: LorenzGenerator = LorenzGenerator()\n",
    "            time, behaviour, spikes, rates, behaviour_w, neural_w, latent = \\\n",
    "                g.generate_spikes_and_behaviour(\n",
    "                    step=step,\n",
    "                    stop=stop,\n",
    "                    n=neurons,\n",
    "                    base=base_rate,\n",
    "                    l=latent_dim,\n",
    "                    b=relevant_dim,\n",
    "                    y=behaviour_dim,\n",
    "                    behaviour_sigma=behaviour_sigma,\n",
    "                    trials=trials + 2 * train_num,\n",
    "                    initial_conditions=initial_conditions,\n",
    "                    conditions=1,\n",
    "                    seed=inner_seed\n",
    "                )\n",
    "\n",
    "            c_i = 0\n",
    "            generation_settings = dict(\n",
    "                step=step,\n",
    "                stop=stop,\n",
    "                neurons=neurons,\n",
    "                base_rate=base_rate,\n",
    "                latent_dim=latent_dim,\n",
    "                relevant_dim=relevant_dim,\n",
    "                behaviour_dim=behaviour_dim,\n",
    "                conditions=conditions,\n",
    "                behaviour_sigma=behaviour_sigma,\n",
    "                trials=trials + 2 * train_num,\n",
    "                initial_conditions={'type': 'uniform', 'arguments': {'min': -10, 'max': 10}},\n",
    "                selected_condition=c_i,\n",
    "                seed=inner_seed)\n",
    "\n",
    "            valid_num = train_num\n",
    "            test_num = trials\n",
    "\n",
    "            dataset, settings = DataManager.build_dataset(\n",
    "                neural_data=spikes[c_i,:,:,:],\n",
    "                behaviour_data=behaviour[c_i,:,:,:],\n",
    "                settings=generation_settings,\n",
    "                noisless_behaviour_data=latent[c_i,:,:,-behaviour_w.shape[1]:] @ behaviour_w[c_i,:,:],\n",
    "                rates_data=rates[c_i,:,:,:],\n",
    "                latent_data=latent[c_i,:,:,:],\n",
    "                time_data=time,\n",
    "                behaviour_weights=behaviour_w[c_i,:,:],\n",
    "                neural_weights=neural_w[c_i,:,:],\n",
    "                train_pct=train_num,\n",
    "                valid_pct=valid_num,\n",
    "                test_pct=test_num\n",
    "            )\n",
    "            dirname = 'train_trials=%d|baselinerate=%d|behaviour_sigma=%.1f' % \\\n",
    "                (train_num, base_rate, behaviour_sigma)\n",
    "            data_dir = os.path.join('..', 'latentneural', 'data', 'storage', 'lorenz', 'grid', \\\n",
    "                                    dirname)\n",
    "            DataManager.store_dataset(\n",
    "                dataset=dataset,\n",
    "                settings=settings,\n",
    "                directory=data_dir)\n",
    "            logger.info('Dataset stored.')\n",
    "            \n",
    "            training_settings = deepcopy(training_settings_template)\n",
    "            training_settings['data']['directory'] = \\\n",
    "                training_settings['data']['directory'].replace('{{name}}', dirname)\n",
    "            training_settings['output']['directory'] = \\\n",
    "                training_settings['output']['directory'].replace('{{name}}', dirname)\n",
    "            # keeping increase per epoch constant (updates are based on batches)\n",
    "            training_settings['runtime']['weights']['update_rate'][1] = \\\n",
    "                training_settings['runtime']['weights']['update_rate'][1] * 100 / train_num\n",
    "            training_settings['runtime']['weights']['update_rate'][2] = \\\n",
    "                training_settings['runtime']['weights']['update_rate'][2] * 100 / train_num\n",
    "            # keeping start epoch constant (start time is based on batches)\n",
    "            training_settings['runtime']['weights']['update_start'][1] = \\\n",
    "                training_settings['runtime']['weights']['update_start'][1] * train_num / 100\n",
    "            \n",
    "            with open(os.path.join(data_dir, 'training_settings.yaml'), 'w') as fp:\n",
    "                yaml.dump(training_settings, fp)\n",
    "            logger.info('Training settings stored.')\n",
    "            logger.info('Stored train_trials=%d|baselinerate=%d|behaviour_sigma=%.1f' % \\\n",
    "                (train_num, base_rate, behaviour_sigma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latentneural",
   "language": "python",
   "name": "latentneural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "1ff63d4d10c80c355101950545778da81857c7b6dbd37ac71d711732e5d5d456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
