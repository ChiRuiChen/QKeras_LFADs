{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228b29f-91ad-42b3-92e5-406bbadfe804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "use_cpu = False\n",
    "cuda_device = '0'\n",
    "\n",
    "if use_cpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    os.environ['CPU_ONLY'] = \"TRUE\"\n",
    "    physical_devices = tf.config.list_physical_devices('CPU')\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        physical_devices[0],\n",
    "        [tf.config.LogicalDeviceConfiguration() for i in range(8)])\n",
    "    logical_devices = tf.config.list_logical_devices('CPU')\n",
    "\n",
    "    print(logical_devices)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = cuda_device\n",
    "    os.environ['CPU_ONLY'] = \"FALSE\"\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    \n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from tndm.data import DataManager\n",
    "from tndm import TNDM\n",
    "from tndm.runtime import Runtime, ModelType\n",
    "from tndm.utils import AdaptiveWeights\n",
    "from tndm.models.model_loader import ModelLoader\n",
    "\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a9d83-e8ad-4510-acec-0824b792c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "spike_data_dir = \"/disk/scratch/cole/Chewie_CO_FF_2016-10-07_pos_M1_spikes/test_data/\"\n",
    "\n",
    "data_dir = os.path.join( spike_data_dir )\n",
    "\n",
    "dataset, settings = DataManager.load_dataset(\n",
    "    directory=data_dir,\n",
    "    filename='dataset.h5')\n",
    "\n",
    "# test set is combined valid and test\n",
    "neural_data = dataset['train_data'].astype('float')\n",
    "valid_neural_data = dataset['valid_data'].astype('float')\n",
    "test_neural_data = dataset['test_data'].astype('float')\n",
    "\n",
    "behavioural_data = dataset['train_behaviours'].astype('float')\n",
    "valid_behavioural_data = dataset['valid_behaviours'].astype('float')\n",
    "test_behavioural_data = dataset['test_behaviours'].astype('float')\n",
    "\n",
    "# center behaviour at zero, using first time step (not strictly required)\n",
    "b_mean = np.mean(np.vstack((behavioural_data, test_behavioural_data, valid_behavioural_data))[:,0,:],axis=0)\n",
    "for i in range(2):\n",
    "    behavioural_data[:,:,i] = behavioural_data[:,:,i]-b_mean[i]\n",
    "    valid_behavioural_data[:,:,i] = valid_behavioural_data[:,:,i]-b_mean[i]\n",
    "    test_behavioural_data[:,:,i] = test_behavioural_data[:,:,i]-b_mean[i]\n",
    "\n",
    "# for plotting\n",
    "d = dataset['train_target_direction']\n",
    "direction_index_train = np.array([sorted(set(d)).index(i) for i in d])\n",
    "d = dataset['test_target_direction']\n",
    "direction_index_test = np.array([sorted(set(d)).index(i) for i in d])\n",
    "direction_index_all = np.concatenate((direction_index_test, direction_index_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b9011-2934-4c02-aeea-101242151d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "\n",
    "# l2 regulariser for the recurrent decoder weights\n",
    "l2_reg = 1\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-2,\n",
    "    beta_1=0.9, \n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08)\n",
    "\n",
    "layers_settings=defaultdict(lambda: dict(\n",
    "    kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "        scale=1.0, mode='fan_in', distribution='normal'),\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(l=0.0)\n",
    "))\n",
    "\n",
    "layers_settings['encoder'].update(dict(dropout=0.15, var_min=0.1, var_trainable=True))\n",
    "layers_settings['relevant_decoder'].update(dict(kernel_regularizer=tf.keras.regularizers.l2(l=0),\n",
    "                                      recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                      original_cell=False))    \n",
    "layers_settings['irrelevant_decoder'].update(dict(kernel_regularizer=tf.keras.regularizers.l2(l=0),\n",
    "                                      recurrent_regularizer=tf.keras.regularizers.l2(l=l2_reg),\n",
    "                                      original_cell=False))   \n",
    "layers_settings['behavioural_dense'].update(dict(behaviour_type='causal'))    \n",
    "\n",
    "initial_neural_weight = 1.0 # weight of neural nll\n",
    "initial_behaviour_weight = .2 # weight of behaviour loss\n",
    "lambda_q = 100.0\n",
    "update_rate = .0005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003ee5b-e0f5-4d83-bc53-632e65f67abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = datetime.today().strftime(\"%y_%m_%d_%X\")\n",
    "\n",
    "logdir = os.path.join( spike_data_dir, 'log_l2_reg_'+str(l2_reg)+'_'+T)\n",
    "modeldir = os.path.join( spike_data_dir, 'model_l2_reg_'+str(l2_reg)+'_'+T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537bdff-f267-4fde-b31b-d3d5f34da2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T0 = datetime.now()\n",
    "\n",
    "model, history = Runtime.train(\n",
    "    model_type=ModelType.TNDM,\n",
    "    adaptive_lr=dict(factor=0.95, patience=10, min_lr=1e-5),\n",
    "    model_settings=dict(\n",
    "        rel_factors=2,\n",
    "        irr_factors=2,\n",
    "        encoded_dim=64,\n",
    "        max_grad_norm=200,\n",
    "        encoded_var_trainable=True, ##changed\n",
    "        encoded_var_min=0.1,\n",
    "        timestep=settings['step'],\n",
    "        seed=0\n",
    "    ),\n",
    "    layers_settings=layers_settings,\n",
    "    optimizer=optimizer, \n",
    "    epochs=1000, \n",
    "    logdir=logdir,\n",
    "    train_dataset=(neural_data, behavioural_data), \n",
    "    val_dataset=(valid_neural_data, valid_behavioural_data),\n",
    "    adaptive_weights=AdaptiveWeights(\n",
    "        initial=[initial_neural_weight, initial_behaviour_weight, .0, .0, lambda_q, .0], #changed\n",
    "        update_start=[0, 0, 0, 0, 0, 0],\n",
    "        update_rate=[0., 0., update_rate, update_rate, 0.0, update_rate],\n",
    "        min_weight=[initial_neural_weight, initial_behaviour_weight, 0.0, 0.0, lambda_q, 0.0],#changed\n",
    "        max_weight=[initial_neural_weight, initial_behaviour_weight, 1.0, 1.0, lambda_q, 1.0],#changed\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    verbose=0 # set to 2 to see the losses during training\n",
    ")\n",
    "\n",
    "model.save(modeldir)\n",
    "\n",
    "print('Training took '+str(datetime.now()-T0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e643a42-22bf-4853-8b31-78dd4117d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = '/disk/scratch/cole/Chewie_CO_FF_2016-10-07_pos_M1_spikes/test_data/model_l2_reg_1_21_10_22_23:23:46'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d86842-203f-4049-b3ad-a9451d21c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelLoader.load(modeldir, model_class=TNDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770ebf8-abcf-4641-ab68-e6912de205bc",
   "metadata": {},
   "source": [
    "# Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84a787-3ee6-4f6b-bdba-263aea1cc211",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866305e-40b7-4687-a3d9-3783261e770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = neural_data\n",
    "test_sample_mode = 'posterior_sample' #choose 'mean' for previous behaviour\n",
    "\n",
    "if test_sample_mode == 'mean':\n",
    "    log_f, b, (g0_r, mean_r, logvar_r), (g0_r, mean_i, logvar_i), (z_r, z_i) = \\\n",
    "        model(data.astype('float'), training=False, test_sample_mode=test_sample_mode)\n",
    "else:\n",
    "    batch_size_eval = 128\n",
    "    log_fs = []\n",
    "    bs = []\n",
    "    g0_rs, mean_rs, logvar_rs, z_rs = [], [], [], []\n",
    "    g0_is, mean_is, logvar_is, z_is = [], [], [], []\n",
    "    for neural_datum in data:\n",
    "        neural_datum_batch = np.repeat(np.expand_dims(neural_datum, 0), batch_size_eval, axis=0)\n",
    "        log_f, b, (g0_r, mean_r, logvar_r), (g0_i, mean_i, logvar_i), (z_r, z_i) = \\\n",
    "            model(neural_datum_batch.astype('float'), training=False, test_sample_mode=test_sample_mode)\n",
    "        log_fs.append(np.mean(log_f, 0))\n",
    "        bs.append(np.mean(b, 0))\n",
    "        g0_rs.append(np.mean(g0_r, 0))\n",
    "        mean_rs.append(np.mean(mean_r, 0))\n",
    "        logvar_rs.append(np.mean(logvar_r, 0))\n",
    "        z_rs.append(np.mean(z_r, 0))\n",
    "        g0_is.append(np.mean(g0_i, 0))\n",
    "        mean_is.append(np.mean(mean_i, 0))\n",
    "        logvar_is.append(np.mean(logvar_i, 0))\n",
    "        z_is.append(np.mean(z_i, 0))\n",
    "    log_f = tf.stack(log_fs)\n",
    "    b = tf.stack(bs)\n",
    "    g0_r = tf.stack(g0_rs)\n",
    "    mean_r = tf.stack(mean_rs)\n",
    "    logvar_r = tf.stack(logvar_rs)\n",
    "    z_r = tf.stack(z_rs)\n",
    "    g0_i = tf.stack(g0_is)\n",
    "    mean_i = tf.stack(mean_is)\n",
    "    logvar_i = tf.stack(logvar_is)\n",
    "    z_i = tf.stack(z_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984983e6-3220-45c9-896c-2c8739fcdeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent variables\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.subplot(221)\n",
    "proj = PCA(n_components=2).fit_transform(mean_r)\n",
    "plt.scatter(proj[:,0], proj[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.ylabel('PCA factor 2')\n",
    "plt.title('Relevant factors')\n",
    "\n",
    "plt.subplot(222)\n",
    "ics_embedded = TSNE(n_components=2, n_jobs=2, random_state=12).fit_transform(mean_r)\n",
    "plt.scatter(ics_embedded[:,0], ics_embedded[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.ylabel('T-SNE factor 2')\n",
    "plt.title('Relevant factors')\n",
    "\n",
    "plt.subplot(223)\n",
    "proj = PCA(n_components=2).fit_transform(mean_i)\n",
    "plt.scatter(proj[:,0], proj[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('PCA factor 1')\n",
    "plt.ylabel('PCA factor 2')\n",
    "plt.title('Irrelevant factors')\n",
    "\n",
    "plt.subplot(224)\n",
    "ics_embedded = TSNE(n_components=2, n_jobs=2, random_state=12).fit_transform(mean_i)\n",
    "plt.scatter(ics_embedded[:,0], ics_embedded[:,1], alpha=.8, color=direction_colors[direction_index_train])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('T-SNE factor 1')\n",
    "plt.ylabel('T-SNE factor 2')\n",
    "plt.title('Irrelevant factors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca6c1e-c6c2-4b86-82f4-f257780909d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent factors\n",
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_2factors(z_r, direction_index_train)\n",
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_r, direction_index_train)\n",
    "# irrelevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_i, direction_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14269fb4-9bdb-4dac-8dd1-387d635152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour reconstruction\n",
    "plt.figure(figsize=(6,6));\n",
    "plot_behaviour(b, behavioural_data, direction_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc7b3f-3ea6-49a9-b456-1be4d3b813cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.transpose(b, (0,2,1)).reshape((b.shape[0], -1))\n",
    "yt = np.transpose(behavioural_data, (0,2,1)).reshape((behavioural_data.shape[0], -1))\n",
    "print('R2 score behaviour: {:.3%}'.format(r2_score( yt, Xt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d701cd3-d88d-416b-928c-99b101355ce4",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffffd8-26b0-4abb-8a1c-6754685b16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_neural_data\n",
    "test_sample_mode = 'posterior_sample' #choose 'mean' for previous behaviour\n",
    "if test_sample_mode == 'mean':\n",
    "    log_f_t, b_t, (g0_r_t, mean_r_t, logvar_r_t), (g0_r_t, mean_i_t, logvar_i_t), (z_r_t, z_i_t) = \\\n",
    "        model(data.astype('float'), training=False, test_sample_mode=test_sample_mode)\n",
    "else:\n",
    "    batch_size_eval = 128\n",
    "    log_f_ts = []\n",
    "    b_ts = []\n",
    "    g0_r_ts, mean_r_ts, logvar_r_ts, z_r_ts = [], [], [], []\n",
    "    g0_i_ts, mean_i_ts, logvar_i_ts, z_i_ts = [], [], [], []\n",
    "    for neural_datum in data:\n",
    "        neural_datum_batch = np.repeat(np.expand_dims(neural_datum, 0), batch_size_eval, axis=0)\n",
    "        log_f_t, b_t, (g0_r_t, mean_r_t, logvar_r_t), (g0_i_t, mean_i_t, logvar_i_t), (z_r_t, z_i_t) = \\\n",
    "            model(neural_datum_batch.astype('float'), training=False, test_sample_mode=test_sample_mode)\n",
    "        log_f_ts.append(np.mean(log_f_t, 0))\n",
    "        b_ts.append(np.mean(b_t, 0))\n",
    "        g0_r_ts.append(np.mean(g0_r_t, 0))\n",
    "        mean_r_ts.append(np.mean(mean_r_t, 0))\n",
    "        logvar_r_ts.append(np.mean(logvar_r_t, 0))\n",
    "        z_r_ts.append(np.mean(z_r_t, 0))\n",
    "        g0_i_ts.append(np.mean(g0_i_t, 0))\n",
    "        mean_i_ts.append(np.mean(mean_i_t, 0))\n",
    "        logvar_i_ts.append(np.mean(logvar_i_t, 0))\n",
    "        z_i_ts.append(np.mean(z_i_t, 0))\n",
    "\n",
    "    log_f_t = tf.stack(log_f_ts)\n",
    "    b_t = tf.stack(b_ts)\n",
    "    g0_r_t = tf.stack(g0_r_ts)\n",
    "    mean_r_t = tf.stack(mean_r_ts)\n",
    "    logvar_r_t = tf.stack(logvar_r_ts)\n",
    "    z_r_t = tf.stack(z_r_ts)\n",
    "    g0_i_t = tf.stack(g0_i_ts)\n",
    "    mean_i_t = tf.stack(mean_i_ts)\n",
    "    logvar_i_t = tf.stack(logvar_i_ts)\n",
    "    z_i_t = tf.stack(z_i_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa38dd9-22ae-4b10-9ce7-37e416c424b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_2factors(z_r_t, direction_index_test)\n",
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_r_t, direction_index_test)\n",
    "# irrelevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_i_t, direction_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abbda3-737b-433b-ae50-21ccfb54c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_2factors(z_r_t, direction_index_test)\n",
    "# relevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_r_t, direction_index_test)\n",
    "# irrelevant factors\n",
    "plt.figure()\n",
    "plot_all_1factors(z_i_t, direction_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d1cd0-8a6b-4c47-8518-823063b620a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour reconstruction\n",
    "plt.figure(figsize=(6,6));\n",
    "plot_behaviour(b_t, test_behavioural_data, direction_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae2385-d408-4e1d-8192-daf595c4e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.transpose(b_t, (0,2,1)).reshape((b_t.shape[0], -1))\n",
    "yt = np.transpose(test_behavioural_data, (0,2,1)).reshape((test_behavioural_data.shape[0], -1))\n",
    "print('R2 score behaviour: {:.3%}'.format(r2_score( yt, Xt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a011344-9a6c-4c44-b4f4-cb343b5c29dc",
   "metadata": {},
   "source": [
    "# Trial-averaged firing rates and predictions\n",
    "Computed from test+train data for better averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4929699-0d91-421d-bb41-b0010966ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,10))\n",
    "colors = plt.cm.nipy_spectral(np.arange(8)/8)\n",
    "for i in range(8):\n",
    "    data = np.vstack((test_neural_data, neural_data))[direction_index_all==i,:,:]\n",
    "    \n",
    "    for i_n,n in enumerate(range(0,10)):\n",
    "        ax = fig.add_subplot(8, 10, i*10+i_n+1)\n",
    "        pred = np.vstack((np.exp(log_f_t)*settings['step'], np.exp(log_f)*settings['step']))[np.array(direction_index_all)==i,:,n]\n",
    "        x = np.arange(data.shape[1])\n",
    "        ax.plot(x,np.mean(data,axis=0)[:,n],'k',alpha=0.5);\n",
    "        ax.fill_between(x,np.mean(data,axis=0)[:,n]-np.std(data,axis=0)[:,n], np.mean(data,axis=0)[:,n]+np.std(data,axis=0)[:,n], alpha=0.2, color='k');\n",
    "        ax.plot(x,np.mean(pred,axis=0),lw=3, color=colors[i]);\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        plt.ylim(0,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4506b3b-7d22-4540-8b48-063c9f2ea190",
   "metadata": {},
   "source": [
    "# Decoder weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e0f3d-3b58-449f-bbd8-713af801fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural decoder\n",
    "plt.figure(figsize=(12,1))\n",
    "plt.imshow((model.neural_dense._trainable_weights[0]),vmin=-1,vmax=1,cmap=plt.cm.RdBu_r)\n",
    "plt.colorbar()\n",
    "# behaviour decoder\n",
    "plot_behaviour_weights(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:latentneural-gpu] *",
   "language": "python",
   "name": "conda-env-latentneural-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
